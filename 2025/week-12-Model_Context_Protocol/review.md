# MCP (Model Context Protocol)

В последнее время аббревиатура MCP стала все более часто появляться в некоторых статьях и разделах комментариев на arXiv или Daily Papers Hugging Face, которые я просматриваю. Внезапно осознав, что мое представление об этом лишь приблизительное, я решил изучить его более подробно и поделиться с вами.

## Single Agent

Давайте сначала рассмотрим архитектуру с одним агентом.

![Figure](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-12-Model_Context_Protocol/assets/Figure.png)

1. Инструменты — это функции, которые определены и вызываются в текущей программе. Определение функции инструментов будет включено в системную подсказку, чтобы позволить LLM понять доступные в настоящее время инструменты.

2. Память делится на две части: текущий поток данных сеанса, включая то, что выполняется на каждом шаге, и каков результат, сохраняется в памяти текущего сеанса и может быть полностью введен в LLM в любое время, чтобы позволить LLM определить, что делать дальше. Долгосрочные данные и база знаний пользователя, такие как данные о предпочтениях пользователя на платформе, контент домена, многораундовый контекст разговора и т. д., будут извлечены из векторной базы данных.

3. Маршрутизатор централизует планирование программы всего процесса, передавая вводимые пользователем подсказки/системные подсказки/память в LLM, а LLM проводит углубленное мышление и выдает конкретные задачи по выполнению, а маршрутизатор вызывает соответствующую функцию действия (function calling).

Это простая и общая архитектура с одним агентом, которая реализует цикл Мысль – План – Действие – Размышление (Мысль) в Агенте, при этом за все отвечает одна модель.

## MCP

В приведенной выше архитектуре модуль Tools (Инструменты) имеет некоторые незначительные проблемы: не очень хорошая поддерживаемость и масштабируемость функций инструмента. Сложно управлять, когда их слишком много. Чтобы добавить функции, нужно обновить основную программу. Кроме того, нужно самостоятельно определить спецификацию вызова функции. Некоторые внешние сервисы инструментов, которые будут использоваться, нужно инкапсулировать самостоятельно.

Для решения этих незначительных проблем данную архитектуру можно оптимизировать: модуль инструмента отделен от агента и управляется и реализуется единообразно с использованием протокола MCP.

## Протокол контекста модели (MCP): новый стандарт интеграции в экосистеме ИИ

Протокол контекста модели (Model Context Protocol, MCP) — это открытый стандарт, разработанный и представленный компанией Anthropic 25 ноября 2024 года. Основная цель MCP — создание унифицированного протокола связи между большими языковыми моделями (LLM) и внешними источниками данных и инструментами. Как по мне, MCP появился как естественная эволюция подхода Function Calling, преодолевая его ограничения и расширяя возможности взаимодействия моделей ИИ с внешним миром. Если Function Calling можно рассматривать как точечное решение конкретных задач взаимодействия, то MCP представляет собой комплексный подход к проблеме интеграции, обеспечивая более гибкую, масштабируемую и стандартизированную экосистему.

### Сущность MCP

MCP — это не фреймворк или инструмент, а именно протокол, аналогичный:
- HTTP для интернета
- SMTP для обмена сообщениями
- LSP (Language Server Protocol) для поддержки языков программирования

Anthropic точно характеризует MCP как "эквивалент порта USB-C для агентских систем" — универсальный интерфейс, позволяющий стандартизировать взаимодействие между различными компонентами экосистемы ИИ независимо от их производителя.

> Как говорится, картинка стоит тысячи слов. 

![Figure_1](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-12-Model_Context_Protocol/assets/Figure_1.jpeg)

MCP унифицирует определения вызовов интерфейса для доступа к возможностям различных инструментов. Раньше служба (например, Slack) должна была подключаться к форматам вызовов функций, определенным несколькими пользовательскими продуктами (например, курсором). Теперь службе и клиенту нужно подключаться только к одному и тому же формату, и обеим сторонам нужно реализовать его только один раз.

![Figure_2](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-12-Model_Context_Protocol/assets/Figure_2.png)

MCP Server работает независимо на любом сервере и может иметь собственную независимую базу данных информации/ресурсов. Он не привязан к серверу Agent и может использоваться повторно, а также его легко подключать и отключать.

![Figure_3](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-12-Model_Context_Protocol/assets/Figure_3.png)

Исходные вызовы функций инструмента инкапсулируются с помощью MCP Server, и архитектура становится такой:

![Figure_4](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-12-Model_Context_Protocol/assets/Figure_4.png)

Отличие от исходного чистого вызова функции заключается в том, что архитектура более гибкая, включая:

1. Кластеризация : разрозненные функции можно объединить в одну службу для удобства управления.
2. Развязка : вызов фактически происходит на соответствующей стороне сервера MCP, а не напрямую вызывается службой Agent. Инструмент расширения развертывания развязывается от проекта Agent.
3. Сплоченность: сам сервер MCP может выполнять некоторые действия слаженно, включая независимое управление ресурсами, независимый контекст и т. д.
4. Повторное использование: универсальные протоколы и возможности инструментов облегчают повторное использование между несколькими агентами. Во внешней экосистеме существует множество существующих серверов MCP, к которым можно получить прямой доступ.
5. Унификация: вызовы как клиентских, так и облачных инструментов могут быть реализованы с использованием унифицированного протокола MCP.

### Архитектура и принцип работы

MCP определяет:
1. Способы взаимодействия клиентов с серверами
2. Методы обработки серверами инструментов (API, функции)
3. Правила доступа к ресурсам (файлы, базы данных)

В этой архитектуре:
- Модели ИИ выступают в роли клиентов
- Внешние сервисы и источники данных — периферийные устройства (инструменты)
- MCP — стандартизированный интерфейс (порт) между ними

## Как LLM взаимодействует с MCP-сервером: пример поиска информации о погоде

Давайте разберем пример практического взаимодействия LLM с MCP-сервером на примере запроса прогноза погоды.

### 1. Архитектура взаимодействия

```
Пользователь → Клиент с LLM → MCP-клиент → MCP-сервер погоды → API прогноза погоды
```

### 2. Пошаговое взаимодействие

#### Шаг 1: Инициализация соединения
- Пользователь запускает клиентское приложение, содержащее LLM (например, чат-приложение)
- Клиент обнаруживает доступные MCP-серверы
- Происходит установка соединения между клиентом и MCP-сервером погоды
- MCP-сервер сообщает клиенту о своих возможностях (инструменты, ресурсы, промпты)

#### Шаг 2: Запрос пользователя
- Пользователь вводит: "Какая погода в Москве сегодня?"
- Клиентская LLM получает запрос и анализирует его

#### Шаг 3: Идентификация потребности в инструменте
- LLM понимает, что не имеет актуальных данных о погоде
- LLM проверяет список доступных инструментов, полученных от MCP-сервера
- LLM обнаруживает инструмент `get_forecast`, который требует координаты

#### Шаг 4: Формирование вызова инструмента
- LLM формирует запрос к инструменту: 
  ```json
  {
    "tool": "get_forecast",
    "parameters": {
      "latitude": 55.7558,
      "longitude": 37.6173
    }
  }
  ```

#### Шаг 5: Клиент передает вызов инструмента
- Клиент отправляет запрос инструмента на MCP-сервер погоды
- MCP-сервер обрабатывает запрос, преобразуя его в API-вызов к службе погоды

#### Шаг 6: Выполнение инструмента
- MCP-сервер выполняет HTTP-запрос к API погоды
- Получает JSON с данными о прогнозе
- Форматирует данные в читаемый формат

#### Шаг 7: Возврат результатов
- MCP-сервер возвращает результат клиенту:
  ```
  Сегодня:
  Температура: 22°C
  Ветер: 5 м/с Северный
  Прогноз: Переменная облачность с вероятностью осадков 30%
  
  Вечер:
  Температура: 18°C
  Ветер: 3 м/с Северо-восточный
  Прогноз: Ясно, без осадков
  ```

#### Шаг 8: Интеграция результатов в ответ LLM
- Клиентская LLM получает результат выполнения инструмента
- Интегрирует данные о прогнозе погоды в содержательный ответ
- Формирует финальный ответ пользователю: "В Москве сегодня ожидается переменная облачность с температурой около 22°C днем и 18°C вечером. Вероятность осадков 30%, ветер преимущественно северный..."

### 3. Технические детали процесса

#### Формат вызова инструмента:
```json
{
  "jsonrpc": "2.0",
  "method": "tool/call",
  "params": {
    "name": "get_forecast",
    "arguments": {
      "latitude": 55.7558,
      "longitude": 37.6173
    }
  },
  "id": 1
}
```

#### Формат ответа от MCP-сервера:
```json
{
  "jsonrpc": "2.0",
  "result": {
    "content": "Сегодня:\nТемпература: 22°C\nВетер: 5 м/с Северный\nПрогноз: Переменная облачность с вероятностью осадков 30%\n\nВечер:\nТемпература: 18°C\nВетер: 3 м/с Северо-восточный\nПрогноз: Ясно, без осадков"
  },
  "id": 1
}
```

## Как работает MCP: три основных примитива

MCP определяет три основных примитива для взаимодействия:

1. **Ресурсы (Resources)** — данные, доступные для чтения клиентом:
   - Контролируются приложением
   - Подобны GET-запросам в REST API
   - Пример: данные о предыдущих запросах прогноза погоды пользователя

2. **Инструменты (Tools)** — функции, вызываемые LLM:
   - Контролируются моделью
   - Подобны POST-запросам в REST API
   - Могут иметь побочные эффекты (сохранение данных, вызов API)
   - Пример: `get_forecast`, `get_alerts` в примере погоды

3. **Промпты (Prompts)** — шаблоны взаимодействия:
   - Контролируются пользователем
   - Предоставляют готовые шаблоны для типичных сценариев
   - Пример: шаблон "Проверить погоду в моем регионе"

## Преимущества MCP для интеграции с LLM

1. **Стандартизация** — единый протокол связи вместо множества специфичных API
2. **Развязывание компонентов** — серверы MCP работают независимо от LLM
3. **Масштабируемость** — можно добавлять новые инструменты без изменения клиента
4. **Кластеризация** — группировка связанных функций в один сервер
5. **Повторное использование** — один сервер MCP может использоваться множеством клиентов и моделей

## Реализация собственного MCP-сервера

Создать базовый MCP-сервер достаточно просто. Вот пример минимального сервера погоды на Python с использованием FastMCP:

```python
from typing import List
from mcp.server.fastmcp import FastMCP
import httpx

# Создаем MCP-сервер
mcp = FastMCP("weather-server")

@mcp.tool()
async def get_forecast(latitude: float, longitude: float) -> str:
    """
    Description:
    ---------------
        Получает прогноз погоды для указанных координат.

    Args:
    ---------------
        latitude: Широта местоположения
        longitude: Долгота местоположения

    Returns:
    ---------------
        Строка с прогнозом погоды для ближайших двух периодов

    Raises:
    ---------------
        Exception: В случае ошибки при запросе к API погоды

    Examples:
    ---------------
        >>> await get_forecast(34.05, -118.25)
        'Today: Temperature: 20°C Wind: 5 mph NW Forecast: Sunny...'
    """
    # Вызов API погоды
    async with httpx.AsyncClient() as client:
        try:
            response = await client.get(
                f"https://api.weather.gov/points/{latitude},{longitude}"
            )
            response.raise_for_status()
            points_data = response.json()

            # Получение URL прогноза
            forecast_url = points_data["properties"]["forecast"]
            forecast_response = await client.get(forecast_url)
            forecast_response.raise_for_status()
            forecast_data = forecast_response.json()

            # Форматирование прогноза
            periods = forecast_data["properties"]["periods"]
            result = []
            for period in periods[:2]:  # Показываем только 2 ближайших периода
                result.append(f"""
{period['name']}:
Температура: {period['temperature']}°{period['temperatureUnit']}
Ветер: {period['windSpeed']} {period['windDirection']}
Прогноз: {period['detailedForecast']}
                """)

            return "\n".join(result)

        except httpx.HTTPStatusError as e:
            raise Exception(f"Ошибка HTTP: {e}")
        except Exception as e:
            raise Exception(f"Ошибка при получении прогноза: {e}")

# Запуск сервера
if __name__ == "__main__":
    mcp.run()
```

## Реализация клиента для работы с MCP-сервером

Пример минимального клиента, который может взаимодействовать с MCP-сервером:

```python
import asyncio
from typing import List
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from anthropic import Anthropic

async def main() -> None:
    """
    Description:
    ---------------
        Основная функция для взаимодействия с сервером погоды и LLM.

    Args:
    ---------------
        None

    Returns:
    ---------------
        None

    Raises:
    ---------------
        Exception: В случае ошибки при взаимодействии с сервером или LLM

    Examples:
    ---------------
        >>> await main()
        'Доступные инструменты: [get_forecast] ...'
    """
    # Параметры запуска сервера
    server_params = StdioServerParameters(
        command="python",
        args=["weather_server.py"]
    )

    # Подключение к серверу
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            # Инициализация соединения
            await session.initialize()

            # Получение списка доступных инструментов
            tools = await session.list_tools()
            print(f"Доступные инструменты: {[tool.name for tool in tools.tools]}")

            # Вызов инструмента
            result = await session.call_tool(
                "get_forecast",
                {"latitude": 55.7558, "longitude": 37.6173}
            )

            # Вывод результата
            print(f"Результат: {result.content}")

            # Интеграция с LLM (в данном случае используется Claude от Anthropic)
            anthropic = Anthropic()
            response = anthropic.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=1000,
                messages=[
                    {
                        "role": "user",
                        "content": (
                            f"На основе этих данных о погоде, расскажи что "
                            f"сегодня ожидается и стоит ли брать зонт: "
                            f"{result.content}"
                        )
                    }
                ]
            )

            print(f"Ответ LLM: {response.content[0].text}")

if __name__ == "__main__":
    asyncio.run(main())
```

### Решаемые проблемы

MCP решает ключевую проблему современных моделей ИИ — ограничения их потенциала из-за изоляции данных. До появления MCP:
- Передача данных осуществлялась через ручное копирование/вставку или загрузку/скачивание
- Каждый новый источник данных требовал индивидуальной настройки и реализации
- Формировались "информационные острова", ограничивающие возможности даже самых мощных моделей

### Возможности и перспективы

MCP позволяет построить прямой "мост" между ИИ и различными источниками данных и инструментами, включая:
- Локальные файловые системы
- Интернет-ресурсы
- Инструменты разработки
- Средства автоматизации веб-сайтов и браузеров
- Системы для повышения производительности и коммуникации

При широком внедрении стандарта MCP создается возможность для реализации концепции "Интернета всего" в сфере искусственного интеллекта, обеспечивая мощные возможности для совместной работы различных систем и компонентов.

MCP призван стать промежуточным уровнем протокола, который упростит и стандартизирует разработку и интеграцию приложений ИИ, делая экосистему более открытой, гибкой и функциональной.