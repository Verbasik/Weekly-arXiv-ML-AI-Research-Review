[![arXiv](https://img.shields.io/badge/arXiv-2505.05522-b31b1b.svg)](https://arxiv.org/abs/2505.05522)
[![SakanaAI](https://img.shields.io/badge/SakanaAI-purple)](https://pub.sakana.ai/ctm/)
[![GitHub](https://img.shields.io/badge/GitHub-black)](https://github.com/SakanaAI/continuous-thought-machines/)

# Continuous Thought Machines (CTM) ‚Äî A Revolutionary Neural Architecture with Biological Inspiration

> **Neural Synchronization ‚Üí A Powerful Foundation for AI**  
> CTM demonstrates that incorporating neural temporal dynamics and synchronization into AI architecture enables a system with superior reasoning, generalization, and interpretability.

## üöÄ Key Achievements

* üß† **Architectural Revolution** ‚Äî Explicit incorporation of neural synchronization as a fundamental AI component, inspired by biological principles.
* üåê **Impressive Versatility** ‚Äî The same architecture achieves high performance across tasks ranging from image classification to maze navigation and mathematical problem solving.
* üîç **Enhanced Interpretability** ‚Äî Rich visualizations of internal representations and reasoning processes.
* ‚ö° **Adaptive Computation** ‚Äî Natural ability for the model to dynamically regulate its computational budget based on task complexity.
* üß© **Strong Generalization** ‚Äî The model successfully solves 99√ó99 mazes after training only on 39√ó39 mazes.

## Why CTM Matters?

| Problem | CTM's Solution |
| --------------------------------------------- | ----------------------------------------------- |
| Standard neural networks are limited in commonsense reasoning | Temporal dynamics enable complex sequential reasoning |
| Lack of transparency in AI internal processes | Visualizable patterns of neural activity |
| Fixed computational budgets for all tasks | Adaptive computation: more resources allocated to complex tasks |
| Limited generalization beyond training data | Robust generalization to unseen scenarios |
| Gap between AI and biological cognition | Architecture inspired by principles of brain function |

## ‚öôÔ∏è Key Architectural Components

1. **Neuron-Level Temporal Processing:**
   - Each neuron uses unique weight parameters to process the history of incoming signals
   - Replaces instantaneous activations with temporal evolution

2. **Neural Synchronization as a Hidden Representation:**
   - Information is encoded in patterns of synchronized neural activity over time
   - Rich representational space for complex information

3. **Separated Internal Time Dimension:**
   - Thought processes unfold independently of the input sequence
   - Enables iterative processing of complex tasks

4. **Adaptive Decision Making:**
   - The model makes decisions only upon reaching a confidence threshold
   - Complex examples automatically receive extended processing

## üî¨ Results

- **Image Classification:** 86.03% accuracy on CIFAR-10, outperforming both feedforward networks (84.44%) and LSTMs (85.54%)
- **Maze Navigation:** Solving shortest-path navigation in 99√ó99 mazes after training only on 39√ó39 mazes
- **Confidence Calibration:** Remarkable similarity to human confidence calibration
- **Reinforcement Learning:** Competitive performance on CartPole, Acrobot, and MiniGrid
- **Mathematical Tasks:** Development of algorithmic solutions for parity computation and sorting

---

<div align="center">

**Explore with us üöÄ**

‚≠ê Star this repository if you found it helpful

</div>