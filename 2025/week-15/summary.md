# **Как LLM выучивают факты и почему они галлюцинируют?**

## Содержание
1. [Введение](#введение)
2. [Трехфазный Процесс Обучения](#трехфазный-процесс-обучения)
3. [Нейронные Механизмы, Лежащие в Основе Фактических Знаний](#нейронные-механизмы-лежащие-в-основе-фактических-знаний)
4. [Влияние Распределения Данных](#влияние-распределения-данных)
5. [Стратегии Учебной Программы Данных](#стратегии-учебной-программы-данных)
6. [Галлюцинации и Искажение Знаний](#галлюцинации-и-искажение-знаний)
7. [Проблемы Тонкой Настройки](#проблемы-тонкой-настройки)
8. [Практические Последствия](#практические-последствия)
9. [Заключение](#заключение)

## Введение
Большие языковые модели (LLM) служат все более важными интерфейсами к человеческим знаниям, однако наше понимание того, как они приобретают, представляют и вспоминают фактическую информацию, остается ограниченным. В статье _"Как языковые модели узнают факты? Динамика, учебные программы и галлюцинации"_ исследователи из Google DeepMind и ETH Zürich предоставляют углубленный анализ динамики обучения, которая происходит, когда языковые модели приобретают фактические знания.

![Figure_2](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-15/assets/Figure_02.png)
> Figure_2. Приобретение знаний происходит в три этапа. (Слева) На очень коротком первом этапе модель изучает общую статистику значений атрибутов. На втором этапе производительность выходит на плато, соответствующее уровню, достижимому идеальной моделью без знаний об отдельных индивидах (это соответствует базовому уровню "без знаний" и почти нулевой точности распознавания). Длительность этого плато почти пропорциональна количеству индивидов (справа). Наконец, модель учится ассоциациям между субъектами и атрибутами: знания формируются по мере продолжения обучения (в центре). Результаты усреднены по 5 запускам (± стандартное отклонение).

В исследовании используются синтетические наборы данных биографий для систематического изучения того, как модели учатся связывать отдельные объекты с их атрибутами. Этот подход обеспечивает точный контроль над распределением данных и позволяет эффективно измерять приобретение знаний на протяжении всего обучения. Анализ выявляет захватывающий трехфазный процесс обучения с важными последствиями для обучения и надежности модели.

## **Трехфазный процесс обучения**

Исследователи выделяют отчетливый трехфазный процесс, посредством которого языковые модели приобретают фактические знания:

1. **Начальное Понимание Языка**: на ранних этапах обучения модель изучает общую статистику значений атрибутов, но ей не хватает знаний, специфичных для отдельных лиц;

2. **Плато Производительности**: производительность модели выходит на плато на уровне, достижимом моделью без знаний, специфичных для отдельных лиц. Эта фаза плато представляет собой критический период, когда модель создает нейронные цепи, необходимые для последующего приобретения знаний;

3. **Появление Знаний**: после плато модель быстро развивает способность связывать людей с их конкретными атрибутами, что приводит к резкому улучшению производительности припоминания фактов.

Ключевым выводом является то, что продолжительность фазы плато почти пропорциональна количеству людей в наборе данных и соответствует следующей зависимости:

```
Продолжительность_плато ≈ 0.43 × (Количество_индивидов)^0.81
```

Этот закон масштабирования указывает на то, что с увеличением числа людей модели требуется непропорционально больше шагов обучения для перехода от общего понимания языка к конкретным фактическим знаниям. Эта зависимость имеет существенное значение для обучения крупномасштабных моделей, которым необходимо запоминать огромные объемы фактической информации.

## **Нейронные механизмы, лежащие в основе фактических знаний**

Чтобы понять нейронные механизмы, лежащие в основе припоминания фактов, исследователи использовали методы attention patching, чтобы выделить компоненты, ответственные за хранение и извлечение знаний.

![Figure_3](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-15/assets/Figure_03.png)
> **Схемы внимания, поддерживающие воспроизведение, формируются во время плато потерь.**  (слева) Мы разрабатываем эксперимент с модификацией внимания, в котором делаем снимок эталонной модели на определенном этапе её обучения и используем её шаблоны внимания вместо шаблонов модифицированной модели на протяжении всего её обучения. (в центре) Чем более обучена эталонная модель, тем лучше её шаблоны внимания подходят для модифицированной модели, и эти изменения в основном происходят во время плато. Однако самое начало обучения является исключением из этой тенденции. Это коррелирует с тем, что на данном этапе обучения токены имен (по сравнению с остальным текстом, содержащим информацию о типе атрибута) получают меньше внимания при предсказании первого токена значения атрибута (см. правую панель).  

Результаты показывают, что фактические знания распределены между несколькими компонентами модели:

1. **Ранние Слой Внимания:** обрабатывают и объединяют токены имени для формирования запроса;
2. **Средние MLP-Слои:** действуют как ассоциативная память, содержащая информацию обо всех значениях атрибутов;
3. **Финальные Слой Внимания:** извлекают конкретный атрибут для запрашиваемого человека.

Это распределенное представление знаний помогает объяснить, почему модели требуется значительное обучение, прежде чем она сможет эффективно хранить и извлекать информацию, относящуюся к конкретным лицам. Паттерны внимания в модели развиваются в процессе обучения, при этом более поздние слои внимания становятся все более специализированными для извлечения знаний по мере выхода модели из фазы плато.

Исследователи обнаружили, что схемы извлечения на основе внимания начинают развиваться во время фазы плато, даже до того, как модель демонстрирует улучшенную производительность при извлечении фактической информации. Это говорит о том, что плато представляет собой критический период формирования цепей, а не период стагнации.

