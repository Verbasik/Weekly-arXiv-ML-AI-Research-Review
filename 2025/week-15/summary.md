# **Как LLM выучивают факты и почему они галлюцинируют?**

## Содержание
1. [Введение](#введение)
2. [Трехфазный Процесс Обучения](#трехфазный-процесс-обучения)
3. [Нейронные Механизмы, Лежащие в Основе Фактических Знаний](#нейронные-механизмы-лежащие-в-основе-фактических-знаний)
4. [Влияние Распределения Данных](#влияние-распределения-данных)
5. [Стратегии Учебной Программы Данных](#стратегии-учебной-программы-данных)
6. [Галлюцинации и Искажение Знаний](#галлюцинации-и-искажение-знаний)
7. [Проблемы Тонкой Настройки](#проблемы-тонкой-настройки)
8. [Практические Последствия](#практические-последствия)
9. [Заключение](#заключение)

## Введение
Большие языковые модели (LLM) служат все более важными интерфейсами к человеческим знаниям, однако наше понимание того, как они приобретают, представляют и вспоминают фактическую информацию, остается ограниченным. В статье _"Как языковые модели узнают факты? Динамика, учебные программы и галлюцинации"_ исследователи из Google DeepMind и ETH Zürich предоставляют углубленный анализ динамики обучения, которая происходит, когда языковые модели приобретают фактические знания.

![Figure_2](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-15/assets/Figure_02.png)
>Figure_2. Приобретение знаний происходит в три этапа. (Слева) На очень коротком первом этапе модель изучает общую статистику значений атрибутов. На втором этапе производительность выходит на плато, соответствующее уровню, достижимому идеальной моделью без знаний об отдельных индивидах (это соответствует базовому уровню "без знаний" и почти нулевой точности распознавания). Длительность этого плато почти пропорциональна количеству индивидов (справа). Наконец, модель учится ассоциациям между субъектами и атрибутами: знания формируются по мере продолжения обучения (в центре). Результаты усреднены по 5 запускам (± стандартное отклонение).

В исследовании используются синтетические наборы данных биографий для систематического изучения того, как модели учатся связывать отдельные объекты с их атрибутами. Этот подход обеспечивает точный контроль над распределением данных и позволяет эффективно измерять приобретение знаний на протяжении всего обучения. Анализ выявляет захватывающий трехфазный процесс обучения с важными последствиями для обучения и надежности модели.

## **Трехфазный Процесс Обучения**

Исследователи выделяют отчетливый трехфазный процесс, посредством которого языковые модели приобретают фактические знания:

1. **Начальное Понимание Языка**: на ранних этапах обучения модель изучает общую статистику значений атрибутов, но ей не хватает знаний, специфичных для отдельных лиц;

2. **Плато Производительности**: производительность модели выходит на плато на уровне, достижимом моделью без знаний, специфичных для отдельных лиц. Эта фаза плато представляет собой критический период, когда модель создает нейронные цепи, необходимые для последующего приобретения знаний;

3. **Появление Знаний**: после плато модель быстро развивает способность связывать людей с их конкретными атрибутами, что приводит к резкому улучшению производительности припоминания фактов.

Ключевым выводом является то, что продолжительность фазы плато почти пропорциональна количеству людей в наборе данных и соответствует следующей зависимости:

```
Продолжительность_плато ≈ 0.43 × (Количество_индивидов)^0.81
```

Этот закон масштабирования указывает на то, что с увеличением числа людей модели требуется непропорционально больше шагов обучения для перехода от общего понимания языка к конкретным фактическим знаниям. Эта зависимость имеет существенное значение для обучения крупномасштабных моделей, которым необходимо запоминать огромные объемы фактической информации.

