# **Как LLM выучивают факты и почему они галлюцинируют?**

## Содержание
1. [Введение](#введение)
2. [Трехфазный Процесс Обучения](#трехфазный-процесс-обучения)
3. [Нейронные Механизмы, Лежащие в Основе Фактических Знаний](#нейронные-механизмы-лежащие-в-основе-фактических-знаний)
4. [Влияние Распределения Данных](#влияние-распределения-данных)
5. [Стратегии Учебной Программы Данных](#стратегии-учебной-программы-данных)
6. [Галлюцинации и Искажение Знаний](#галлюцинации-и-искажение-знаний)
7. [Проблемы Тонкой Настройки](#проблемы-тонкой-настройки)
8. [Практические Последствия](#практические-последствия)
9. [Заключение](#заключение)

## Введение
Большие языковые модели (LLM) служат все более важными интерфейсами к человеческим знаниям, однако наше понимание того, как они приобретают, представляют и вспоминают фактическую информацию, остается ограниченным. В статье _"Как языковые модели узнают факты? Динамика, учебные программы и галлюцинации"_ исследователи из Google DeepMind и ETH Zürich предоставляют углубленный анализ динамики обучения, которая происходит, когда языковые модели приобретают фактические знания.

![Figure_2](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-15/assets/Figure_02.png)
> Figure_2. Приобретение знаний происходит в три этапа. (Слева) На очень коротком первом этапе модель изучает общую статистику значений атрибутов. На втором этапе производительность выходит на плато, соответствующее уровню, достижимому идеальной моделью без знаний об отдельных индивидах (это соответствует базовому уровню "без знаний" и почти нулевой точности распознавания). Длительность этого плато почти пропорциональна количеству индивидов (справа). Наконец, модель учится ассоциациям между субъектами и атрибутами: знания формируются по мере продолжения обучения (в центре). Результаты усреднены по 5 запускам (± стандартное отклонение).

В исследовании используются синтетические наборы данных биографий для систематического изучения того, как модели учатся связывать отдельные объекты с их атрибутами. Этот подход обеспечивает точный контроль над распределением данных и позволяет эффективно измерять приобретение знаний на протяжении всего обучения. Анализ выявляет захватывающий трехфазный процесс обучения с важными последствиями для обучения и надежности модели.

## **Трехфазный процесс обучения**

Исследователи выделяют отчетливый трехфазный процесс, посредством которого языковые модели приобретают фактические знания:

1. **Начальное Понимание Языка**: на ранних этапах обучения модель изучает общую статистику значений атрибутов, но ей не хватает знаний, специфичных для отдельных лиц;

2. **Плато Производительности**: производительность модели выходит на плато на уровне, достижимом моделью без знаний, специфичных для отдельных лиц. Эта фаза плато представляет собой критический период, когда модель создает нейронные цепи, необходимые для последующего приобретения знаний;

3. **Появление Знаний**: после плато модель быстро развивает способность связывать людей с их конкретными атрибутами, что приводит к резкому улучшению производительности припоминания фактов.

Ключевым выводом является то, что продолжительность фазы плато почти пропорциональна количеству людей в наборе данных и соответствует следующей зависимости:

```
Продолжительность_плато ≈ 0.43 × (Количество_индивидов)^0.81
```

Этот закон масштабирования указывает на то, что с увеличением числа людей модели требуется непропорционально больше шагов обучения для перехода от общего понимания языка к конкретным фактическим знаниям. Эта зависимость имеет существенное значение для обучения крупномасштабных моделей, которым необходимо запоминать огромные объемы фактической информации.

## **Нейронные механизмы, лежащие в основе фактических знаний**

Чтобы понять нейронные механизмы, лежащие в основе припоминания фактов, исследователи использовали методы attention patching, чтобы выделить компоненты, ответственные за хранение и извлечение знаний.

![Figure_3](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-15/assets/Figure_03.png)
> **Схемы внимания, поддерживающие воспроизведение, формируются во время плато потерь.**  (слева) Мы разрабатываем эксперимент с модификацией внимания, в котором делаем снимок эталонной модели на определенном этапе её обучения и используем её шаблоны внимания вместо шаблонов модифицированной модели на протяжении всего её обучения. (в центре) Чем более обучена эталонная модель, тем лучше её шаблоны внимания подходят для модифицированной модели, и эти изменения в основном происходят во время плато. Однако самое начало обучения является исключением из этой тенденции. Это коррелирует с тем, что на данном этапе обучения токены имен (по сравнению с остальным текстом, содержащим информацию о типе атрибута) получают меньше внимания при предсказании первого токена значения атрибута (см. правую панель).  

Результаты показывают, что фактические знания распределены между несколькими компонентами модели:

1. **Ранние Слой Внимания:** обрабатывают и объединяют токены имени для формирования запроса;
2. **Средние MLP-Слои:** действуют как ассоциативная память, содержащая информацию обо всех значениях атрибутов;
3. **Финальные Слои Внимания:** извлекают конкретный атрибут для запрашиваемого человека.

Это распределенное представление знаний помогает объяснить, почему модели требуется значительное обучение, прежде чем она сможет эффективно хранить и извлекать информацию, относящуюся к конкретным лицам. Паттерны внимания в модели развиваются в процессе обучения, при этом более поздние слои внимания становятся все более специализированными для извлечения знаний по мере выхода модели из фазы плато.

Исследователи обнаружили, что схемы извлечения на основе внимания начинают развиваться во время фазы плато, даже до того, как модель демонстрирует улучшенную производительность при извлечении фактической информации. Это говорит о том, что плато представляет собой критический период формирования цепей, а не период стагнации.

## **Эффекты распределения данных**

Исследование показывает, что распределение индивидуумов в обучающих данных существенно влияет на то, как быстро и эффективно модели усваивают фактические знания.

![Figure H](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-15/assets/Figure_06.png)
> Кривые обучения для распределения "знаменитостей", полученные при 8k шагах обучения и 64k индивидов. На левом графике вес для знаменитостей установлен в 8, а на правом графике количество знаменитостей установлено в 4k.

Когда обучающие данные содержат несбалансированные частоты индивидуумов (например, распределение Ципфа или распределение "знаменитостей", когда некоторые индивидуумы встречаются чаще), возникают несколько эффектов:

1. Фаза плато сокращается для часто встречающихся индивидуумов;
2. Модель усваивает факты о высокочастотных индивидуумах раньше, чем о низкочастотных;
3. Однако высокочастотные индивидуумы могут привести к переобучению, когда модель хорошо работает на обучающих данных, но плохо на новых примерах.

Этот анализ показывает, что существует фундаментальный компромисс в приобретении фактических знаний: ускорение обучения за счет несбалансированного распределения данных может повысить эффективность, но потенциально снизить обобщение на новые факты или индивидуумов.

## **Стратегии учебной программы данных**

Основываясь на информации, полученной из эффектов распределения данных, исследователи изучили различные стратегии учебной программы данных для оптимизации приобретения фактических знаний.

![Figure I](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-15/assets/Figure_07.png)
> Кривые обучения для распределения "разогрева", полученные при 8k шагах обучения и 64k индивидов. На левом графике количество шагов разогрева установлено в 1,5k, а на правом графике количество индивидов разогрева установлено в 8k.

Особенно эффективным подходом является учебная программа "разминки", в которой:

1. Модель изначально обучается на небольшом подмножестве индивидуумов с высокой частотой;
2. После этого периода разминки обучение продолжается на полном наборе данных с равномерным распределением.

Эта двухэтапная учебная программа значительно ускоряет переход модели через фазу плато, сохраняя при этом хорошую производительность обобщения. Исследователи систематически исследовали различные комбинации индивидуумов для разминки и шагов разминки, находя оптимальные конфигурации, которые уравновешивают эффективность обучения с итоговой производительностью модели.

Данные показывают, что лучшие учебные программы включают умеренное количество индивидуумов для разминки (приблизительно 8-16 тысяч индивидуумов для набора данных из 64 тысяч индивидуумов) и умеренное количество шагов разминки (приблизительно 1-2 тысячи шагов). Слишком малое или слишком большое количество индивидуумов/шагов для разминки приводит к субоптимальной производительности.

![Figure K](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-15/assets/Figure_08.png)
> Визуализация того, как меняется итоговая производительность при изменении гиперпараметров начального распределения (warm-up). Общее количество индивидуумов фиксировано на уровне 64 тысяч, и эти графики соответствуют рисунку J (в центре справа и справа).

## **Галлюцинации и искажение знаний**

Одним из наиболее тревожных аспектов языковых моделей является их склонность к галлюцинациям - выдаче неверной информации с высокой уверенностью. Исследование предоставляет важную информацию об этом явлении.

![Figure M](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-15/assets/Figure_09.png)
> Модель начинает галлюцинировать во время обучения. Синяя линия соответствует производительности модели на знакомых индивидуумах (как и в других частях статьи), а фиолетовая — её производительности на 16 тысячах отложенных индивидуумов. (слева) потеря атрибутов, (слева посередине) точность знаний, (справа посередине) средняя вероятность наиболее вероятного предсказанного токена (для значений атрибутов), и (справа) средняя энтропия предсказательного распределения (для значений атрибутов). В целом, модель менее уверена в своих галлюцинациях, чем в обоснованных предсказаниях.

Исследователи обнаружили, что галлюцинации возникают одновременно с приобретением знаний во время перехода от фазы плато. Когда модели предъявляют неизвестных индивидуумов (не встречавшихся во время обучения), ее поведение следует определенной схеме:

1. Изначально модель правильно указывает на неопределенность, выдавая прогнозы с низкой степенью уверенности;
2. По мере того, как модель учится ассоциировать известных людей с атрибутами, у нее одновременно развивается тенденция уверенно генерировать неправильные атрибуты для неизвестных людей;
3. Это проявляется в виде более высоких максимальных вероятностных выходных данных и более низких энтропийных распределений для неизвестных людей, что указывает на увеличение (но неуместной) уверенности.

Этот вывод предполагает, что нейронные механизмы, отвечающие за фактическое воспроизведение и галлюцинации, неразрывно связаны, что представляет собой фундаментальную проблему для разработки правдивых языковых моделей.

## **Проблемы тонкой настройки**

В исследовании также изучаются проблемы включения новых знаний посредством тонкой настройки, выявляющие серьезные ограничения в том, как модели адаптируются к новой информации.

![Figure N](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-15/assets/Figure_10.png)
> Эволюция производительности модели на распределении предобучения (левая и средняя левая панели) и на распределении дообучения (средняя правая и правая панели) по мере прогресса дообучения. В первой строке во время дообучения не используется повторение данных предобучения, и мы варьируем количество индивидуумов для дообучения. Во второй строке, полученной для 4 тысяч индивидуумов дообучения, мы вводим некоторое повторение и варьируем его вес (вес соответствует тому, насколько больше вероятность выборки индивидуума из предобучения по сравнению с одним из набора дообучения). Данные, представленные здесь, те же, что и на рисунке 5 (средняя и правая панели), но здесь они построены как функция времени и включают точность.

Когда обученная модель подвергается тонкой настройке на новых людях, возникает несколько проблем:

1. Искажение знаний: Тонкая настройка на новых людях быстро искажает существующие воспоминания, при этом производительность предварительно обученных людей быстро ухудшается;
2. Уязвимость прямого слоя: Ассоциативные воспоминания, хранящиеся в прямых слоях, особенно восприимчивы к искажению во время тонкой настройки;
3. Стабильность паттернов внимания: Паттерны внимания остаются относительно стабильными во время тонкой настройки, что говорит о том, что механизм извлечения знаний сохраняется, в то время как фактическое хранилище памяти искажается.

Это нарушение памяти представляет собой серьезную проблему для языковых моделей, которые необходимо постоянно обновлять новой информацией, не теряя существующих знаний. Компромисс между изучением новых фактов и сохранением старых представляется фундаментальным для современных архитектур нейронных сетей.

## **Практические последствия**

Выводы имеют несколько важных практических последствий для разработки LLM:

1. Эффективность обучения: стратегии учебной программы данных, особенно подходы к разогреву, могут значительно сократить время обучения и вычислительные требования для крупномасштабных моделей;
2. Масштабирование модели: закон масштабирования плато предоставляет рекомендации по оценке вычислительных ресурсов, необходимых по мере обучения моделей на все более крупных наборах данных;
3. Смягчение галлюцинаций: понимание связи между приобретением знаний и развитием галлюцинаций может помочь исследователям разрабатывать целевые вмешательства для уменьшения ложных выходных данных;
4. Непрерывное обучение: выявленные проблемы в тонкой настройке предполагают, что для эффективного обновления знаний могут потребоваться альтернативные подходы, такие как методы разреженной тонкой настройки или архитектурные модификации;
5. Оценка модели: трехфазный процесс обучения подчеркивает важность оценки моделей на протяжении всего обучения, а не только в конечной точке, поскольку производительность может кардинально измениться во время переходов между фазами.

## **Вывод**

Это исследование предоставляет основу для понимания того, как языковые модели изучают, хранят и извлекают фактические знания. Выявление трехфазного процесса обучения и задействованных нейронных механизмов предлагает ценные сведения как о возможностях, так и об ограничениях современных языковых моделей.

Выводы предлагают несколько направлений для будущих исследований, включая:

1. Разработка более эффективных учебных программ на основе выявленной динамики обучения;
2. Разработка архитектурных модификаций для лучшего отделения приобретения знаний от развития галлюцинаций;
3. Создание подходов тонкой настройки, которые могут включать новые знания с минимальным искажением существующих воспоминаний;
4. Изучение связей между масштабом модели, размером набора данных и продолжительностью плато для более крупных моделей.

Понимание этих фундаментальных принципов обучения имеет решающее значение для разработки более способных, эффективных и правдивых языковых моделей, которые могут служить надежным интерфейсом для человеческих знаний. Это исследование представляет собой значительный шаг на пути к механистическим объяснениям поведения языковых моделей, выходя за рамки оценок типа "черный ящик" и углубляясь в понимание того, как эти все более важные системы учатся и работают.