# **Как LLM выучивают факты: Динамика, запоминание, галлюцинации. Новое исследование от Google DeepMind**

## **1. Введение**

### **Ключевая проблема**: 

Несмотря на то, что крупные языковые модели (LLM) в ходе предварительного обучения усваивают огромный объем фактических знаний, внутренние механизмы того, как они изучают, хранят и применяют эти знания, остаются «черным ящиком». Раскрытие этих механизмов критически важно не только для оптимизации обучения моделей, но и для понимания и решения таких ключевых проблем, как «галлюцинации» и трудности обновления знаний после предварительного обучения.  

### **Методология исследования**: 

Для системного изучения этой проблемы в данной статье разработана контролируемая экспериментальная методика. Вместо использования сложных реальных текстов исследователи создали синтетическую задачу на воспроизведение фактов (factual recall), основанную на искусственных биографиях. Такой синтетический подход позволяет точно контролировать свойства данных и эффективно отслеживать процесс усвоения знаний на всех этапах обучения.  

### **Ключевые выводы вкратце**:  

1. **Этапное обучение**: Знания усваиваются не линейно. Модель демонстрирует три уникальные фазы изучения фактов, включая критический «плато-период», когда производительность кажется застывшей, но внутри формируются механизмы представления.  
2. **Важность распределения данных**: Статистические свойства обучающих данных, особенно частотное распределение упоминаний разных «индивидуумов», существенно влияют на скорость и динамику обучения, в том числе на длительность плато-периода.  
3. **Сосуществование галлюцинаций и знаний**: Склонность модели к «галлюцинациям» (генерации информации о несуществующих объектах) проявляется почти одновременно с процессом усвоения реальных фактов.  
4. **Сложности дообучения**: Интеграция новых знаний в уже обученную модель через дообучение (fine-tuning) оказывается крайне трудной и часто приводит к быстрому разрушению существующей параметрической памяти (т.н. «катастрофическому забыванию»).

## **2. Отслеживание получения знаний: детали экспериментальной среды**

**Ключевой вопрос:**  
При изучении того, как LLM усваивают факты, мы сталкиваемся с двумя методологическими проблемами:

1. **Отделение знаний:**  
   Как измерить степень владения моделью фактическими знаниями, отделив их от других языковых способностей (грамматика, беглость и т.д.)?

2. **Эффективность и масштабируемость оценки:**  
   Как непрерывно отслеживать уровень знаний в процессе обучения, избегая дорогостоящих комплексных оценок (например, QA-тестов) на каждом этапе?

**Интуиция и общий подход:**  
Идеальная экспериментальная среда должна обладать следующими характеристиками:
- Факты дискретны и атомарны;
- Успех задачи напрямую зависит от воспроизведения конкретных пар "сущность-атрибут";
- Процесс генерации данных контролируем для регистрации статистических свойств;
- Оценка знаний интегрирована в стандартный процесс обучения.

Это естественным образом приводит к использованию структурированных синтетических данных для задач воспроизведения фактов.

### 2.1 Знания vs. Память: ключевое различие

Для точного понимания поведения модели необходимо различать **"знания"** и **"память"**:

| Концепт  | Определение                                                                 | Характеристики                          | Пример (знание "Париж — столица Франции")              |
|----------|-----------------------------------------------------------------------------|-----------------------------------------|-------------------------------------------------------|
| Знания   | Информация, усвоенная моделью, независимая от формы ввода и гибко применяемая | Абстрактность, обобщение, гибкость     | Ответы на вопросы: "Столица Франции?", "Какой стране принадлежит Париж?" |
| Память   | Воспроизведение конкретных примеров обучения, привязанное к форме ввода      | Конкретность, хрупкость                | Завершение предложения: "Париж — это ___ Франции"      |

### 2.2 Синтетический биографический набор данных

**Преимущества дизайна:**
- **Атомарность:** каждый факт (например, место рождения) независим, что отделяет способность "вспоминать" от способности "рассуждать";
- **Синтетичность и контроль:** точный контроль распределения данных (например, частоты появления персонажей) без помех из реальных корпусов;
- **Реалистичная статистика:** использование распространенных имен и мест сохраняет естественное распределение токенов;
- **Релевантность предыдущих исследований:** малые модели на подобных данных демонстрируют механизмы хранения знаний, сравнимые с большими LLM.

**Процесс генерации:**
1. **Создание базы персонажей:** Генерация N виртуальных "персонажей" с уникальными именами и шестью атрибутами;
2. **Заполнение шаблонов:** Для каждого атрибута случайно выбирается шаблон из библиотеки (25 вариантов на тип атрибута), куда подставляется конкретная информация (например, "[Имя] родился в [Место рождения]");
   - *Ключевой момент:* Множество шаблонов создает текстовое разнообразие, вынуждая модель выйти за рамки простого запоминания
3. **Сборка биографии:** Случайное упорядочивание предложений с атрибутами в полную биографи;
   - *Ключевой момент:* Случайный порядок предотвращает использование моделью последовательностных подсказок
4. **Разделение на обучающую/оценочную выборки:** Для каждого персонажа 20 шаблонов идут в обучение, 5 — в оценку. Это гарантирует, что модель сталкивается с новыми формулировками известных фактов, тестируя уровень абстракции знаний.

![Figure_1](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-15/assets/Figure_01.png)
> Figure_1. Процесс генерации данных, лежащий в основе синтетического набора биографий, на котором мы обучаем модели. Мы измеряем знания, содержащиеся в этих моделях, через величину потерь (loss), которую они достигают при предсказании атрибутных токенов (выделены синим).*

### 2.3 Масштабное измерение знаний: потери и точность атрибутов

**Проблема:** Многократные QA-оценки в процессе обучения требуют больших вычислений  
**Решение:** Специальная структура биографий превращает предсказание значений атрибутов в задачу воспроизведения фактов  

### 2.4 Стандартизированные модели и обучение

Для обеспечения воспроизводимости результатов:

- **Архитектура:** 8-слойный Decoder-only Transformer (44M параметров, на основе Hoffmann et al., 2022)
- **Оптимизатор:** AdamW с косинусным затуханием learning rate (без warmup)
- **Learning rate:** Настраивается индивидуально для каждого эксперимента

## **3. Динамический процесс приобретения знаний о языковой модели**

Основной вопрос: теперь, когда у нас есть способ измерения знаний, какова фактическая динамика приобретения знаний в ходе обучения ? Является ли это плавным, постепенным процессом или наблюдаются явные фазовые изменения и потенциальные сдвиги механизмов?

Основные выводы: Исследование показало, что независимо от того, как изменяются гиперпараметры, приобретение знаний обычно происходит по трехэтапной схеме . Среди них, казалось бы, «застойный» период плато играет решающую роль на уровне механизма.

## **3.1 Трехэтапная модель приобретения знаний**

![Figure_2](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-15/assets/Figure_02.png)
> Figure_2. Приобретение знаний происходит в три этапа. (Слева) На очень коротком первом этапе модель изучает общую статистику значений атрибутов. На втором этапе производительность выходит на плато, соответствующее уровню, достижимому идеальной моделью без знаний об отдельных индивидах (это соответствует базовому уровню "без знаний" и почти нулевой точности распознавания). Длительность этого плато почти пропорциональна количеству индивидов (справа). Наконец, модель учится ассоциациям между субъектами и атрибутами: знания формируются по мере продолжения обучения (в центре). Результаты усреднены по 5 запускам (± стандартное отклонение).

Исследователи стабильно выявили следующие три этапа, наблюдая за кривыми изменения потерь атрибутов (Attribute Loss) и точности атрибутов (Attribute Accuracy) в процессе обучения:

### Перевод таблицы на русский язык:

| Этап | Название               | Основное поведение                          | Объяснение и механизм                                                                 |
|------|------------------------|---------------------------------------------|---------------------------------------------------------------------------------------|
| 1    | Начальное понимание / Статистическое обучение | Быстрое снижение потерь атрибутов.          | Модель быстро усваивает поверхностные статистические данные, такие как частые значения атрибутов, структуру биографии и т.д. К концу этапа производительность достигает уровня **базовой линии без знаний**. Модель понимает типы информации, но не связывает их с конкретными индивидуумами. |
| 2    | Плато производительности ("Грань усвоения знаний") | Потери атрибутов остаются на уровне **базовой линии без знаний**; точность атрибутов близка к 0. | Почему возникает застой? Две возможные причины: <br> (1) **Оптимизация**: модель попадает в седловую точку или локальный минимум функции потерь. <br> (2) **Статистика (√)**: модели требуется многократно наблюдать одного и того же индивидуума (несмотря на разное описание), чтобы надежно выделить факты, специфичные для него, из статистического шума. <br> **Доказательство**: длина плато линейно зависит от количества индивидуумов \( N \) (\( \text{Плато} \propto N^{0.81} \), рис. 2 справа), что сильно поддерживает статистическую гипотезу. |
| 3    | Проявление знаний (Knowledge Emergence) | Потери атрибутов становятся значительно ниже **базовой линии без знаний**; точность атрибутов стабильно превышает 0. | На этом этапе модель активно формирует и укрепляет связи между **именем индивидуума** и его **специфическими атрибутами**. Параметризованные знания сохраняются и успешно извлекаются. |

Устойчивость модели: Эта трехэтапная модель стабильно сохраняется при изменении скорости обучения (learning rate), весового затухания (weight decay), размера пакета (batch size), количества индивидуумов, размера модели и даже при замене механизма внимания на рекуррентную сеть (разновидность RNN).

### **Связь с полным циклом обучения языковых моделей**

Понимание трехэтапной модели приобретения знаний помогает переосмыслить весь процесс обучения современных LLM. Рассмотрим, как эти три этапа соотносятся с традиционными фазами обучения языковых моделей:

<details> 
    <summary><em><strong>Полный цикл обучения современных LLM</strong></em></summary>

---

Обучение современных больших языковых моделей — это сложный, многоэтапный и ресурсоемкий процесс. Он включает в себя несколько фаз, каждая из которых преследует свою цель: от формирования базового понимания языка до тонкой настройки поведения модели в соответствии с человеческими ожиданиями. Давайте разберем этот цикл по шагам.

**Полный цикл обучения LLM**

1.  **Подготовка данных**
2.  **Pre-training (Предварительное обучение)**
3.  **Supervised Fine-Tuning (SFT) / Instruction Fine-Tuning**
4.  **Reinforcement Learning from Human Feedback (RLHF)**
5.  **Оценка и Развертывание**

![Этапы обучения LLM](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-15/assets/Image_01.jpeg)
> Этапы обучения LLM

---

<details> 
    <summary><em><strong>Этап 1. Подготовка данных</strong></em></summary>

## **Этап 1. Подготовка данных**

### **1.1 Концептуальные основы подготовки данных**

Качество и количество данных представляют собой фундаментальную основу для функционирования крупномасштабных языковых моделей (Large Language Models, LLM). Процесс подготовки данных для предварительного обучения следует рассматривать как многоаспектную задачу, стратегические направления которой формируются в значительной степени под влиянием современных исследований в области масштабирования нейронных архитектур. Комплексный характер данной задачи обусловлен необходимостью обеспечения оптимального баланса между объемом данных, их качеством и вычислительными ресурсами, доступными для обучения модели.

## **2. Систематизация процессов сбора и обработки данных**

### **2.1. Методы аккумуляции текстовых корпусов**

В современной практике разработки LLM аккумуляция данных осуществляется посредством интеграции масштабных текстовых корпусов из разнообразных источников, включая:
* интернет-ресурсы (преимущественно Common Crawl);
* литературные источники (коллекции Project Gutenberg, Google Books);
* научные публикации (репозиторий arXiv);
* программный код (GitHub);
* диалогические корпусы;
* медийные публикации.

Объемы используемых данных в современных проектах исчисляются терабайтами текстовой информации, что соответствует триллионам токенизированных элементов. Данная количественная характеристика обусловлена эмпирически установленными закономерностями масштабирования языковых моделей.

### **2.2. Теоретические и практические аспекты законов масштабирования (Chinchilla Scaling Laws)**

Стратегия сбора данных и планирования обучающего процесса находится в тесной взаимосвязи с эмпирическими законами масштабирования. Исследование DeepMind "Chinchilla" (2022) установило, что для достижения оптимальных показателей производительности модели при фиксированном вычислительном бюджете (FLOPs) необходимо обеспечить сбалансированное соотношение между размером модели (количество параметров, $N$) и объемом обучающих данных (количество токенов, $D$).

#### **2.2.1. Статистические закономерности и их интерпретация**
Согласно закономерностям Chinchilla, оптимальное соотношение выражается как $D \approx 20 \times N$, что указывает на необходимость обеспечения примерно 20 токенов обучающих данных на каждый параметр модели. Данная пропорция основана на эмпирических наблюдениях и статистическом анализе эффективности различных конфигураций моделей.

#### **2.2.2. Практическая значимость исследования в контексте развития LLM**
Открытие, сделанное в рамках проекта Chinchilla, продемонстрировало, что предшествующие крупномасштабные модели (включая GPT-3 и Gopher) характеризовались субоптимальным соотношением объема обучающих данных к размеру модели. В частности, модель Chinchilla (70 миллиардов параметров), обученная на 1,4 триллиона токенов (соотношение ~20:1), продемонстрировала превосходящие показатели по сравнению с более параметризованной моделью Gopher (280 миллиардов параметров), обученной на 300 миллиардах токенов (соотношение ~1:1).

#### **2.2.3. Методологические импликации для подготовки данных**
Установленные закономерности подчеркивают критическую важность не только увеличения параметрической размерности модели, но и опережающего наращивания объема качественных обучающих данных. Данный вывод стимулирует интенсификацию усилий исследовательского сообщества по сбору, фильтрации и обработке триллионов токенов текстовой информации с целью максимизации эффективности использования вычислительных ресурсов при обучении современных LLM.

### **2.3. Методология очистки и нормализации данных**

Процесс очистки данных представляет собой критически важный этап, оказывающий непосредственное влияние на качественные характеристики и безопасность модели. Данный процесс включает следующие компоненты:

* **Удаление дубликатов** на уровне документов и предложений с целью повышения разнообразия данных и предотвращения эффекта переобучения на повторяющихся паттернах.

* **Фильтрация низкокачественного контента**, включая спам, шаблонные тексты и автоматически генерируемую информацию. Данная процедура направлена на повышение общего качества корпуса и снижение риска обучения модели на нерелевантных или малоинформативных данных.

* **Обработка персональных данных** посредством удаления или анонимизации персональной идентифицирующей информации (PII) для обеспечения соответствия нормативам приватности и защиты данных.

* **Фильтрация нежелательного контента**, включая токсичные, предвзятые или потенциально вредоносные материалы. Данная задача представляет собой комплексную проблему, требующую применения как автоматизированных алгоритмов, так и методов ручной модерации.

* **Нормализация текстового материала**, которая может включать стандартизацию регистра, обработку пунктуации, унификацию пробельных символов. При этом следует отметить, что современные архитектуры часто демонстрируют повышенную эффективность при работе с текстом, максимально приближенным к исходной форме, сохраняющим оригинальный регистр и пунктуацию.

### **2.4. Алгоритмические подходы к токенизации текстовых данных**

Токенизация представляет собой процесс декомпозиции текста на элементарные единицы — токены, подлежащие обработке моделью. В контексте современных LLM преимущественно используются субсловные токенизаторы (subword tokenizers), среди которых можно выделить следующие:

* **Byte Pair Encoding (BPE)**: Алгоритм, начинающий процесс с отдельных символов (или байтов) и итеративно объединяющий наиболее частотные пары в новые токены словаря. Данный метод обеспечивает эффективное балансирование между размером словаря и способностью моделировать редкие слова.

* **WordPiece**: Метод, методологически близкий к BPE, но отличающийся критерием объединения пар, который заключается в максимизации правдоподобия данных обучения при заданной модели токенизации. Данный алгоритм нашел применение в моделях BERT и других разработках Google.

* **SentencePiece**: Токенизатор, осуществляющий обработку текста как последовательности Unicode-символов без предварительной сегментации по словам. Данная особенность обеспечивает универсальность применения для различных языковых систем, что особенно актуально в контексте многоязычных моделей. SentencePiece активно используется в современных архитектурах, включая Llama и серию GPT.

#### **2.4.1. Иллюстративный пример и функциональный анализ токенизации**

В качестве примера рассмотрим процесс токенизации слова "масштабирование", которое может быть сегментировано на токены вида `[" мас", "штаб", "ирование"]` или `[" масштаб", "ирован", "ие"]`. Данный механизм обеспечивает модели следующие функциональные возможности:

1. **Обработка неизвестной лексики**: Способность анализировать и генерировать незнакомые или редкие слова посредством их композиции из известных сегментов, что существенно повышает гибкость модели при работе с открытым словарем.

2. **Оптимизация размера словаря**: Возможность эффективного управления размерностью словаря (обычно в диапазоне от 30 до 100 тысяч токенов), что было бы невозможно при использовании целых слов в качестве базовых единиц токенизации.

## **3. Выводы**

Законы масштабирования Chinchilla представляют собой значимый методологический ориентир на этапе подготовки данных, определяя целевые объемы текстовых корпусов в зависимости от планируемой параметрической размерности модели и доступных вычислительных ресурсов. Данные закономерности подчеркивают, что эффективность LLM определяется не исключительно архитектурными и алгоритмическими аспектами обучения, но и в существенной степени стратегическими подходами к работе с данными.

В контексте современных исследований в области искусственного интеллекта и, в частности, обработки естественного языка, глубокое понимание взаимосвязи между характеристиками обучающих данных и производительностью модели представляется фундаментальным для дальнейшего прогресса в разработке все более совершенных языковых моделей. Стратегическое планирование процессов сбора и обработки данных, основанное на эмпирически установленных закономерностях, становится одним из ключевых факторов, определяющих успешность проектов в области разработки крупномасштабных языковых моделей.

</details> 

<details> 
    <summary><em><strong>Этап 2. Pre-training (Предварительное обучение)</strong></em></summary>

## **2. Pre-training (Предварительное обучение)**

### **2.1. Концептуальная характеристика этапа предварительного обучения**

Предварительное обучение (pre-training) представляет собой наиболее вычислительно интенсивный этап в разработке крупномасштабных языковых моделей, в ходе которого осуществляется формирование базового понимания моделью статистических и семантических закономерностей языка. Этот процесс требует значительных вычислительных ресурсов и имеет определяющее значение для функциональных возможностей модели.

Основная целевая задача предварительного обучения заключается в формировании способности модели прогнозировать следующий токен в последовательности на основе контекста предыдущих токенов. Данный подход позволяет модели усваивать грамматические структуры, фактологическую информацию, основы логических взаимосвязей и определенные аспекты рассуждений, представленные в масштабных текстовых корпусах. Процесс обучения основывается на выявлении статистических закономерностей в последовательностях токенов, что обеспечивает формирование обобщенных репрезентаций языковых структур без необходимости в явной аннотации данных.

### **2.2. Архитектурные компоненты современных языковых моделей**

В настоящее время доминирующей архитектурой в области крупномасштабных языковых моделей является архитектура Transformer, представленная в исследовании "Attention Is All You Need" (Vaswani et al., 2017).

На рисунке ниже, изображена архитектура модели Transformer. Она состоит из двух основных частей: **кодера (encoder)** и **декодера (decoder)**.

![Figure_1](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-04/assets/Figure_1.png)

### Кодер (Encoder)
Кодер обычно находится в левой части архитектуры. Он состоит из нескольких слоев, каждый из которых включает:
1. **Multi-Head Attention** — механизм внимания, который позволяет модели фокусироваться на разных частях входных данных.
2. **Add & Norm** — слой, который добавляет входные данные к результату внимания (residual connection) и применяет нормализацию.
3. **Feed Forward** — полносвязный слой, который применяется к каждому элементу последовательности независимо.
4. **Add & Norm** — снова добавляет входные данные к результату и нормализует.

Эти слои повторяются несколько раз (обычно 6 или более) для создания глубокой модели.

### Декодер (Decoder)
Декодер обычно находится в правой части архитектуры. Он также состоит из нескольких слоев, но имеет дополнительные компоненты:
1. **Masked Multi-Head Attention** — механизм внимания, который маскирует будущие токены, чтобы предотвратить "подглядывание" вперед.
2. **Add & Norm** — слой, который добавляет входные данные к результату внимания и нормализует.
3. **Multi-Head Attention** — механизм внимания, который учитывает выход кодера.
4. **Add & Norm** — снова добавляет входные данные к результату и нормализует.
5. **Feed Forward** — полносвязный слой, аналогичный тому, что используется в кодировщике.
6. **Add & Norm** — завершающий слой добавления и нормализации.

### Входы и выходы
- **Input Embedding** и **Positional Encoding** относятся к входным данным, которые подаются в кодер.
- **Output Embedding** и **Outputs (shifted right)** относятся к выходным данным, которые обрабатываются декодером.

### **2.3. Методология процесса обучения**

#### **2.3.1. Формулировка задачи предварительного обучения**

В контексте крупномасштабных языковых моделей основной задачей предварительного обучения является причинное языковое моделирование (Causal Language Modeling, CLM), заключающееся в последовательном предсказании токенов. Модель получает на вход последовательность токенов $t_1, t_2, ..., t_{k-1}$ и оптимизируется для предсказания следующего токена $t_k$. Эта формулировка задачи позволяет модели осваивать широкий спектр языковых закономерностей без необходимости в специфической разметке данных.

#### **2.3.2. Функция потерь и её обоснование**

В качестве целевой функции оптимизации используется кросс-энтропийная функция потерь (Cross-Entropy Loss), которая количественно оценивает расхождение между предсказанным моделью распределением вероятностей следующего токена и фактическим распределением, представленным истинным следующим токеном.

Математически для последовательности $T = (t_1, ..., t_L)$ функция потерь выражается как:

$$L_{Pretrain}(\theta) = - \sum_{i=1}^{L} \log P(t_i | t_{1}, ..., t_{i-1}; \theta)$$

где: 

- $\theta$ — параметры модели
- $P(t_i | t_{1}, ..., t_{i-1}; \theta)$ — вероятность $i$-го токена, предсказанная моделью на основе предшествующих токенов. 
В практических реализациях вычисление проводится по батчам последовательностей.

Содержательная интерпретация данной функции заключается в том, что модель штрафуется при присвоении низкой вероятности токену, который фактически следует за предшествующей последовательностью в обучающем тексте. Минимизация этой функции стимулирует модель к более точному предсказанию текстовых последовательностей, что приводит к усвоению структурных и семантических закономерностей языка.

#### **2.3.3. Оптимизационные алгоритмы**

В процессе предварительного обучения крупномасштабных языковых моделей преимущественно используются адаптивные алгоритмы оптимизации, такие как Adam (Adaptive Moment Estimation) или его модификация AdamW, характеризующаяся усовершенствованным механизмом регуляризации весов. Ключевым гиперпараметром оптимизационного процесса является скорость обучения (learning rate), определяющая величину обновления параметров на каждой итерации.

#### **2.3.4. Стратегии управления скоростью обучения**

Процесс обучения обычно начинается с низких значений скорости обучения, которая постепенно увеличивается до максимального значения в течение начальных нескольких тысяч итераций (фаза разогрева, warmup). Этот подход способствует стабилизации процесса обучения на начальных этапах. После фазы разогрева скорость обучения постепенно снижается согласно определенному расписанию (например, косинусоидальному), что способствует более точной сходимости модели к оптимуму.

Математическая формулировка фазы разогрева представляется следующим образом:

$$lr(step) = lr_{max} \times \frac{step}{warmup\_steps}$$ 

для $step \leq warmup\_steps$

где: 

- $lr(step)$ — скорость обучения на итерации $step$ 
- $lr_{max}$ — максимальное значение скорости обучения
- $warmup\_steps$ — количество итераций фазы разогрева. На этом этапе скорость обучения линейно возрастает от почти нулевого значения до максимального, что обеспечивает плавное начало процесса оптимизации.

### **2.4. Вычислительные аспекты и стратегии масштабирования**

Предварительное обучение крупномасштабных языковых моделей требует значительных вычислительных ресурсов, включая сотни или тысячи графических (GPU) или тензорных (TPU) процессоров, функционирующих в течение продолжительного времени. Для обеспечения эффективности процесса обучения применяются следующие стратегии распределенного обучения:

* **Параллелизм данных (Data Parallelism)**: Предполагает распределение различных батчей данных между вычислительными устройствами, каждое из которых содержит полную копию модели. После обработки батчей вычисляется средний градиент, который используется для обновления параметров на всех устройствах.

* **Тензорный параллелизм (Tensor Parallelism)**: Обеспечивает распределение отдельных тензоров (матриц весов) между устройствами, что особенно эффективно для моделей, превышающих объем памяти одного устройства. Этот подход позволяет обрабатывать значительно более крупные модели, чем было бы возможно на одном устройстве.

* **Конвейерный параллелизм (Pipeline Parallelism)**: Предполагает распределение различных слоев модели между устройствами с организацией конвейерной обработки последовательных микро-батчей, что обеспечивает эффективное использование вычислительных ресурсов при обучении глубоких архитектур.

## **3. Выводы**

Результатом этапа предварительного обучения является базовая модель (base model), характеризующаяся развитыми способностями к пониманию и генерации текста. Однако, следует отметить, что данная модель еще не оптимизирована для выполнения специфических инструкций или поддержания диалогического взаимодействия, что обуславливает необходимость последующих этапов обучения.

Важно подчеркнуть, что качество базовой модели, полученной на этапе предварительного обучения, в значительной степени определяет потенциал модели для последующих этапов тонкой настройки и обучения с подкреплением. Таким образом, оптимизация процесса предварительного обучения представляет собой критически важную задачу в контексте разработки высокоэффективных крупномасштабных языковых моделей.

</details>

</details>