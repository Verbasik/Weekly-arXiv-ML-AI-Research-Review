# **Как LLM выучивают факты: Динамика, запоминание, галлюцинации. Новое исследование от Google DeepMind**

## **1. Введение**

### **Ключевая проблема**: 

Несмотря на то, что крупные языковые модели (LLM) в ходе предварительного обучения усваивают огромный объем фактических знаний, внутренние механизмы того, как они изучают, хранят и применяют эти знания, остаются «черным ящиком». Раскрытие этих механизмов критически важно не только для оптимизации обучения моделей, но и для понимания и решения таких ключевых проблем, как «галлюцинации» и трудности обновления знаний после предварительного обучения.  

### **Методология исследования**: 

Для системного изучения этой проблемы в данной статье разработана контролируемая экспериментальная методика. Вместо использования сложных реальных текстов исследователи создали синтетическую задачу на воспроизведение фактов (factual recall), основанную на искусственных биографиях. Такой синтетический подход позволяет точно контролировать свойства данных и эффективно отслеживать процесс усвоения знаний на всех этапах обучения.  

### **Ключевые выводы вкратце**:  

1. **Этапное обучение**: Знания усваиваются не линейно. Модель демонстрирует три уникальные фазы изучения фактов, включая критический «плато-период», когда производительность кажется застывшей, но внутри формируются механизмы представления.  
2. **Важность распределения данных**: Статистические свойства обучающих данных, особенно частотное распределение упоминаний разных «индивидуумов», существенно влияют на скорость и динамику обучения, в том числе на длительность плато-периода.  
3. **Сосуществование галлюцинаций и знаний**: Склонность модели к «галлюцинациям» (генерации информации о несуществующих объектах) проявляется почти одновременно с процессом усвоения реальных фактов.  
4. **Сложности дообучения**: Интеграция новых знаний в уже обученную модель через дообучение (fine-tuning) оказывается крайне трудной и часто приводит к быстрому разрушению существующей параметрической памяти (т.н. «катастрофическому забыванию»).

## **2. Отслеживание получения знаний: детали экспериментальной среды**

**Ключевой вопрос:**  
При изучении того, как LLM усваивают факты, мы сталкиваемся с двумя методологическими проблемами:

1. **Отделение знаний:**  
   Как измерить степень владения моделью фактическими знаниями, отделив их от других языковых способностей (грамматика, беглость и т.д.)?

2. **Эффективность и масштабируемость оценки:**  
   Как непрерывно отслеживать уровень знаний в процессе обучения, избегая дорогостоящих комплексных оценок (например, QA-тестов) на каждом этапе?

**Интуиция и общий подход:**  
Идеальная экспериментальная среда должна обладать следующими характеристиками:
- Факты дискретны и атомарны;
- Успех задачи напрямую зависит от воспроизведения конкретных пар "сущность-атрибут";
- Процесс генерации данных контролируем для регистрации статистических свойств;
- Оценка знаний интегрирована в стандартный процесс обучения.

Это естественным образом приводит к использованию структурированных синтетических данных для задач воспроизведения фактов.

### 2.1 Знания vs. Память: ключевое различие

Для точного понимания поведения модели необходимо различать **"знания"** и **"память"**:

| Концепт  | Определение                                                                 | Характеристики                          | Пример (знание "Париж — столица Франции")              |
|----------|-----------------------------------------------------------------------------|-----------------------------------------|-------------------------------------------------------|
| Знания   | Информация, усвоенная моделью, независимая от формы ввода и гибко применяемая | Абстрактность, обобщение, гибкость     | Ответы на вопросы: "Столица Франции?", "Какой стране принадлежит Париж?" |
| Память   | Воспроизведение конкретных примеров обучения, привязанное к форме ввода      | Конкретность, хрупкость                | Завершение предложения: "Париж — это ___ Франции"      |

### 2.2 Синтетический биографический набор данных

**Преимущества дизайна:**
- **Атомарность:** каждый факт (например, место рождения) независим, что отделяет способность "вспоминать" от способности "рассуждать";
- **Синтетичность и контроль:** точный контроль распределения данных (например, частоты появления персонажей) без помех из реальных корпусов;
- **Реалистичная статистика:** использование распространенных имен и мест сохраняет естественное распределение токенов;
- **Релевантность предыдущих исследований:** малые модели на подобных данных демонстрируют механизмы хранения знаний, сравнимые с большими LLM.

**Процесс генерации:**
1. **Создание базы персонажей:** Генерация N виртуальных "персонажей" с уникальными именами и шестью атрибутами;
2. **Заполнение шаблонов:** Для каждого атрибута случайно выбирается шаблон из библиотеки (25 вариантов на тип атрибута), куда подставляется конкретная информация (например, "[Имя] родился в [Место рождения]");
   - *Ключевой момент:* Множество шаблонов создает текстовое разнообразие, вынуждая модель выйти за рамки простого запоминания
3. **Сборка биографии:** Случайное упорядочивание предложений с атрибутами в полную биографи;
   - *Ключевой момент:* Случайный порядок предотвращает использование моделью последовательностных подсказок
4. **Разделение на обучающую/оценочную выборки:** Для каждого персонажа 20 шаблонов идут в обучение, 5 — в оценку. Это гарантирует, что модель сталкивается с новыми формулировками известных фактов, тестируя уровень абстракции знаний.

![Figure_1](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-15/assets/Figure_01.png)
* Figure_1. Процесс генерации данных, лежащий в основе синтетического набора биографий, на котором мы обучаем модели. Мы измеряем знания, содержащиеся в этих моделях, через величину потерь (loss), которую они достигают при предсказании атрибутных токенов (выделены синим).*

### 2.3 Масштабное измерение знаний: потери и точность атрибутов

**Проблема:** Многократные QA-оценки в процессе обучения требуют больших вычислений  
**Решение:** Специальная структура биографий превращает предсказание значений атрибутов в задачу воспроизведения фактов  

### 2.4 Стандартизированные модели и обучение

Для обеспечения воспроизводимости результатов:

- **Архитектура:** 8-слойный Decoder-only Transformer (44M параметров, на основе Hoffmann et al., 2022)
- **Оптимизатор:** AdamW с косинусным затуханием learning rate (без warmup)
- **Learning rate:** Настраивается индивидуально для каждого эксперимента
