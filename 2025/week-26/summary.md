# Eso-LM от NVIDIA: как гибрид диффузионного и авторегрессивного подходов меняет NLP
**Оглавление**

1. [Введение](#введение)  
2. [Предпосылки и мотивация](#предпосылки-и-мотивация)  
3. [Основная методология](#основная-методология)  
4. [Механизмы внимания и кэширование ключ-значение](#механизмы-внимания-и-кэширование-ключ-значение)  
5. [Экспериментальные результаты](#экспериментальные-результаты)  
6. [Значимость и влияние](#значимость-и-влияние)  
7. [Заключение](#заключение)

## 1. Введение

Эзотерические языковые модели (Eso-LMs) представляют собой значительный прорыв в генеративном языковом моделировании, впервые успешно объединив парадигмы авторегрессионных (AR) и моделей маскированной диффузии (MDM). В то время как авторегрессионные модели, такие как GPT, превосходны в качестве генерации, но страдают от медленного последовательного вывода, модели маскированной диффузии предлагают возможности параллельной генерации, но традиционно отстают по показателям перплексии и не имеют эффективных механизмов кеширования. Эта работа устраняет эти фундаментальные ограничения, предлагая унифицированную структуру, которая сочетает в себе сильные стороны обоих подходов, минимизируя при этом их соответствующие недостатки.

![Figure_01](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-26/assets/Figure_01.png)

*Рисунок 1: Процесс генерации Eso-LM иллюстрирует двухэтапную процедуру семплирования. Фаза диффузии (оранжевый) постепенно удаляет шум из токенов параллельно, в то время как последовательная фаза (зеленый) заполняет оставшиеся маскированные токены авторегрессивно с богатым обусловливанием как от левого контекста, так и от чистых токенов, обнаруженных во время диффузии.*

## 2. Обзор и Мотивация

Ландшафт языкового моделирования доминируют авторегрессионные модели, которые генерируют текст последовательно слева направо. Хотя эти модели достигают отличных показателей перплексии, их последовательная природа ограничивает скорость вывода и гибкость. Модели маскированной диффузии появились как альтернатива, предлагая параллельную генерацию токенов и улучшенную управляемость, но они сталкиваются с двумя критическими проблемами: более медленный вывод из-за двунаправленного внимания, которое предотвращает кеширование KV, и заметный разрыв в качестве по сравнению с AR-моделями.

Недавние гибридные подходы, такие как модели дискретного языка с блочным шумоподавлением и диффузией (BD3-LMs), попытались преодолеть этот разрыв, объединив авторегрессионное блочное моделирование с внутриблочной диффузией. Однако эти методы страдают от коллапса мод при низких шагах семплирования и предоставляют лишь частичные преимущества кеширования. Исследование определяет эти ограничения как ключевые барьеры для практического внедрения языковых моделей на основе диффузии.

## 3. Методология

### Гибридная Цель Обучения

Eso-LMs представляют новую структуру обучения, которая плавно интерполирует между целями AR и MDM посредством гибридной функции потерь. Ключевое новшество заключается в формулировке вариационной границы:

![Figure_02](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-26/assets/Figure_02.png)

Эта потеря объединяет авторегрессионный член (вычисляемый для изначально маскированных токенов) с членом маскированной диффузии (взвешенное среднее по прогрессивно зашумленным последовательностям). Гиперпараметр $α_0$ контролирует интерполяцию: $α_0=1$ дает чистое поведение MDM, тогда как $α_0=0$ приводит к чистому поведению AR.

### Двухэтапный Процесс Семплирования

Генерация проходит в два различных этапа:

1. **Фаза диффузии:** начиная с полностью маскированной последовательности, модель постепенно удаляет шум из подмножества токенов параллельно, создавая частично маскированную последовательность $z_0$. Ключевая оптимизация обрабатывает только чистые токены и те, которые запланированы для шумоподавления на каждом шаге, значительно сокращая вычислительные затраты.

2. **Последовательная фаза:** оставшиеся маскированные токены заполняются авторегрессивно слева направо, при этом каждый токен обуславливается как своим левым контекстом, так и чистыми токенами, обнаруженными во время фазы диффузии.