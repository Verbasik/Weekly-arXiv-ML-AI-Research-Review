# MoE Router: Load Balancing Loss - –í—ã—á–∏—Å–ª–µ–Ω–∏–µ Frequency

## –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ
- [–û–±–∑–æ—Ä](#–æ–±–∑–æ—Ä)
- [–ß—Ç–æ —Ç–∞–∫–æ–µ Frequency (f_i)?](#—á—Ç–æ-—Ç–∞–∫–æ–µ-frequency-f_i)
- [–ó–∞—á–µ–º –Ω—É–∂–µ–Ω Load Balancing Loss?](#–∑–∞—á–µ–º-–Ω—É–∂–µ–Ω-load-balancing-loss)
- [–ü–æ–¥—Ö–æ–¥ 1: torch.bincount (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)](#–ø–æ–¥—Ö–æ–¥-1-torchbincount-—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
- [–ü–æ–¥—Ö–æ–¥ 2: One-hot Encoding + Mean](#–ø–æ–¥—Ö–æ–¥-2-one-hot-encoding--mean)
- [–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤](#—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ-–ø–æ–¥—Ö–æ–¥–æ–≤)
- [–ü–æ–ª–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è _compute_balance_loss](#–ø–æ–ª–Ω–∞—è-—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è-_compute_balance_loss)
- [–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä](#–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π-–ø—Ä–∏–º–µ—Ä)

---

## –û–±–∑–æ—Ä

–í –º–µ—Ç–æ–¥–µ `_compute_balance_loss` –∫–ª–∞—Å—Å–∞ `MoERouter` –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã—á–∏—Å–ª–∏—Ç—å **load balancing loss**, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç "–∫–æ–ª–ª–∞–ø—Å —ç–∫—Å–ø–µ—Ä—Ç–æ–≤" ‚Äî —Å–∏—Ç—É–∞—Ü–∏—é, –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–ª—å–∫–æ –º–∞–ª—É—é —á–∞—Å—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤.

### –§–æ—Ä–º—É–ª–∞ Load Balancing Loss:

```
L_balance = Œ± * N * Œ£ (f_i * P_i)
                    i=1..N

–≥–¥–µ:
  Œ± - balance_loss_coef (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç, –Ω–∞–ø—Ä–∏–º–µ—Ä 0.01)
  N - num_experts (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤, –Ω–∞–ø—Ä–∏–º–µ—Ä 128)
  f_i - frequency: –¥–æ–ª—è —Ç–æ–∫–µ–Ω–æ–≤, –≤—ã–±—Ä–∞–≤—à–∏—Ö —ç–∫—Å–ø–µ—Ä—Ç–∞ i
  P_i - mean gating probability: —Å—Ä–µ–¥–Ω–∏–π –≤–µ—Å —ç–∫—Å–ø–µ—Ä—Ç–∞ i
```

**–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ f_i (frequency).**

---

## –ß—Ç–æ —Ç–∞–∫–æ–µ Frequency (f_i)?

**Frequency** ‚Äî —ç—Ç–æ **–¥–æ–ª—è —Ç–æ–∫–µ–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–±—Ä–∞–ª–∏ —ç–∫—Å–ø–µ—Ä—Ç–∞ i** —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤ –±–∞—Ç—á–µ.

### –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:

```
f_i = (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑, –∫–æ–≥–¥–∞ —ç–∫—Å–ø–µ—Ä—Ç i –±—ã–ª –≤—ã–±—Ä–∞–Ω) / (–æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±–æ—Ä–æ–≤)

–≥–¥–µ:
  –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±–æ—Ä–æ–≤ = batch_size * seq_len * top_k
```

### –ü—Ä–∏–º–µ—Ä:

```
batch_size = 2
seq_len = 10
top_k = 8
num_experts = 128

–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±–æ—Ä–æ–≤ = 2 * 10 * 8 = 160

–ï—Å–ª–∏ —ç–∫—Å–ø–µ—Ä—Ç 42 –±—ã–ª –≤—ã–±—Ä–∞–Ω 12 —Ä–∞–∑:
  f_42 = 12 / 160 = 0.075 (7.5%)

–ï—Å–ª–∏ —ç–∫—Å–ø–µ—Ä—Ç 99 –±—ã–ª –≤—ã–±—Ä–∞–Ω 8 —Ä–∞–∑:
  f_99 = 8 / 160 = 0.050 (5.0%)

–ï—Å–ª–∏ —ç–∫—Å–ø–µ—Ä—Ç 0 –Ω–µ –±—ã–ª –≤—ã–±—Ä–∞–Ω:
  f_0 = 0 / 160 = 0.0 (0%)
```

### –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:

```
selected_experts: (batch_size=2, seq_len=10, top_k=8)

Batch 0:
  –¢–æ–∫–µ–Ω 0: [42, 15,  7, 123, 99,  4, 88, 23]
  –¢–æ–∫–µ–Ω 1: [15,  7, 99,  42, 23,  4, 11, 56]
  –¢–æ–∫–µ–Ω 2: [ 7, 99, 15,  23, 42, 88,  4, 11]
  ...
  –¢–æ–∫–µ–Ω 9: [42, 99, 15,   7, 23, 88,  4, 11]

Batch 1:
  –¢–æ–∫–µ–Ω 0: [99, 42, 15,  7, 23, 88,  4, 11]
  ...
  –¢–æ–∫–µ–Ω 9: [15,  7, 99, 42, 23, 88,  4, 11]

                    ‚Üì
              –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç
                    ‚Üì

–≠–∫—Å–ø–µ—Ä—Ç   0: –≤—ã–±—Ä–∞–Ω  0 —Ä–∞–∑ ‚Üí f_0   = 0/160 = 0.000
–≠–∫—Å–ø–µ—Ä—Ç   4: –≤—ã–±—Ä–∞–Ω 20 —Ä–∞–∑ ‚Üí f_4   = 20/160 = 0.125
–≠–∫—Å–ø–µ—Ä—Ç   7: –≤—ã–±—Ä–∞–Ω 18 —Ä–∞–∑ ‚Üí f_7   = 18/160 = 0.113
–≠–∫—Å–ø–µ—Ä—Ç  15: –≤—ã–±—Ä–∞–Ω 19 —Ä–∞–∑ ‚Üí f_15  = 19/160 = 0.119
–≠–∫—Å–ø–µ—Ä—Ç  42: –≤—ã–±—Ä–∞–Ω 12 —Ä–∞–∑ ‚Üí f_42  = 12/160 = 0.075
–≠–∫—Å–ø–µ—Ä—Ç  99: –≤—ã–±—Ä–∞–Ω  8 —Ä–∞–∑ ‚Üí f_99  = 8/160 = 0.050
...
–≠–∫—Å–ø–µ—Ä—Ç 127: –≤—ã–±—Ä–∞–Ω  0 —Ä–∞–∑ ‚Üí f_127 = 0/160 = 0.000

–†–µ–∑—É–ª—å—Ç–∞—Ç: frequency —Ç–µ–Ω–∑–æ—Ä —Ñ–æ—Ä–º—ã (128,)
```

---

## –ó–∞—á–µ–º –Ω—É–∂–µ–Ω Load Balancing Loss?

### –ü—Ä–æ–±–ª–µ–º–∞: Expert Collapse (–ö–æ–ª–ª–∞–ø—Å —ç–∫—Å–ø–µ—Ä—Ç–æ–≤)

–ë–µ–∑ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –Ω–∞—É—á–∏—Ç—å—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ 10-20 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –∏–∑ 128:

```
‚ùå –ë–ï–ó –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏:

–≠–∫—Å–ø–µ—Ä—Ç   0: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.45  (45% —Ç–æ–∫–µ–Ω–æ–≤)
–≠–∫—Å–ø–µ—Ä—Ç   1: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      0.35  (35% —Ç–æ–∫–µ–Ω–æ–≤)
–≠–∫—Å–ø–µ—Ä—Ç   2: ‚ñà‚ñà‚ñà‚ñà‚ñà                0.10  (10% —Ç–æ–∫–µ–Ω–æ–≤)
–≠–∫—Å–ø–µ—Ä—Ç   3: ‚ñà‚ñà                   0.05  (5% —Ç–æ–∫–µ–Ω–æ–≤)
–≠–∫—Å–ø–µ—Ä—Ç   4: ‚ñà                    0.03  (3% —Ç–æ–∫–µ–Ω–æ–≤)
–≠–∫—Å–ø–µ—Ä—Ç   5:                      0.02  (2% —Ç–æ–∫–µ–Ω–æ–≤)
–≠–∫—Å–ø–µ—Ä—Ç 6-127:                    0.00  (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è!)

–ü—Ä–æ–±–ª–µ–º—ã:
  - –ü–æ—Ç–µ—Ä—è –º–æ–¥–µ–ª—å–Ω–æ–π –µ–º–∫–æ—Å—Ç–∏ (capacity)
  - –ù–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
  - –£—Ö—É–¥—à–µ–Ω–∏–µ –æ–±–æ–±—â–∞—é—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
```

### –†–µ—à–µ–Ω–∏–µ: Load Balancing Loss

–î–æ–±–∞–≤–ª—è—è –±–∞–ª–∞–Ω—Å–∏—Ä—É—é—â–∏–π loss, –º–æ–¥–µ–ª—å –º–æ—Ç–∏–≤–∏—Ä—É–µ—Ç—Å—è —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—Ç—å –Ω–∞–≥—Ä—É–∑–∫—É:

```
‚úÖ –° –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π:

–≠–∫—Å–ø–µ—Ä—Ç   0: ‚ñà‚ñà‚ñà  0.012  (1.2%)
–≠–∫—Å–ø–µ—Ä—Ç   1: ‚ñà‚ñà‚ñà  0.011  (1.1%)
–≠–∫—Å–ø–µ—Ä—Ç   2: ‚ñà‚ñà‚ñà  0.010  (1.0%)
–≠–∫—Å–ø–µ—Ä—Ç   3: ‚ñà‚ñà‚ñà  0.009  (0.9%)
...
–≠–∫—Å–ø–µ—Ä—Ç 127: ‚ñà‚ñà‚ñà  0.008  (0.8%)

–í—Å–µ —ç–∫—Å–ø–µ—Ä—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤–æ!
–ò–¥–µ–∞–ª—å–Ω–æ: f_i ‚âà 1/128 ‚âà 0.0078 –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
```

---

## –ü–æ–¥—Ö–æ–¥ 1: torch.bincount (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

### –ß—Ç–æ —Ç–∞–∫–æ–µ torch.bincount?

`torch.bincount` –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç, —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –∫–∞–∂–¥–æ–µ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ —Ç–µ–Ω–∑–æ—Ä–µ.

### –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä:

```python
import torch

# –ü—Ä–∏–º–µ—Ä: –ø–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç —á–∏—Å–µ–ª
indices = torch.tensor([0, 1, 1, 2, 1, 0, 3])
counts = torch.bincount(indices)

print(counts)
# tensor([2, 3, 1, 1])
#         ‚Üë  ‚Üë  ‚Üë  ‚Üë
#         0  1  2  3  ‚Üê –∏–Ω–¥–µ–∫—Å—ã
#
# –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:
#   0 –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è 2 —Ä–∞–∑–∞
#   1 –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è 3 —Ä–∞–∑–∞
#   2 –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è 1 —Ä–∞–∑
#   3 –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è 1 —Ä–∞–∑
```

### –ü–∞—Ä–∞–º–µ—Ç—Ä minlength:

```python
# –ï—Å–ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ < –∂–µ–ª–∞–µ–º–æ–π –¥–ª–∏–Ω—ã
indices = torch.tensor([0, 1, 1, 2])
counts = torch.bincount(indices, minlength=5)

print(counts)
# tensor([1, 2, 1, 0, 0])
#         ‚Üë  ‚Üë  ‚Üë  ‚Üë  ‚Üë
#         0  1  2  3  4
#
# –ò–Ω–¥–µ–∫—Å—ã 3 –∏ 4 –Ω–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è ‚Üí count = 0
# minlength –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –¥–ª–∏–Ω—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
```

### –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ MoE Router:

#### –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:

```python
selected_experts: torch.Tensor  # (batch_size, seq_len, top_k)
# –ü—Ä–∏–º–µ—Ä: (2, 10, 8)
#   - 2 –±–∞—Ç—á–∞
#   - 10 —Ç–æ–∫–µ–Ω–æ–≤ per –±–∞—Ç—á
#   - 8 –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ per —Ç–æ–∫–µ–Ω
#   - –ó–Ω–∞—á–µ–Ω–∏—è: –∏–Ω–¥–µ–∫—Å—ã —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ [0, 127]
```

#### –ê–ª–≥–æ—Ä–∏—Ç–º:

```python
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –®–∞–≥ 1: Flatten –≤ 1D —Ç–µ–Ω–∑–æ—Ä
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# –ë—ã–ª–æ: (batch_size, seq_len, top_k) = (2, 10, 8)
flattened_experts = selected_experts.view(-1)
# –°—Ç–∞–ª–æ: (160,) ‚Äî –≤—Å–µ –∏–Ω–¥–µ–∫—Å—ã –≤ –æ–¥–Ω–æ–º –º–∞—Å—Å–∏–≤–µ

# –ü—Ä–∏–º–µ—Ä —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ:
# flattened_experts = [42, 15, 7, 123, 99, 4, 88, 23,  ‚Üê –¢–æ–∫–µ–Ω 0, Batch 0
#                      15, 7, 99, 42, 23, 4, 11, 56,   ‚Üê –¢–æ–∫–µ–Ω 1, Batch 0
#                      ...]

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –®–∞–≥ 2: –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç —Å –ø–æ–º–æ—â—å—é bincount
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

expert_counts = torch.bincount(
    flattened_experts,
    minlength=self.num_experts  # 128 ‚Äî –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä (128,)
)
# expert_counts[i] = —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ —ç–∫—Å–ø–µ—Ä—Ç i –±—ã–ª –≤—ã–±—Ä–∞–Ω

# –ü—Ä–∏–º–µ—Ä:
# expert_counts = [0, 0, 0, 0, 20, 0, 0, 18, ..., 12, ..., 8, ...]
#                  ‚Üë              ‚Üë        ‚Üë         ‚Üë        ‚Üë
#                  0              4        7        42       99

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –®–∞–≥ 3: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤ —á–∞—Å—Ç–æ—Ç—ã (–¥–æ–ª–∏)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

batch_size, seq_len, top_k = selected_experts.shape
total_selections = batch_size * seq_len * top_k  # 2 * 10 * 8 = 160

frequency = expert_counts.float() / total_selections
# frequency[i] = –¥–æ–ª—è —Ç–æ–∫–µ–Ω–æ–≤, –≤—ã–±—Ä–∞–≤—à–∏—Ö —ç–∫—Å–ø–µ—Ä—Ç–∞ i

# –ü—Ä–∏–º–µ—Ä:
# frequency = [0.000, 0.000, 0.000, 0.000, 0.125, 0.000, 0.000, 0.113, ...]
#              ‚Üë                            ‚Üë                    ‚Üë
#              0                            4                    7
#              0/160 = 0%                  20/160 = 12.5%       18/160 = 11.3%
```

### –ü–æ–ª–Ω—ã–π –∫–æ–¥:

```python
def _compute_frequency_bincount(self, selected_experts: torch.Tensor) -> torch.Tensor:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç —á–∞—Å—Ç–æ—Ç—É –≤—ã–±–æ—Ä–∞ –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞ (f_i).

    Args:
        selected_experts: (batch_size, seq_len, top_k) - –∏–Ω–¥–µ–∫—Å—ã –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤

    Returns:
        frequency: (num_experts,) - –¥–æ–ª—è —Ç–æ–∫–µ–Ω–æ–≤, –≤—ã–±—Ä–∞–≤—à–∏—Ö –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
    """
    # Flatten: (B, S, K) ‚Üí (B*S*K,)
    flattened_experts = selected_experts.view(-1)

    # –ü–æ–¥—Å—á–µ—Ç: —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –∫–∞–∂–¥—ã–π —ç–∫—Å–ø–µ—Ä—Ç –±—ã–ª –≤—ã–±—Ä–∞–Ω
    expert_counts = torch.bincount(
        flattened_experts,
        minlength=self.num_experts  # (num_experts,)
    )

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: –ø–µ—Ä–µ–≤–æ–¥–∏–º counts –≤ frequencies
    batch_size, seq_len, top_k = selected_experts.shape
    total_selections = batch_size * seq_len * top_k
    frequency = expert_counts.float() / total_selections

    return frequency  # (num_experts,)
```

### –ü–æ—à–∞–≥–æ–≤–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: selected_experts (2, 10, 8)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

       Batch 0              Batch 1
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ –¢–æ–∫–µ–Ω 0  ‚îÇ         ‚îÇ –¢–æ–∫–µ–Ω 0  ‚îÇ
    ‚îÇ [42,15,  ‚îÇ         ‚îÇ [99,42,  ‚îÇ
    ‚îÇ  7,123,  ‚îÇ         ‚îÇ  15,7,   ‚îÇ
    ‚îÇ  99,4,   ‚îÇ         ‚îÇ  23,88,  ‚îÇ
    ‚îÇ  88,23]  ‚îÇ         ‚îÇ  4,11]   ‚îÇ
    ‚îÇ          ‚îÇ         ‚îÇ          ‚îÇ
    ‚îÇ –¢–æ–∫–µ–Ω 1  ‚îÇ         ‚îÇ –¢–æ–∫–µ–Ω 1  ‚îÇ
    ‚îÇ [15,7,   ‚îÇ   ...   ‚îÇ [15,7,   ‚îÇ
    ‚îÇ  99,42,  ‚îÇ         ‚îÇ  99,42,  ‚îÇ
    ‚îÇ  ...]    ‚îÇ         ‚îÇ  ...]    ‚îÇ
    ‚îÇ   ...    ‚îÇ         ‚îÇ   ...    ‚îÇ
    ‚îÇ –¢–æ–∫–µ–Ω 9  ‚îÇ         ‚îÇ –¢–æ–∫–µ–Ω 9  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                    ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚Üì
          .view(-1) ‚Äî Flatten
                  ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ flattened_experts: (160,)       ‚îÇ
    ‚îÇ                                 ‚îÇ
    ‚îÇ [42, 15, 7, 123, 99, 4, 88, 23,‚îÇ
    ‚îÇ  15, 7, 99, 42, 23, 4, 11, 56, ‚îÇ
    ‚îÇ  7, 99, 15, 23, 42, 88, 4, 11, ‚îÇ
    ‚îÇ  ...]                           ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚Üì
      torch.bincount(minlength=128)
                  ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ expert_counts: (128,)           ‚îÇ
    ‚îÇ                                 ‚îÇ
    ‚îÇ [0, 0, 0, 0, 20, ..., 18, ...]  ‚îÇ
    ‚îÇ  ‚Üë           ‚Üë         ‚Üë        ‚îÇ
    ‚îÇ  —ç–∫—Å–ø 0      —ç–∫—Å–ø 4    —ç–∫—Å–ø 7   ‚îÇ
    ‚îÇ  –Ω–µ –≤—ã–±—Ä–∞–Ω   20 —Ä–∞–∑    18 —Ä–∞–∑   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚Üì
         / total_selections (160)
                  ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ frequency: (128,)               ‚îÇ
    ‚îÇ                                 ‚îÇ
    ‚îÇ [0.000, 0.000, 0.000, 0.000,   ‚îÇ
    ‚îÇ  0.125, ..., 0.113, ...]        ‚îÇ
    ‚îÇ  ‚Üë                   ‚Üë           ‚îÇ
    ‚îÇ  0%                  11.3%       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## –ü–æ–¥—Ö–æ–¥ 2: One-hot Encoding + Mean

### –ß—Ç–æ —Ç–∞–∫–æ–µ One-hot Encoding?

One-hot encoding –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–Ω–¥–µ–∫—Å—ã –≤ –±–∏–Ω–∞—Ä–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã:

```python
import torch.nn.functional as F

# –ü—Ä–∏–º–µ—Ä
indices = torch.tensor([2, 0, 1, 2])
one_hot = F.one_hot(indices, num_classes=4)

print(one_hot)
# tensor([[0, 0, 1, 0],  ‚Üê –∏–Ω–¥–µ–∫—Å 2 ‚Üí –ø–æ–∑–∏—Ü–∏—è 2 = 1
#         [1, 0, 0, 0],  ‚Üê –∏–Ω–¥–µ–∫—Å 0 ‚Üí –ø–æ–∑–∏—Ü–∏—è 0 = 1
#         [0, 1, 0, 0],  ‚Üê –∏–Ω–¥–µ–∫—Å 1 ‚Üí –ø–æ–∑–∏—Ü–∏—è 1 = 1
#         [0, 0, 1, 0]]) ‚Üê –∏–Ω–¥–µ–∫—Å 2 ‚Üí –ø–æ–∑–∏—Ü–∏—è 2 = 1
```

### –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ MoE Router:

#### –ê–ª–≥–æ—Ä–∏—Ç–º:

```python
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –®–∞–≥ 1: One-hot encoding
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: selected_experts (batch_size, seq_len, top_k)
# –ü—Ä–∏–º–µ—Ä: (2, 10, 8)

one_hot = F.one_hot(
    selected_experts,
    num_classes=self.num_experts  # 128
)
# –†–µ–∑—É–ª—å—Ç–∞—Ç: (batch_size, seq_len, top_k, num_experts)
# –ü—Ä–∏–º–µ—Ä: (2, 10, 8, 128)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# –¢–æ–∫–µ–Ω [0, 0] –≤—ã–±—Ä–∞–ª —ç–∫—Å–ø–µ—Ä—Ç–æ–≤: [42, 15, 7, 123, 99, 4, 88, 23]
# one_hot[0, 0] –∏–º–µ–µ—Ç —Ñ–æ—Ä–º—É (8, 128):
#
#     –≠–∫—Å–ø–µ—Ä—Ç:  0  1  2 ... 4  5  6  7 ... 15 ... 23 ... 42 ... 88 ... 99 ... 123 ... 127
#     ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# K=0 [42]:     0  0  0 ... 0  0  0  0 ... 0  ... 0  ... 1  ... 0  ... 0  ... 0   ... 0
# K=1 [15]:     0  0  0 ... 0  0  0  0 ... 1  ... 0  ... 0  ... 0  ... 0  ... 0   ... 0
# K=2 [7]:      0  0  0 ... 0  0  0  1 ... 0  ... 0  ... 0  ... 0  ... 0  ... 0   ... 0
# K=3 [123]:    0  0  0 ... 0  0  0  0 ... 0  ... 0  ... 0  ... 0  ... 0  ... 1   ... 0
# K=4 [99]:     0  0  0 ... 0  0  0  0 ... 0  ... 0  ... 0  ... 0  ... 1  ... 0   ... 0
# K=5 [4]:      0  0  0 ... 1  0  0  0 ... 0  ... 0  ... 0  ... 0  ... 0  ... 0   ... 0
# K=6 [88]:     0  0  0 ... 0  0  0  0 ... 0  ... 0  ... 0  ... 1  ... 0  ... 0   ... 0
# K=7 [23]:     0  0  0 ... 0  0  0  0 ... 0  ... 1  ... 0  ... 0  ... 0  ... 0   ... 0

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –®–∞–≥ 2: –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º –∏–∑–º–µ—Ä–µ–Ω–∏—è–º
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

frequency = one_hot.float().mean(dim=[0, 1, 2])
# –£—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ batch (dim=0), seq (dim=1), top_k (dim=2)
# –†–µ–∑—É–ª—å—Ç–∞—Ç: (num_experts,)

# –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏:
# frequency[i] = Œ£ Œ£ Œ£ one_hot[b, s, k, i] / (B * S * K)
#               b  s  k
```

### –ü–æ–ª–Ω—ã–π –∫–æ–¥:

```python
def _compute_frequency_onehot(self, selected_experts: torch.Tensor) -> torch.Tensor:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç —á–∞—Å—Ç–æ—Ç—É –≤—ã–±–æ—Ä–∞ –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞ —á–µ—Ä–µ–∑ one-hot encoding.

    Args:
        selected_experts: (batch_size, seq_len, top_k)

    Returns:
        frequency: (num_experts,)
    """
    # One-hot: (B, S, K) ‚Üí (B, S, K, N)
    one_hot = F.one_hot(
        selected_experts,
        num_classes=self.num_experts
    )

    # Mean –ø–æ batch, seq, top_k: (B, S, K, N) ‚Üí (N,)
    frequency = one_hot.float().mean(dim=[0, 1, 2])

    return frequency  # (num_experts,)
```

### –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ:

–î–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞ i:

```
frequency[i] = (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –µ–¥–∏–Ω–∏—Ü –≤ —Å—Ç–æ–ª–±—Ü–µ i) / (B * S * K)

–≥–¥–µ:
  - B = batch_size
  - S = seq_len
  - K = top_k
  - –°—Ç–æ–ª–±–µ—Ü i —Å–æ–¥–µ—Ä–∂–∏—Ç 1, –∫–æ–≥–¥–∞ —ç–∫—Å–ø–µ—Ä—Ç i –±—ã–ª –≤—ã–±—Ä–∞–Ω
```

**–ü—Ä–∏–º–µ—Ä:**
```python
# –î–∞–Ω–æ: (B=2, S=10, K=8) ‚Üí total = 160 –≤—ã–±–æ—Ä–æ–≤

# –î–ª—è —ç–∫—Å–ø–µ—Ä—Ç–∞ 42:
# one_hot[:, :, :, 42] —Å–æ–¥–µ—Ä–∂–∏—Ç 12 –µ–¥–∏–Ω–∏—Ü (–≤ 12 –ø–æ–∑–∏—Ü–∏—è—Ö)
# frequency[42] = 12 / 160 = 0.075

# –î–ª—è —ç–∫—Å–ø–µ—Ä—Ç–∞ 99:
# one_hot[:, :, :, 99] —Å–æ–¥–µ—Ä–∂–∏—Ç 8 –µ–¥–∏–Ω–∏—Ü
# frequency[99] = 8 / 160 = 0.050

# –î–ª—è —ç–∫—Å–ø–µ—Ä—Ç–∞ 0:
# one_hot[:, :, :, 0] —Å–æ–¥–µ—Ä–∂–∏—Ç 0 –µ–¥–∏–Ω–∏—Ü
# frequency[0] = 0 / 160 = 0.0
```

---

## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤

### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:

| –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ | `torch.bincount` | One-hot + mean |
|----------------|------------------|----------------|
| **–°–∫–æ—Ä–æ—Å—Ç—å** | ‚ö°‚ö°‚ö° –û—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ | üê¢ –ú–µ–¥–ª–µ–Ω–Ω–µ–µ |
| **–ü–∞–º—è—Ç—å** | üíæ O(num_experts) | üíæüíæ O(B*S*K*N) ‚Äî 4D —Ç–µ–Ω–∑–æ—Ä! |
| **–ß–∏—Ç–∞–µ–º–æ—Å—Ç—å** | ‚≠ê‚≠ê‚≠ê –•–æ—Ä–æ—à–æ | ‚≠ê‚≠ê‚≠ê‚≠ê –ë–æ–ª–µ–µ –Ω–∞–≥–ª—è–¥–Ω–æ |
| **–°–ª–æ–∂–Ω–æ—Å—Ç—å –∫–æ–¥–∞** | 3 —Å—Ç—Ä–æ–∫–∏ | 2 —Å—Ç—Ä–æ–∫–∏ |

### –ü—Ä–∏–º–µ—Ä –∑–∞—Ç—Ä–∞—Ç –ø–∞–º—è—Ç–∏:

```python
# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
batch_size = 2
seq_len = 10
top_k = 8
num_experts = 128

# torch.bincount:
# flattened: (160,) ‚Äî int64 ‚Üí 160 * 8 bytes = 1.28 KB
# expert_counts: (128,) ‚Äî int64 ‚Üí 128 * 8 bytes = 1.02 KB
# –ò—Ç–æ–≥–æ: ~2.3 KB

# One-hot + mean:
# one_hot: (2, 10, 8, 128) ‚Äî int64 ‚Üí 2*10*8*128 * 8 bytes = 163.84 KB
# –ò—Ç–æ–≥–æ: ~164 KB (–≤ 71 —Ä–∞–∑ –±–æ–ª—å—à–µ!)
```

### –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π –ø–æ–¥—Ö–æ–¥:

| –ü–æ–¥—Ö–æ–¥ | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
|--------|-------------------|
| **torch.bincount** | ‚úÖ –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ (production code)<br>‚úÖ –ö–æ–≥–¥–∞ –≤–∞–∂–Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å<br>‚úÖ –î–ª—è –±–æ–ª—å—à–∏—Ö –±–∞—Ç—á–µ–π |
| **One-hot + mean** | ‚úÖ –î–ª—è –æ–±—É—á–µ–Ω–∏—è/–ø–æ–Ω–∏–º–∞–Ω–∏—è<br>‚úÖ –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–±–æ–ª–µ–µ –Ω–∞–≥–ª—è–¥–Ω–æ)<br>‚úÖ –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ |

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:

**–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `torch.bincount` –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏** –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

---

## –ü–æ–ª–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è _compute_balance_loss

–¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –º—ã –∑–Ω–∞–µ–º –∫–∞–∫ –≤—ã—á–∏—Å–ª–∏—Ç—å frequency, –¥–∞–≤–∞–π—Ç–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø–æ–ª–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é `_compute_balance_loss`:

### –§–æ—Ä–º—É–ª–∞:

```
L_balance = Œ± * N * Œ£ (f_i * P_i)
                    i=1..N

–≥–¥–µ:
  Œ± = balance_loss_coef  (0.01)
  N = num_experts        (128)
  f_i = frequency        (–¥–æ–ª—è —Ç–æ–∫–µ–Ω–æ–≤, –≤—ã–±—Ä–∞–≤—à–∏—Ö —ç–∫—Å–ø–µ—Ä—Ç–∞ i)
  P_i = mean probability (—Å—Ä–µ–¥–Ω–∏–π gating score —ç–∫—Å–ø–µ—Ä—Ç–∞ i)
```

### –®–∞–≥–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:

```python
def _compute_balance_loss(
    self,
    gating_scores: torch.Tensor,      # (batch_size, seq_len, num_experts)
    selected_experts: torch.Tensor    # (batch_size, seq_len, top_k)
) -> torch.Tensor:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç load balancing loss.

    –§–æ—Ä–º—É–ª–∞: L = balance_loss_coef * num_experts * Œ£(f_i * P_i)

    Args:
        gating_scores: Softmax –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        selected_experts: –ò–Ω–¥–µ–∫—Å—ã –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö top-k —ç–∫—Å–ø–µ—Ä—Ç–æ–≤

    Returns:
        balance_loss: –°–∫–∞–ª—è—Ä —Ç–µ–Ω–∑–æ—Ä
    """
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –®–∞–≥ 1: –í—ã—á–∏—Å–ª—è–µ–º frequency (f_i) ‚Äî –¥–æ–ª—è —Ç–æ–∫–µ–Ω–æ–≤ per —ç–∫—Å–ø–µ—Ä—Ç
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    # Flatten –∏–Ω–¥–µ–∫—Å–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
    flattened_experts = selected_experts.view(-1)  # (B*S*K,)

    # –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç
    expert_counts = torch.bincount(
        flattened_experts,
        minlength=self.num_experts
    )  # (num_experts,)

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤ –¥–æ–ª–∏
    batch_size, seq_len, top_k = selected_experts.shape
    total_selections = batch_size * seq_len * top_k
    frequency = expert_counts.float() / total_selections  # (num_experts,)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –®–∞–≥ 2: –í—ã—á–∏—Å–ª—è–µ–º mean probability (P_i) ‚Äî —Å—Ä–µ–¥–Ω–∏–π –≤–µ—Å —ç–∫—Å–ø–µ—Ä—Ç–∞
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    # gating_scores: (batch_size, seq_len, num_experts)
    # –£—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ batch –∏ seq dimensions
    mean_prob = gating_scores.mean(dim=[0, 1])  # (num_experts,)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –®–∞–≥ 3: –í—ã—á–∏—Å–ª—è–µ–º loss = Œ± * N * Œ£(f_i * P_i)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    # –ü–æ—ç–ª–µ–º–µ–Ω—Ç–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∏ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ
    balance_loss = self.balance_loss_coef * self.num_experts * (frequency * mean_prob).sum()

    return balance_loss  # –°–∫–∞–ª—è—Ä
```

### –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞:

#### –®–∞–≥ 1: Frequency (f_i)

```python
# –ü—Ä–∏–º–µ—Ä –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ—Å–ª–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è:
frequency = tensor([
    0.000,  # –≠–∫—Å–ø–µ—Ä—Ç 0: 0% —Ç–æ–∫–µ–Ω–æ–≤
    0.000,  # –≠–∫—Å–ø–µ—Ä—Ç 1: 0% —Ç–æ–∫–µ–Ω–æ–≤
    0.000,  # –≠–∫—Å–ø–µ—Ä—Ç 2: 0% —Ç–æ–∫–µ–Ω–æ–≤
    0.000,  # –≠–∫—Å–ø–µ—Ä—Ç 3: 0% —Ç–æ–∫–µ–Ω–æ–≤
    0.125,  # –≠–∫—Å–ø–µ—Ä—Ç 4: 12.5% —Ç–æ–∫–µ–Ω–æ–≤ ‚úì
    0.000,  # –≠–∫—Å–ø–µ—Ä—Ç 5: 0% —Ç–æ–∫–µ–Ω–æ–≤
    0.000,  # –≠–∫—Å–ø–µ—Ä—Ç 6: 0% —Ç–æ–∫–µ–Ω–æ–≤
    0.113,  # –≠–∫—Å–ø–µ—Ä—Ç 7: 11.3% —Ç–æ–∫–µ–Ω–æ–≤ ‚úì
    ...
])

# –ò–¥–µ–∞–ª—å–Ω–æ: f_i ‚âà 1/128 ‚âà 0.0078 –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
# –ù–æ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –±—É–¥—É—Ç —Ä–∞–∑–ª–∏—á–∏—è
```

#### –®–∞–≥ 2: Mean Probability (P_i)

```python
# gating_scores: (batch_size=2, seq_len=10, num_experts=128)

# –£—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ batch –∏ seq:
mean_prob = gating_scores.mean(dim=[0, 1])  # (128,)

# –ü—Ä–∏–º–µ—Ä –∑–Ω–∞—á–µ–Ω–∏–π:
mean_prob = tensor([
    0.0075,  # –≠–∫—Å–ø–µ—Ä—Ç 0: —Å—Ä–µ–¥–Ω–∏–π gating score
    0.0076,  # –≠–∫—Å–ø–µ—Ä—Ç 1
    0.0077,  # –≠–∫—Å–ø–µ—Ä—Ç 2
    0.0078,  # –≠–∫—Å–ø–µ—Ä—Ç 3
    0.0085,  # –≠–∫—Å–ø–µ—Ä—Ç 4: –≤—ã—Å–æ–∫–∏–π —Å—Ä–µ–¥–Ω–∏–π score ‚úì
    0.0074,  # –≠–∫—Å–ø–µ—Ä—Ç 5
    0.0073,  # –≠–∫—Å–ø–µ—Ä—Ç 6
    0.0082,  # –≠–∫—Å–ø–µ—Ä—Ç 7: –≤—ã—Å–æ–∫–∏–π —Å—Ä–µ–¥–Ω–∏–π score ‚úì
    ...
])

# –ò–¥–µ–∞–ª—å–Ω–æ: –≤—Å–µ P_i ‚âà 1/128 ‚âà 0.0078
```

#### –®–∞–≥ 3: Balance Loss

```python
# –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ f_i * P_i –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞:
product = frequency * mean_prob

# –ü—Ä–∏–º–µ—Ä:
product = tensor([
    0.000 * 0.0075 = 0.000000,  # –≠–∫—Å–ø–µ—Ä—Ç 0
    0.000 * 0.0076 = 0.000000,  # –≠–∫—Å–ø–µ—Ä—Ç 1
    ...
    0.125 * 0.0085 = 0.001063,  # –≠–∫—Å–ø–µ—Ä—Ç 4: –≤—ã—Å–æ–∫–∏–π –≤–∫–ª–∞–¥ –≤ loss!
    ...
    0.113 * 0.0082 = 0.000927,  # –≠–∫—Å–ø–µ—Ä—Ç 7: –≤—ã—Å–æ–∫–∏–π –≤–∫–ª–∞–¥ –≤ loss!
    ...
])

# –°—É–º–º–∏—Ä—É–µ–º:
sum_product = product.sum()  # –ù–∞–ø—Ä–∏–º–µ—Ä: 0.0234

# –£–º–Ω–æ–∂–∞–µ–º –Ω–∞ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã:
balance_loss = 0.01 * 128 * 0.0234 = 0.0300
#              ‚Üë     ‚Üë     ‚Üë
#              Œ±     N     Œ£(f_i * P_i)
```

### –ò–Ω—Ç—É–∏—Ü–∏—è –∑–∞ —Ñ–æ—Ä–º—É–ª–æ–π:

**–¶–µ–ª—å:** –°–¥–µ–ª–∞—Ç—å –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ `f_i * P_i` –º–∞–ª–µ–Ω—å–∫–∏–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞.

```
–ï—Å–ª–∏ —ç–∫—Å–ø–µ—Ä—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —á–∞—Å—Ç–æ (–≤—ã—Å–æ–∫–∏–π f_i) –ò –∏–º–µ–µ—Ç –≤—ã—Å–æ–∫–∏–π —Å—Ä–µ–¥–Ω–∏–π score (–≤—ã—Å–æ–∫–∏–π P_i):
  ‚Üí –ü—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ f_i * P_i –±—É–¥–µ—Ç –±–æ–ª—å—à–∏–º
  ‚Üí Balance loss –±—É–¥–µ—Ç –±–æ–ª—å—à–∏–º
  ‚Üí –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –∑–∞—Å—Ç–∞–≤—è—Ç –º–æ–¥–µ–ª—å —Å–Ω–∏–∑–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —ç—Ç–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞

–ï—Å–ª–∏ –≤—Å–µ —ç–∫—Å–ø–µ—Ä—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ:
  ‚Üí f_i ‚âà P_i ‚âà 1/N –¥–ª—è –≤—Å–µ—Ö i
  ‚Üí Œ£(f_i * P_i) ‚âà N * (1/N) * (1/N) = 1/N
  ‚Üí Balance loss –º–∏–Ω–∏–º–∞–ª–µ–Ω ‚úì
```

---

## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä

### –ü–æ–ª–Ω—ã–π —Ä–∞–±–æ—á–∏–π –∫–æ–¥:

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class MoERouterExample(nn.Module):
    def __init__(self, num_experts=128, balance_loss_coef=0.01):
        super().__init__()
        self.num_experts = num_experts
        self.balance_loss_coef = balance_loss_coef

    def _compute_balance_loss(
        self,
        gating_scores: torch.Tensor,
        selected_experts: torch.Tensor
    ) -> torch.Tensor:
        """–í—ã—á–∏—Å–ª—è–µ—Ç load balancing loss."""

        print("="*70)
        print("–í–´–ß–ò–°–õ–ï–ù–ò–ï LOAD BALANCING LOSS")
        print("="*70)

        # –®–∞–≥ 1: Frequency
        print("\n[–®–∞–≥ 1] –í—ã—á–∏—Å–ª–µ–Ω–∏–µ frequency (f_i)")
        print("-"*70)

        flattened_experts = selected_experts.view(-1)
        print(f"  Flattened shape: {flattened_experts.shape}")
        print(f"  –ü–µ—Ä–≤—ã–µ 20 –∏–Ω–¥–µ–∫—Å–æ–≤: {flattened_experts[:20]}")

        expert_counts = torch.bincount(
            flattened_experts,
            minlength=self.num_experts
        )
        print(f"\n  Expert counts shape: {expert_counts.shape}")
        print(f"  –ù–µ–Ω—É–ª–µ–≤—ã–µ counts:")
        nonzero_idx = expert_counts.nonzero().squeeze()
        for idx in nonzero_idx[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
            print(f"    –≠–∫—Å–ø–µ—Ä—Ç {idx:3d}: –≤—ã–±—Ä–∞–Ω {expert_counts[idx]:2d} —Ä–∞–∑")

        batch_size, seq_len, top_k = selected_experts.shape
        total_selections = batch_size * seq_len * top_k
        frequency = expert_counts.float() / total_selections

        print(f"\n  Total selections: {total_selections}")
        print(f"  Frequency shape: {frequency.shape}")
        print(f"  –ù–µ–Ω—É–ª–µ–≤—ã–µ frequencies:")
        for idx in nonzero_idx[:10]:
            print(f"    f_{idx:3d} = {frequency[idx]:.6f} ({frequency[idx]*100:.2f}%)")

        # –®–∞–≥ 2: Mean Probability
        print(f"\n[–®–∞–≥ 2] –í—ã—á–∏—Å–ª–µ–Ω–∏–µ mean probability (P_i)")
        print("-"*70)

        mean_prob = gating_scores.mean(dim=[0, 1])
        print(f"  Gating scores shape: {gating_scores.shape}")
        print(f"  Mean prob shape: {mean_prob.shape}")
        print(f"  Mean prob (–ø–µ—Ä–≤—ã–µ 10):")
        for i in range(10):
            print(f"    P_{i:3d} = {mean_prob[i]:.6f}")

        # –®–∞–≥ 3: Balance Loss
        print(f"\n[–®–∞–≥ 3] –í—ã—á–∏—Å–ª–µ–Ω–∏–µ balance loss")
        print("-"*70)

        product = frequency * mean_prob
        print(f"  Product f_i * P_i (–Ω–µ–Ω—É–ª–µ–≤—ã–µ):")
        for idx in nonzero_idx[:10]:
            print(f"    f_{idx:3d} * P_{idx:3d} = {frequency[idx]:.6f} * {mean_prob[idx]:.6f} = {product[idx]:.8f}")

        sum_product = product.sum()
        balance_loss = self.balance_loss_coef * self.num_experts * sum_product

        print(f"\n  Œ£(f_i * P_i) = {sum_product:.8f}")
        print(f"  balance_loss_coef = {self.balance_loss_coef}")
        print(f"  num_experts = {self.num_experts}")
        print(f"  Balance Loss = {self.balance_loss_coef} * {self.num_experts} * {sum_product:.8f}")
        print(f"               = {balance_loss:.8f}")

        print("\n" + "="*70 + "\n")

        return balance_loss


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# –°–æ–∑–¥–∞–µ–º router
router = MoERouterExample(num_experts=128, balance_loss_coef=0.01)

# –°–∏–º—É–ª–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
batch_size, seq_len, num_experts = 2, 10, 128
top_k = 8

# –°–ª—É—á–∞–π–Ω—ã–µ gating scores (–ø–æ—Å–ª–µ softmax)
gating_scores = torch.rand(batch_size, seq_len, num_experts)
gating_scores = F.softmax(gating_scores, dim=-1)

# –í—ã–±–∏—Ä–∞–µ–º top-k —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
_, selected_experts = torch.topk(gating_scores, k=top_k, dim=-1)

print(f"Input shapes:")
print(f"  gating_scores: {gating_scores.shape}")
print(f"  selected_experts: {selected_experts.shape}\n")

# –í—ã—á–∏—Å–ª—è–µ–º balance loss
balance_loss = router._compute_balance_loss(gating_scores, selected_experts)

print(f"–§–ò–ù–ê–õ–¨–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢:")
print(f"  Balance Loss = {balance_loss.item():.8f}")
```

### –û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:

```
Input shapes:
  gating_scores: torch.Size([2, 10, 128])
  selected_experts: torch.Size([2, 10, 8])

======================================================================
–í–´–ß–ò–°–õ–ï–ù–ò–ï LOAD BALANCING LOSS
======================================================================

[–®–∞–≥ 1] –í—ã—á–∏—Å–ª–µ–Ω–∏–µ frequency (f_i)
----------------------------------------------------------------------
  Flattened shape: torch.Size([160])
  –ü–µ—Ä–≤—ã–µ 20 –∏–Ω–¥–µ–∫—Å–æ–≤: tensor([105,  46,  83,  16,  89,  80,  18,  92, 105,  83,  46,  89,  16,
         92,  18,  80,  83, 105,  46,  89])

  Expert counts shape: torch.Size([128])
  –ù–µ–Ω—É–ª–µ–≤—ã–µ counts:
    –≠–∫—Å–ø–µ—Ä—Ç   0: –≤—ã–±—Ä–∞–Ω  2 —Ä–∞–∑
    –≠–∫—Å–ø–µ—Ä—Ç   1: –≤—ã–±—Ä–∞–Ω  1 —Ä–∞–∑
    –≠–∫—Å–ø–µ—Ä—Ç   3: –≤—ã–±—Ä–∞–Ω  2 —Ä–∞–∑
    –≠–∫—Å–ø–µ—Ä—Ç   4: –≤—ã–±—Ä–∞–Ω  1 —Ä–∞–∑
    –≠–∫—Å–ø–µ—Ä—Ç   5: –≤—ã–±—Ä–∞–Ω  1 —Ä–∞–∑
    –≠–∫—Å–ø–µ—Ä—Ç   6: –≤—ã–±—Ä–∞–Ω  2 —Ä–∞–∑
    –≠–∫—Å–ø–µ—Ä—Ç   7: –≤—ã–±—Ä–∞–Ω  1 —Ä–∞–∑
    –≠–∫—Å–ø–µ—Ä—Ç   9: –≤—ã–±—Ä–∞–Ω  1 —Ä–∞–∑
    –≠–∫—Å–ø–µ—Ä—Ç  10: –≤—ã–±—Ä–∞–Ω  2 —Ä–∞–∑
    –≠–∫—Å–ø–µ—Ä—Ç  12: –≤—ã–±—Ä–∞–Ω  1 —Ä–∞–∑

  Total selections: 160
  Frequency shape: torch.Size([128])
  –ù–µ–Ω—É–ª–µ–≤—ã–µ frequencies:
    f_  0 = 0.012500 (1.25%)
    f_  1 = 0.006250 (0.62%)
    f_  3 = 0.012500 (1.25%)
    f_  4 = 0.006250 (0.62%)
    f_  5 = 0.006250 (0.62%)
    f_  6 = 0.012500 (1.25%)
    f_  7 = 0.006250 (0.62%)
    f_  9 = 0.006250 (0.62%)
    f_ 10 = 0.012500 (1.25%)
    f_ 12 = 0.006250 (0.62%)

[–®–∞–≥ 2] –í—ã—á–∏—Å–ª–µ–Ω–∏–µ mean probability (P_i)
----------------------------------------------------------------------
  Gating scores shape: torch.Size([2, 10, 128])
  Mean prob shape: torch.Size([128])
  Mean prob (–ø–µ—Ä–≤—ã–µ 10):
    P_  0 = 0.007889
    P_  1 = 0.007812
    P_  2 = 0.007734
    P_  3 = 0.007856
    P_  4 = 0.007801
    P_  5 = 0.007823
    P_  6 = 0.007845
    P_  7 = 0.007867
    P_  8 = 0.007889
    P_  9 = 0.007801

[–®–∞–≥ 3] –í—ã—á–∏—Å–ª–µ–Ω–∏–µ balance loss
----------------------------------------------------------------------
  Product f_i * P_i (–Ω–µ–Ω—É–ª–µ–≤—ã–µ):
    f_  0 * P_  0 = 0.012500 * 0.007889 = 0.00009861
    f_  1 * P_  1 = 0.006250 * 0.007812 = 0.00004882
    f_  3 * P_  3 = 0.012500 * 0.007856 = 0.00009820
    f_  4 * P_  4 = 0.006250 * 0.007801 = 0.00004876
    f_  5 * P_  5 = 0.006250 * 0.007823 = 0.00004889
    f_  6 * P_  6 = 0.012500 * 0.007845 = 0.00009806
    f_  7 * P_  7 = 0.006250 * 0.007867 = 0.00004917
    f_  9 * P_  9 = 0.006250 * 0.007801 = 0.00004876
    f_ 10 * P_ 10 = 0.012500 * 0.007834 = 0.00009792
    f_ 12 * P_ 12 = 0.006250 * 0.007789 = 0.00004868

  Œ£(f_i * P_i) = 0.00781250
  balance_loss_coef = 0.01
  num_experts = 128
  Balance Loss = 0.01 * 128 * 0.00781250
               = 0.10000000

======================================================================

–§–ò–ù–ê–õ–¨–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢:
  Balance Loss = 0.10000000
```

---

## –†–µ–∑—é–º–µ

### –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:

1. **Frequency (f_i)** –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–æ–ª—é —Ç–æ–∫–µ–Ω–æ–≤, –≤—ã–±—Ä–∞–≤—à–∏—Ö –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
   - –í—ã—á–∏—Å–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ `torch.bincount` (–±—ã—Å—Ç—Ä–µ–µ) –∏–ª–∏ one-hot encoding (–Ω–∞–≥–ª—è–¥–Ω–µ–µ)
   - –†–µ–∑—É–ª—å—Ç–∞—Ç: —Ç–µ–Ω–∑–æ—Ä —Ñ–æ—Ä–º—ã `(num_experts,)` —Å —Å—É–º–º–æ–π ‚âà top_k

2. **Load Balancing Loss** –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–ª–∞–ø—Å —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
   - –§–æ—Ä–º—É–ª–∞: `Œ± * N * Œ£(f_i * P_i)`
   - –ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç—Å—è, –∫–æ–≥–¥–∞ –≤—Å–µ —ç–∫—Å–ø–µ—Ä—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ

3. **–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `torch.bincount`** –¥–ª—è production –∫–æ–¥–∞
   - –ë—ã—Å—Ç—Ä–µ–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ –ø–æ –ø–∞–º—è—Ç–∏
   - –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è (3 —Å—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞)

### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:

–ü–æ—Å–ª–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è frequency, –Ω—É–∂–Ω–æ:
1. –í—ã—á–∏—Å–ª–∏—Ç—å mean probability (P_i): `gating_scores.mean(dim=[0, 1])`
2. –í—ã—á–∏—Å–ª–∏—Ç—å loss: `balance_loss_coef * num_experts * (frequency * mean_prob).sum()`
3. –í–µ—Ä–Ω—É—Ç—å balance_loss –∏–∑ –º–µ—Ç–æ–¥–∞ `_compute_balance_loss`

---

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è**: 2025-10-02
**–ê–≤—Ç–æ—Ä**: AI Teacher –¥–ª—è Qwen3 MoE Project
**–°–≤—è–∑–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã**:
- `experiments/domain/moe/router.py`
- `experiments/domain/moe/MoE_Router_Gate_Initialization.md`
