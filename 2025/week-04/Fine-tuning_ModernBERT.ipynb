{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7080c94a",
   "metadata": {},
   "source": [
    "# –î–æ–æ–±—É—á–µ–Ω–∏–µ ModernBERT –Ω–∞ –º—É–ª—å—Ç–∏–ª–µ–π–±–ª –¥–∞—Ç–∞—Å–µ—Ç–µ üöÄ\n",
    "\n",
    "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–¥ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ **ModernBERT** –Ω–∞ –∑–∞–¥–∞—á–µ –º–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤. –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ, —Å–æ–¥–µ—Ä–∂–∞—â–µ–º —Ç–µ–∫—Å—Ç—ã –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–º –±–∏–Ω–∞—Ä–Ω—ã–µ –º–µ—Ç–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π.\n",
    "\n",
    "## üìå –û—Å–Ω–æ–≤–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏\n",
    "\n",
    "- üß† **–ú–æ–¥–µ–ª—å**: ModernBERT (—Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è BERT —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π)\n",
    "- üè∑Ô∏è **–ó–∞–¥–∞—á–∞**: –ú–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤\n",
    "- üöÄ **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–∏–∫ –æ–±—É—á–µ–Ω–∏—è, —Ç–∞–∫–∏—Ö –∫–∞–∫:\n",
    "  - –ì–∏–±—Ä–∏–¥–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ (–ª–æ–∫–∞–ª—å–Ω–æ–µ + –≥–ª–æ–±–∞–ª—å–Ω–æ–µ)\n",
    "  - Rotary Position Embedding (RoPE) –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤\n",
    "  - GeGLU –∞–∫—Ç–∏–≤–∞—Ü–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –º–æ–¥–µ–ª–∏\n",
    "- üíª **–£—Å–∫–æ—Ä–µ–Ω–∏–µ**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Å–º–µ—à–∞–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ (FP16) –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "## üìä –û–ø–∏—Å–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "\n",
    "### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "- **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π**: 35,303\n",
    "- **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤**: 20\n",
    "\n",
    "### –ù–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤\n",
    "1. `—Ç–µ–∫—Å—Ç` - –¢–µ–∫—Å—Ç –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "2. `–æ—Ñ–ª–∞–π–Ω_–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –æ—Ñ–ª–∞–π–Ω-–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏–π\n",
    "3. `–æ–Ω–ª–∞–π–Ω_–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –æ–Ω–ª–∞–π–Ω-–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏–π\n",
    "4. `–Ω–∞—Ä–∫–æ—Ç–∏–∫–∏` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –Ω–∞—Ä–∫–æ—Ç–∏–∫–æ–≤\n",
    "5. `–∞–∑–∞—Ä—Ç–Ω—ã–µ_–∏–≥—Ä—ã` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∞–∑–∞—Ä—Ç–Ω—ã—Ö –∏–≥—Ä\n",
    "6. `–ø–æ—Ä–Ω–æ–≥—Ä–∞—Ñ–∏—è` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø–æ—Ä–Ω–æ–≥—Ä–∞—Ñ–∏–∏\n",
    "7. `–ø—Ä–æ—Å—Ç–∏—Ç—É—Ü–∏—è` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–∏—Ç—É—Ü–∏–∏\n",
    "8. `—Ä–∞–±—Å—Ç–≤–æ` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ä–∞–±—Å—Ç–≤–∞\n",
    "9. `—Å–∞–º–æ—É–±–∏–π—Å—Ç–≤–æ` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Å–∞–º–æ—É–±–∏–π—Å—Ç–≤–∞\n",
    "10. `—Ç–µ—Ä—Ä–æ—Ä–∏–∑–º` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ç–µ—Ä—Ä–æ—Ä–∏–∑–º–∞\n",
    "11. `–æ—Ä—É–∂–∏–µ` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –æ—Ä—É–∂–∏—è\n",
    "12. `–±–æ–¥–∏—à–µ–π–º–∏–Ω–≥` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –±–æ–¥–∏—à–µ–π–º–∏–Ω–≥–∞\n",
    "13. `—Ö–µ–π—Ç—Å–ø–∏—á` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ö–µ–π—Ç—Å–ø–∏—á–∞\n",
    "14. `–ø–æ–ª–∏—Ç–∏–∫–∞` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø–æ–ª–∏—Ç–∏–∫–∏\n",
    "15. `—Ä–∞—Å–∏–∑–º` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ä–∞—Å–∏–∑–º–∞\n",
    "16. `—Ä–µ–ª–∏–≥–∏—è` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ä–µ–ª–∏–≥–∏–∏\n",
    "17. `—Å–µ–∫—Å—É–∞–ª—å–Ω—ã–µ_–º–µ–Ω—å—à–∏–Ω—Å—Ç–≤–∞` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Å–µ–∫—Å—É–∞–ª—å–Ω—ã—Ö –º–µ–Ω—å—à–∏–Ω—Å—Ç–≤\n",
    "18. `—Å–µ–∫—Å–∏–∑–º` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Å–µ–∫—Å–∏–∑–º–∞\n",
    "19. `—Å–æ—Ü–∏–∞–ª—å–Ω–∞—è_–Ω–µ—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–π –Ω–µ—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏\n",
    "20. `–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π` - –ü—Ä–∏–∑–Ω–∞–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç\n",
    "\n",
    "### –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö\n",
    "- **–¢–µ–∫—Å—Ç**: `object` (1 –∫–æ–ª–æ–Ω–∫–∞)\n",
    "- **–ú–µ—Ç–∫–∏**: `float64` (19 –∫–æ–ª–æ–Ω–æ–∫)\n",
    "\n",
    "## üõ†Ô∏è –û—Å–Ω–æ–≤–Ω—ã–µ —à–∞–≥–∏\n",
    "\n",
    "1. **–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö**: –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞.\n",
    "2. **–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è**: –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç, –ø–æ–¥—Ö–æ–¥—è—â–∏–π –¥–ª—è –º–æ–¥–µ–ª–∏.\n",
    "3. **–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏**: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ ModernBERT —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π –¥–ª—è –º–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.\n",
    "4. **–û–±—É—á–µ–Ω–∏–µ**: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–∏–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.\n",
    "5. **–û—Ü–µ–Ω–∫–∞**: –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ.\n",
    "6. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏**: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.\n",
    "\n",
    "## üìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "\n",
    "–í –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏:\n",
    "- **Hamming Loss**: –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ –≤—Å–µ–º –º–µ—Ç–∫–∞–º.\n",
    "- **Subset Accuracy**: –¢–æ—á–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤—Å–µ—Ö –º–µ—Ç–æ–∫ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ.\n",
    "- **Macro Precision/Recall/F1**: –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è precision, recall –∏ F1 –ø–æ –≤—Å–µ–º –º–µ—Ç–∫–∞–º.\n",
    "- **Micro F1**: F1-–º–µ—Ä–∞, –≤—ã—á–∏—Å–ª–µ–Ω–Ω–∞—è —Å —É—á–µ—Ç–æ–º –≤—Å–µ—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ –∏—Å—Ç–∏–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫.\n",
    "- **Jaccard Score**: –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º–∏ –∏ –∏—Å—Ç–∏–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏.\n",
    "\n",
    "## üöÄ –ó–∞–ø—É—Å–∫\n",
    "\n",
    "–î–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ:\n",
    "1. –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.\n",
    "2. –£–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.\n",
    "3. –ó–∞–ø—É—Å—Ç–∏—Ç—å –Ω–æ—É—Ç–±—É–∫ –∏ –¥–æ–∂–¥–∞—Ç—å—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è.\n",
    "\n",
    "---\n",
    "\n",
    "<p align=\"center\">‚ö° –ü—Ä–µ–æ–±—Ä–∞–∑–∏—Ç–µ –≤–∞—à NLP-–ø–∞–π–ø–ª–∞–π–Ω —Å ModernBERT —É–∂–µ —Å–µ–≥–æ–¥–Ω—è!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c96e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q numpy==1.26\n",
    "!pip install -q packaging\n",
    "!pip install -q torch==2.1.0 torchvision==0.16.0\n",
    "!pip install -q setuptools scikit-learn\n",
    "!pip install --upgrade -q  datasets==3.1.0 accelerate==1.2.1\n",
    "!pip install -q \"git+https://github.com/huggingface/transformers.git@6e0515e99c39444caae39472ee1b2fd76ece32f1\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c542b8-49d6-41d8-8543-6f967ca21996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 31 10:27:49 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   49C    P0             408W / 700W |  76034MiB / 81559MiB |     92%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA H100 80GB HBM3          On  | 00000000:82:00.0 Off |                    0 |\n",
      "| N/A   45C    P0             393W / 700W |  73425MiB / 81559MiB |     92%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA H100 80GB HBM3          On  | 00000000:83:00.0 Off |                    0 |\n",
      "| N/A   44C    P0             384W / 700W |  73105MiB / 81559MiB |     92%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA H100 80GB HBM3          On  | 00000000:84:00.0 Off |                    0 |\n",
      "| N/A   54C    P0             414W / 700W |  73105MiB / 81559MiB |     93%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA H100 80GB HBM3          On  | 00000000:91:00.0 Off |                    0 |\n",
      "| N/A   28C    P0              75W / 700W |      3MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA H100 80GB HBM3          On  | 00000000:92:00.0 Off |                    0 |\n",
      "| N/A   26C    P0              72W / 700W |      3MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA H100 80GB HBM3          On  | 00000000:93:00.0 Off |                    0 |\n",
      "| N/A   27C    P0              70W / 700W |      3MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA H100 80GB HBM3          On  | 00000000:94:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             113W / 700W |   6563MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   3558748      C   /usr/bin/python3                           4204MiB |\n",
      "|    0   N/A  N/A   4139947      C   /opt/conda/bin/python3.11                 71814MiB |\n",
      "|    1   N/A  N/A   4139948      C   /opt/conda/bin/python3.11                 73414MiB |\n",
      "|    2   N/A  N/A   4139949      C   /opt/conda/bin/python3.11                 73094MiB |\n",
      "|    3   N/A  N/A   4139950      C   /opt/conda/bin/python3.11                 73094MiB |\n",
      "|    7   N/A  N/A   3380383      C   /home/ubuntu/speaches/.venv/bin/python     6554MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c9db82-20be-497c-a314-85766d28fd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/username/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Python\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    hamming_loss,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    jaccard_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# PyTorch –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification\n",
    ")\n",
    "\n",
    "# Typing\n",
    "from typing import Dict, List, Optional, Tuple, Union, Any\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CUDA\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "torch._dynamo.config.disable = True\n",
    "\n",
    "\n",
    "class MultiLabelTextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∫–ª–∞—Å—Å –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –º–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤.\n",
    "        \n",
    "    Args:\n",
    "        texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "        labels: –ú–∞—Å—Å–∏–≤ –º–µ—Ç–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–∞\n",
    "        tokenizer: –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤\n",
    "        max_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞\n",
    "        \n",
    "    Returns:\n",
    "        –û–±—ä–µ–∫—Ç Dataset –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å DataLoader\n",
    "        \n",
    "    Examples:\n",
    "        >>> dataset = MultiLabelTextDataset(\n",
    "        ...     texts=['—Ç–µ–∫—Å—Ç1', '—Ç–µ–∫—Å—Ç2'],\n",
    "        ...     labels=np.array([[1, 0], [0, 1]]),\n",
    "        ...     tokenizer=tokenizer,\n",
    "        ...     max_length=512\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        labels: np.ndarray,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        max_length: int = 512\n",
    "    ) -> None:\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –∞—Ç—Ä–∏–±—É—Ç—ã –∫–ª–∞—Å—Å–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ __getitem__\n",
    "        self.texts      = texts\n",
    "        self.labels     = labels\n",
    "        self.tokenizer  = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–æ–≤)\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∏ –º–µ—Ç–∫–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É\n",
    "        text = str(self.texts[idx])\n",
    "        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–µ—Ç–∫–∏ –≤ float32 –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏\n",
    "        labels = self.labels[idx].astype(np.float32)\n",
    "\n",
    "        # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,     # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã ([CLS], [SEP] –∏ —Ç.–¥.)\n",
    "            max_length=self.max_length,  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "            padding='max_length',        # –î–æ–ø–æ–ª–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–æ max_length\n",
    "            truncation=True,             # –û–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç—ã, –ø—Ä–µ–≤—ã—à–∞—é—â–∏–µ max_length\n",
    "            return_tensors='pt'          # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–Ω–∑–æ—Ä—ã PyTorch –≤–º–µ—Å—Ç–æ —Å–ø–∏—Å–∫–æ–≤\n",
    "        )\n",
    "\n",
    "        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å –≤—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ –º–µ—Ç–∫–∞–º–∏\n",
    "        return {\n",
    "            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–Ω–∑–æ—Ä —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (1, max_length) –≤ (max_length,)\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            \n",
    "            # attention_mask: 1 –¥–ª—è –Ω–∞—Å—Ç–æ—è—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤, 0 –¥–ª—è padding —Ç–æ–∫–µ–Ω–æ–≤\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            \n",
    "            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º numpy –º–∞—Å—Å–∏–≤ –º–µ—Ç–æ–∫ –≤ —Ç–µ–Ω–∑–æ—Ä PyTorch\n",
    "            'labels': torch.FloatTensor(labels)\n",
    "        }\n",
    "\n",
    "\n",
    "def load_data(\n",
    "    data_path: str,\n",
    "    text_column: str = '—Ç–µ–∫—Å—Ç'\n",
    ") -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ CSV —Ñ–∞–π–ª–∞.\n",
    "        \n",
    "    Args:\n",
    "        data_path: –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏\n",
    "        text_column: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å —Ç–µ–∫—Å—Ç–∞–º–∏\n",
    "        \n",
    "    Returns:\n",
    "        –ö–æ—Ä—Ç–µ–∂ (—Ç–µ–∫—Å—Ç—ã, –º–µ—Ç–∫–∏, –Ω–∞–∑–≤–∞–Ω–∏—è_–º–µ—Ç–æ–∫)\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω\n",
    "    \"\"\"\n",
    "    print(f\"\\n–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {data_path}...\")\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –º–µ—Ç–æ–∫\n",
    "    texts = df[text_column].values\n",
    "    label_columns = [col for col in df.columns if col != text_column]\n",
    "    labels = df[label_columns].values\n",
    "    \n",
    "    print(f\"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(texts)} –∑–∞–ø–∏—Å–µ–π —Å {len(label_columns)} –º–µ—Ç–∫–∞–º–∏\")\n",
    "    return texts, labels, label_columns\n",
    "\n",
    "\n",
    "def evaluate_multilabel(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    label_columns: Optional[List[str]] = None\n",
    ") -> Dict[str, Union[float, Dict[str, Dict[str, float]]]]:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        –í—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –º—É–ª—å—Ç–∏–ª–µ–π–±–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.\n",
    "        \n",
    "    Args:\n",
    "        y_true: –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏\n",
    "        y_pred: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏\n",
    "        label_columns: –ù–∞–∑–≤–∞–Ω–∏—è –º–µ—Ç–æ–∫ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏\n",
    "        \n",
    "    Returns:\n",
    "        –°–ª–æ–≤–∞—Ä—å —Å –æ–±—â–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø–æ –∫–∞–∂–¥–æ–π –º–µ—Ç–∫–µ\n",
    "    \"\"\"\n",
    "    # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –º—É–ª—å—Ç–∏–ª–µ–π–±–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "    metrics = {\n",
    "        'hamming_loss':    hamming_loss(y_true, y_pred),\n",
    "        'subset_accuracy': accuracy_score(y_true, y_pred),\n",
    "        'macro_precision': precision_score(y_true, y_pred, average='macro'),\n",
    "        'macro_recall':    recall_score(y_true, y_pred, average='macro'),\n",
    "        'macro_f1':        f1_score(y_true, y_pred, average='macro'),\n",
    "        'micro_f1':        f1_score(y_true, y_pred, average='micro'),\n",
    "        'samples_f1':      f1_score(y_true, y_pred, average='samples'),\n",
    "        'jaccard_score':   jaccard_score(y_true, y_pred, average='samples')\n",
    "    }\n",
    "    \n",
    "    # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º –º–µ—Ç–∫–∞–º\n",
    "    if label_columns is not None:\n",
    "        per_label_metrics = {}\n",
    "        for i, label in enumerate(label_columns):\n",
    "            per_label_metrics[label] = {\n",
    "                'precision': precision_score(y_true[:, i], y_pred[:, i]),\n",
    "                'recall': recall_score(y_true[:, i], y_pred[:, i]),\n",
    "                'f1': f1_score(y_true[:, i], y_pred[:, i])\n",
    "            }\n",
    "        metrics['per_label'] = per_label_metrics\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "class MultilabelClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        –ú–æ–¥–µ–ª—å –º–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ ModernBERT.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "        num_labels (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ç–æ–∫ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    Examples:\n",
    "        >>> model = MultilabelClassifier(\"bert-base-uncased\", 3)\n",
    "        >>> input_ids = torch.tensor([[101, 2054, 2003, 102]])\n",
    "        >>> attention_mask = torch.tensor([[1, 1, 1, 1]])\n",
    "        >>> labels = torch.tensor([[1, 0, 1]])\n",
    "        >>> outputs = model(input_ids, attention_mask, labels)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str, num_labels: int) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å BERT —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π –¥–ª—è –º–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "        self.bert = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels,                      # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ö–æ–¥–Ω—ã—Ö –º–µ—Ç–æ–∫\n",
    "            problem_type=\"multi_label_classification\",  # –£–∫–∞–∑—ã–≤–∞–µ–º —Ç–∏–ø –∑–∞–¥–∞—á–∏\n",
    "            ignore_mismatched_sizes=True                # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ\n",
    "        )\n",
    "        # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–ª–æ–π\n",
    "        # –≠—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤ –¥–ª—è –Ω–∞—à–µ–π –∑–∞–¥–∞—á–∏\n",
    "        self.bert.classifier = nn.Linear(\n",
    "            self.bert.config.hidden_size,               # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—ã—Ö–æ–¥–∞ BERT\n",
    "            num_labels                                  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        labels: Optional[torch.Tensor] = None\n",
    "    ) -> Any:\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å.\n",
    "\n",
    "        Args:\n",
    "            input_ids (torch.Tensor): –¢–µ–Ω–∑–æ—Ä –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "            attention_mask (torch.Tensor): –¢–µ–Ω–∑–æ—Ä –º–∞—Å–∫–∏ –≤–Ω–∏–º–∞–Ω–∏—è.\n",
    "            labels (Optional[torch.Tensor]): –¢–µ–Ω–∑–æ—Ä –º–µ—Ç–æ–∫ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ).\n",
    "\n",
    "        Returns:\n",
    "            Any: –í—ã—Ö–æ–¥ –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "        Raises:\n",
    "            None\n",
    "\n",
    "        Examples:\n",
    "            >>> input_ids = torch.tensor([[101, 2054, 2003, 102]])\n",
    "            >>> attention_mask = torch.tensor([[1, 1, 1, 1]])\n",
    "            >>> labels = torch.tensor([[1, 0, 1]])\n",
    "            >>> outputs = model.forward(input_ids, attention_mask, labels)\n",
    "        \"\"\"\n",
    "        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ BERT –∏ –ø–æ–ª—É—á–∞–µ–º –≤—ã—Ö–æ–¥—ã\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,            # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç\n",
    "            attention_mask=attention_mask,  # –ú–∞—Å–∫–∞ –¥–ª—è —Ä–∞–∑–ª–∏—á–µ–Ω–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –æ—Ç padding\n",
    "            labels=labels                   # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã –º–µ—Ç–∫–∏, –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è BCE loss\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: MultilabelClassifier,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: torch.optim.lr_scheduler._LRScheduler,\n",
    "    device: torch.device,\n",
    "    num_epochs: int,\n",
    "    patience: int,\n",
    "    output_dir: Path,\n",
    "    label_columns: List[str]\n",
    ") -> MultilabelClassifier:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        –§—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º.\n",
    "        \n",
    "    Args:\n",
    "        model: –ú–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "        train_loader: –ó–∞–≥—Ä—É–∑—á–∏–∫ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "        val_loader: –ó–∞–≥—Ä—É–∑—á–∏–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "        optimizer: –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä\n",
    "        scheduler: –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è\n",
    "        device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (CPU/GPU)\n",
    "        num_epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è\n",
    "        patience: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏\n",
    "        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "        label_columns: –ù–∞–∑–≤–∞–Ω–∏—è –º–µ—Ç–æ–∫\n",
    "        \n",
    "    Returns:\n",
    "        –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å\n",
    "    \"\"\"\n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –¥–ª—è –º–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è\n",
    "    best_val_loss = float('inf')   # –õ—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "    early_stopping_counter = 0     # –°—á–µ—Ç—á–∏–∫ —ç–ø–æ—Ö –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è\n",
    "    \n",
    "    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è\n",
    "    history = {\n",
    "        'train_loss': [],    # –ò—Å—Ç–æ—Ä–∏—è –æ—à–∏–±–æ–∫ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ\n",
    "        'val_loss': [],      # –ò—Å—Ç–æ—Ä–∏—è –æ—à–∏–±–æ–∫ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ\n",
    "        'metrics': []        # –ò—Å—Ç–æ—Ä–∏—è –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "    }\n",
    "    \n",
    "    print(\"\\n–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è –ø–æ —ç–ø–æ—Ö–∞–º\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n–≠–ø–æ—Ö–∞ {epoch + 1}/{num_epochs}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # ===================== –§–ê–ó–ê –û–ë–£–ß–ï–ù–ò–Ø =====================\n",
    "        model.train()  # –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è\n",
    "        train_loss = 0\n",
    "        \n",
    "        print(\"\\n–û–±—É—á–µ–Ω–∏–µ:\")\n",
    "        for batch in tqdm(train_loader, desc='–ü—Ä–æ–≥—Ä–µ—Å—Å'):\n",
    "            # –û–±–Ω—É–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º –±–∞—Ç—á–µ–º\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ü–µ–ª–µ–≤–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            \n",
    "            # –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è\n",
    "            loss.backward()\n",
    "            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–π –æ—à–∏–±–∫–∏ –∑–∞ —ç–ø–æ—Ö—É\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        \n",
    "        # ===================== –§–ê–ó–ê –í–ê–õ–ò–î–ê–¶–ò–ò =====================\n",
    "        model.eval()     # –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏\n",
    "        val_loss = 0\n",
    "        all_preds = []   # –°–ø–∏—Å–æ–∫ –¥–ª—è —Å–±–æ—Ä–∞ –≤—Å–µ—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "        all_labels = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è —Å–±–æ—Ä–∞ –≤—Å–µ—Ö –∏—Å—Ç–∏–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫\n",
    "        \n",
    "        print(\"\\n–í–∞–ª–∏–¥–∞—Ü–∏—è:\")\n",
    "        with torch.no_grad():  # –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤\n",
    "            for batch in tqdm(val_loader, desc='–ü—Ä–æ–≥—Ä–µ—Å—Å'):\n",
    "                # –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ü–µ–ª–µ–≤–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å\n",
    "                loss = criterion(outputs.logits, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ª–æ–≥–∏—Ç–æ–≤ –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∏ —Å–±–æ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "                preds = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–π –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        \n",
    "        # ===================== –í–´–ß–ò–°–õ–ï–ù–ò–ï –ú–ï–¢–†–ò–ö =====================\n",
    "        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤ –±–∏–Ω–∞—Ä–Ω—ã–µ –º–µ—Ç–∫–∏\n",
    "        all_preds = np.array(all_preds) > 0.5\n",
    "        all_labels = np.array(all_labels)\n",
    "        \n",
    "        # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –≤—Å–µ—Ö –º–µ—Ç–æ–∫\n",
    "        metrics = evaluate_multilabel(all_labels, all_preds, label_columns)\n",
    "        history['metrics'].append(metrics)\n",
    "        \n",
    "        # –í—ã–≤–æ–¥ –æ–±—â–∏—Ö –º–µ—Ç—Ä–∏–∫\n",
    "        print(\"\\n–û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –º—É–ª—å—Ç–∏–ª–µ–π–±–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\")\n",
    "        print(\"-\" * 50)\n",
    "        for metric_name, value in metrics.items():\n",
    "            if metric_name != 'per_label':\n",
    "                print(f\"{metric_name:20s}: {value:.4f}\")\n",
    "        \n",
    "        # –í—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫ –ø–æ –∫–∞–∂–¥–æ–π –º–µ—Ç–∫–µ –æ—Ç–¥–µ–ª—å–Ω–æ\n",
    "        print(\"\\n–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º –º–µ—Ç–∫–∞–º:\")\n",
    "        print(\"-\" * 50)\n",
    "        for label, label_metrics in metrics['per_label'].items():\n",
    "            print(f\"{label:25s}:\", end=\" \")\n",
    "            print(\", \".join([\n",
    "                f\"{k}: {v:.4f}\"\n",
    "                for k, v in label_metrics.items()\n",
    "            ]))\n",
    "        \n",
    "        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç–ø–æ—Ö–∏\n",
    "        print(\"\\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–ø–æ—Ö–∏:\")\n",
    "        print(f\"–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è:    {avg_train_loss:.4f}\")\n",
    "        print(f\"–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:   {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # ===================== –†–ê–ù–ù–Ø–Ø –û–°–¢–ê–ù–û–í–ö–ê =====================\n",
    "        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            early_stopping_counter = 0\n",
    "            \n",
    "            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏\n",
    "            print(f\"\\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –≤ {output_dir}/best_model\")\n",
    "            model.bert.save_pretrained(Path(output_dir) / \"best_model\")\n",
    "        else:\n",
    "            # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Å—á–µ—Ç—á–∏–∫–∞ —ç–ø–æ—Ö –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(\"\\n–†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞!\")\n",
    "                break\n",
    "        \n",
    "        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ learning rate –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é\n",
    "        scheduler.step()\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ\n",
    "    history_path = Path(output_dir) / \"training_history.json\"\n",
    "    print(f\"\\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è –≤ {history_path}\")\n",
    "    with open(history_path, \"w\") as f:\n",
    "        json.dump(history, f)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –º–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.\n",
    "    \"\"\"\n",
    "    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n",
    "    CONFIG = {\n",
    "        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –ø–µ—Ä–≤–æ–º –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–∏\n",
    "        'model_id': \"modernBERT-large-multilingual\",          # –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –º–æ–¥–µ–ª–∏\n",
    "        'data_path': \"data/dataset.csv\",                      # –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º\n",
    "        'output_dir': \"modernbert-russian-multilabel-final\",  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "        'max_length': 1024,                                   # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "        'num_epochs': 5,                                      # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "        'patience': 3,                                        # –ü–∞—Ä–∞–º–µ—Ç—Ä —Ç–µ—Ä–ø–µ–Ω–∏—è –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏\n",
    "        'learning_rate': 2e-5,                                # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è\n",
    "        'weight_decay': 0.01,                                 # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ (L2)\n",
    "        'train_batch_size': 16,                               # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "        'eval_batch_size': 32,                                # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏\n",
    "    \n",
    "        # –ù–æ–≤—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (—ç–º–ø–∏—Ä–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ)\n",
    "        'gradient_clip_max_norm': 1.0,                        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –±–æ—Ä—å–±—ã —Å –≤–∑—Ä—ã–≤–æ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤\n",
    "        'dropout_rate': 0.1,                                  # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ –¥—Ä–æ–ø–∞—É—Ç\n",
    "        'scheduler_type': 'cosine',                           # –¢–∏–ø —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è: 'linear', 'cosine', 'warmup'\n",
    "        'warmup_steps': 100,                                  # –®–∞–≥–∏ —Ä–∞–∑–æ–≥—Ä–µ–≤–∞ –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è\n",
    "        'accumulation_steps': 2,                              # –ê–∫–∫—É–º—É–ª—è—Ü–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –±–∞—Ç—á–∞\n",
    "        'pos_weight': 'balanced',                             # –í–µ—Å–∞ –¥–ª—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤ ('balanced' –∏–ª–∏ –º–∞—Å—Å–∏–≤)\n",
    "        'threshold': 0.4,                                     # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–º–æ–∂–Ω–æ –ø–æ–¥–æ–±—Ä–∞—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏)\n",
    "        'use_fp16': True,                                     # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–º–µ—à–∞–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è\n",
    "        'num_workers': 8,                                     # –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
    "        'label_smoothing': 0.1,                               # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫ –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º\n",
    "        'layerwise_lr_decay': 0.85,                           # –î–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π LR –ø–æ —Å–ª–æ—è–º BERT\n",
    "        'freeze_layers': 6,                                   # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω—ã—Ö –Ω–∏–∂–Ω–∏—Ö —Å–ª–æ–µ–≤ BERT\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "    # ================== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ==================\n",
    "    print(\"\\n–ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã\")\n",
    "    print(f\"–ú–æ–¥–µ–ª—å: {CONFIG['model_id']}\")\n",
    "    print(f\"–î–∞–Ω–Ω—ã–µ: {CONFIG['data_path']}\")\n",
    "    print(f\"–í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {CONFIG['output_dir']}\")\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    output_dir = Path(CONFIG['output_dir'])\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # ================== –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• ==================\n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ —Ä–∞–∑–±–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ —Ç–µ–∫—Å—Ç—ã –∏ –º–µ—Ç–∫–∏\n",
    "    texts, labels, label_columns = load_data(CONFIG['data_path'])\n",
    "    num_labels = len(label_columns)\n",
    "    \n",
    "    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        texts, labels, test_size=0.2, random_state=42  # 20% –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n–†–∞–∑–±–∏–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "    print(f\"–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(train_texts)} –∑–∞–ø–∏—Å–µ–π\")\n",
    "    print(f\"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(val_texts)} –∑–∞–ø–∏—Å–µ–π\")\n",
    "    \n",
    "    # ================== –ú–û–î–ï–õ–¨ –ò –¢–û–ö–ï–ù–ò–ó–ê–¢–û–† ==================\n",
    "    print(\"\\n–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏...\")\n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CONFIG['model_id'])\n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —Å –Ω—É–∂–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –º–µ—Ç–æ–∫\n",
    "    model = MultilabelClassifier(CONFIG['model_id'], num_labels)\n",
    "    \n",
    "    # ================== –°–û–ó–î–ê–ù–ò–ï –î–ê–¢–ê–°–ï–¢–û–í ==================\n",
    "    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏\n",
    "    train_dataset = MultiLabelTextDataset(\n",
    "        train_texts,\n",
    "        train_labels,\n",
    "        tokenizer,\n",
    "        CONFIG['max_length']  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "    )\n",
    "    val_dataset = MultiLabelTextDataset(\n",
    "        val_texts,\n",
    "        val_labels,\n",
    "        tokenizer,\n",
    "        CONFIG['max_length']\n",
    "    )\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å –±–∞—Ç—á–∞–º–∏\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CONFIG['train_batch_size'],\n",
    "        shuffle=True,  # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏\n",
    "        num_workers=4  # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CONFIG['eval_batch_size'],\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    # ================== –ù–ê–°–¢–†–û–ô–ö–ê –û–ë–£–ß–ï–ù–ò–Ø ==================\n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (GPU/CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\n–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\")\n",
    "    \n",
    "    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —Ü–µ–ª–µ–≤–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "    model.to(device)\n",
    "    \n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä AdamW —Å L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=CONFIG['learning_rate'],\n",
    "        weight_decay=CONFIG['weight_decay']\n",
    "    )\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer,\n",
    "        start_factor=1.0,  # –ù–∞—á–∞–ª—å–Ω—ã–π –º–Ω–æ–∂–∏—Ç–µ–ª—å lr\n",
    "        end_factor=0.0,    # –ö–æ–Ω–µ—á–Ω—ã–π –º–Ω–æ–∂–∏—Ç–µ–ª—å lr\n",
    "        total_iters=CONFIG['num_epochs']  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –∏–∑–º–µ–Ω–µ–Ω–∏—è\n",
    "    )\n",
    "    \n",
    "    # ================== –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò ==================\n",
    "    model = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        num_epochs=CONFIG['num_epochs'],\n",
    "        patience=CONFIG['patience'],\n",
    "        output_dir=output_dir,\n",
    "        label_columns=label_columns\n",
    "    )\n",
    "    \n",
    "    # ================== –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ==================\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏\n",
    "    print(f\"\\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –≤ {output_dir}/final_model\")\n",
    "    model.bert.save_pretrained(output_dir / \"final_model\")\n",
    "    tokenizer.save_pretrained(output_dir / \"final_model\")\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –º–µ—Ç–æ–∫ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "    label_columns_path = output_dir / \"label_columns.json\"\n",
    "    print(f\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–µ—Ç–æ–∫ –≤ {label_columns_path}\")\n",
    "    with open(label_columns_path, \"w\") as f:\n",
    "        json.dump(label_columns, f)\n",
    "    \n",
    "    print(\"\\n–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a6003f7-743d-4713-8651-76532ac466e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã\n",
      "–ú–æ–¥–µ–ª—å: modernBERT-large-multilingual\n",
      "–î–∞–Ω–Ω—ã–µ: data/dataset.csv\n",
      "–í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: modernbert-russian-multilabel-final\n",
      "\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ data/dataset.csv...\n",
      "–ó–∞–≥—Ä—É–∂–µ–Ω–æ 35303 –∑–∞–ø–∏—Å–µ–π —Å 19 –º–µ—Ç–∫–∞–º–∏\n",
      "\n",
      "–†–∞–∑–±–∏–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:\n",
      "–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: 28242 –∑–∞–ø–∏—Å–µ–π\n",
      "–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: 7061 –∑–∞–ø–∏—Å–µ–π\n",
      "\n",
      "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at modernBERT-large-multilingual and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([19]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 1024]) in the checkpoint and torch.Size([19, 1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cuda\n",
      "\n",
      "–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è:\n",
      "--------------------------------------------------\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 1/5\n",
      "==================================================\n",
      "\n",
      "–û–±—É—á–µ–Ω–∏–µ:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ–≥—Ä–µ—Å—Å: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1766/1766 [33:38<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–í–∞–ª–∏–¥–∞—Ü–∏—è:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ–≥—Ä–µ—Å—Å: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 221/221 [02:48<00:00,  1.31it/s]\n",
      "/home/username/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/username/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –º—É–ª—å—Ç–∏–ª–µ–π–±–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\n",
      "--------------------------------------------------\n",
      "hamming_loss        : 0.0201\n",
      "subset_accuracy     : 0.7211\n",
      "macro_precision     : 0.8750\n",
      "macro_recall        : 0.7090\n",
      "macro_f1            : 0.7718\n",
      "micro_f1            : 0.7962\n",
      "samples_f1          : 0.6953\n",
      "jaccard_score       : 0.6806\n",
      "\n",
      "–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º –º–µ—Ç–∫–∞–º:\n",
      "--------------------------------------------------\n",
      "–æ—Ñ—Ñ–ª–∞–π–Ω_–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è     : precision: 0.7597, recall: 0.4836, f1: 0.5910\n",
      "–æ–Ω–ª–∞–π–Ω_–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è      : precision: 0.8054, recall: 0.7376, f1: 0.7700\n",
      "–Ω–∞—Ä–∫–æ—Ç–∏–∫–∏                : precision: 0.9469, recall: 0.9231, f1: 0.9349\n",
      "–∞–∑–∞—Ä—Ç–Ω—ã–µ_–∏–≥—Ä—ã            : precision: 0.8841, recall: 0.9037, f1: 0.8938\n",
      "–ø–æ—Ä–Ω–æ–≥—Ä–∞—Ñ–∏—è              : precision: 0.8798, recall: 0.4357, f1: 0.5828\n",
      "–ø—Ä–æ—Å—Ç–∏—Ç—É—Ü–∏—è              : precision: 0.9401, recall: 0.6305, f1: 0.7548\n",
      "—Ä–∞–±—Å—Ç–≤–æ                  : precision: 0.8454, recall: 0.8283, f1: 0.8367\n",
      "—Å–∞–º–æ—É–±–∏–π—Å—Ç–≤–æ             : precision: 0.9602, recall: 0.8732, f1: 0.9146\n",
      "—Ç–µ—Ä—Ä–æ—Ä–∏–∑–º                : precision: 0.9429, recall: 0.8524, f1: 0.8953\n",
      "–æ—Ä—É–∂–∏–µ                   : precision: 0.9308, recall: 0.6758, f1: 0.7831\n",
      "–±–æ–¥–∏—à–µ–π–º–∏–Ω–≥              : precision: 0.8571, recall: 0.6864, f1: 0.7624\n",
      "—Ö–µ–π–ª—Ç—à–µ–π–º–∏–Ω–≥             : precision: 0.9363, recall: 0.6386, f1: 0.7593\n",
      "–ø–æ–ª–∏—Ç–∏–∫–∞                 : precision: 0.5771, recall: 0.6239, f1: 0.5996\n",
      "—Ä–∞—Å–∏–∑–º                   : precision: 0.8929, recall: 0.5352, f1: 0.6692\n",
      "—Ä–µ–ª–∏–≥–∏—è                  : precision: 0.9841, recall: 0.9312, f1: 0.9569\n",
      "—Å–µ–∫—Å—É–∞–ª—å–Ω—ã–µ_–º–µ–Ω—å—à–∏–Ω—Å—Ç–≤–∞  : precision: 0.9657, recall: 0.7598, f1: 0.8505\n",
      "—Å–µ–∫—Å–∏–∑–º                  : precision: 0.6950, recall: 0.7106, f1: 0.7027\n",
      "—Å–æ—Ü–∏–∞–ª—å–Ω–∞—è_–Ω–µ—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å: precision: 0.8252, recall: 0.2950, f1: 0.4346\n",
      "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π              : precision: 0.9972, recall: 0.9469, f1: 0.9714\n",
      "\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–ø–æ—Ö–∏:\n",
      "–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è:    0.0848\n",
      "–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:   0.0648\n",
      "\n",
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –≤ modernbert-russian-multilabel-final/best_model\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 2/5\n",
      "==================================================\n",
      "\n",
      "–û–±—É—á–µ–Ω–∏–µ:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ–≥—Ä–µ—Å—Å: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1766/1766 [34:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–í–∞–ª–∏–¥–∞—Ü–∏—è:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ–≥—Ä–µ—Å—Å: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 221/221 [02:48<00:00,  1.31it/s]\n",
      "/home/username/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/username/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –º—É–ª—å—Ç–∏–ª–µ–π–±–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\n",
      "--------------------------------------------------\n",
      "hamming_loss        : 0.0188\n",
      "subset_accuracy     : 0.7447\n",
      "macro_precision     : 0.8683\n",
      "macro_recall        : 0.7384\n",
      "macro_f1            : 0.7924\n",
      "micro_f1            : 0.8130\n",
      "samples_f1          : 0.7213\n",
      "jaccard_score       : 0.7067\n",
      "\n",
      "–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º –º–µ—Ç–∫–∞–º:\n",
      "--------------------------------------------------\n",
      "–æ—Ñ—Ñ–ª–∞–π–Ω_–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è     : precision: 0.7323, recall: 0.5082, f1: 0.6000\n",
      "–æ–Ω–ª–∞–π–Ω_–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è      : precision: 0.9155, recall: 0.6436, f1: 0.7558\n",
      "–Ω–∞—Ä–∫–æ—Ç–∏–∫–∏                : precision: 0.9584, recall: 0.9164, f1: 0.9369\n",
      "–∞–∑–∞—Ä—Ç–Ω—ã–µ_–∏–≥—Ä—ã            : precision: 0.9323, recall: 0.8840, f1: 0.9075\n",
      "–ø–æ—Ä–Ω–æ–≥—Ä–∞—Ñ–∏—è              : precision: 0.8322, recall: 0.5786, f1: 0.6826\n",
      "–ø—Ä–æ—Å—Ç–∏—Ç—É—Ü–∏—è              : precision: 0.9159, recall: 0.8313, f1: 0.8716\n",
      "—Ä–∞–±—Å—Ç–≤–æ                  : precision: 0.9012, recall: 0.7374, f1: 0.8111\n",
      "—Å–∞–º–æ—É–±–∏–π—Å—Ç–≤–æ             : precision: 0.9691, recall: 0.9094, f1: 0.9383\n",
      "—Ç–µ—Ä—Ä–æ—Ä–∏–∑–º                : precision: 0.8897, recall: 0.8635, f1: 0.8764\n",
      "–æ—Ä—É–∂–∏–µ                   : precision: 0.7177, recall: 0.8881, f1: 0.7939\n",
      "–±–æ–¥–∏—à–µ–π–º–∏–Ω–≥              : precision: 0.8649, recall: 0.6780, f1: 0.7601\n",
      "—Ö–µ–π–ª—Ç—à–µ–π–º–∏–Ω–≥             : precision: 0.9481, recall: 0.6957, f1: 0.8025\n",
      "–ø–æ–ª–∏—Ç–∏–∫–∞                 : precision: 0.6535, recall: 0.5225, f1: 0.5807\n",
      "—Ä–∞—Å–∏–∑–º                   : precision: 0.7651, recall: 0.6972, f1: 0.7296\n",
      "—Ä–µ–ª–∏–≥–∏—è                  : precision: 0.9791, recall: 0.9399, f1: 0.9591\n",
      "—Å–µ–∫—Å—É–∞–ª—å–Ω—ã–µ_–º–µ–Ω—å—à–∏–Ω—Å—Ç–≤–∞  : precision: 0.9543, recall: 0.8186, f1: 0.8813\n",
      "—Å–µ–∫—Å–∏–∑–º                  : precision: 0.8333, recall: 0.5627, f1: 0.6718\n",
      "—Å–æ—Ü–∏–∞–ª—å–Ω–∞—è_–Ω–µ—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å: precision: 0.7376, recall: 0.4075, f1: 0.5250\n",
      "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π              : precision: 0.9972, recall: 0.9469, f1: 0.9714\n",
      "\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–ø–æ—Ö–∏:\n",
      "–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è:    0.0407\n",
      "–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:   0.0595\n",
      "\n",
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –≤ modernbert-russian-multilabel-final/best_model\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 3/5\n",
      "==================================================\n",
      "\n",
      "–û–±—É—á–µ–Ω–∏–µ:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ–≥—Ä–µ—Å—Å: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1766/1766 [32:28<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–í–∞–ª–∏–¥–∞—Ü–∏—è:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ–≥—Ä–µ—Å—Å: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 221/221 [02:48<00:00,  1.31it/s]\n",
      "/home/username/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/username/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –º—É–ª—å—Ç–∏–ª–µ–π–±–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\n",
      "--------------------------------------------------\n",
      "hamming_loss        : 0.0178\n",
      "subset_accuracy     : 0.7547\n",
      "macro_precision     : 0.8812\n",
      "macro_recall        : 0.7449\n",
      "macro_f1            : 0.8034\n",
      "micro_f1            : 0.8223\n",
      "samples_f1          : 0.7227\n",
      "jaccard_score       : 0.7089\n",
      "\n",
      "–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º –º–µ—Ç–∫–∞–º:\n",
      "--------------------------------------------------\n",
      "–æ—Ñ—Ñ–ª–∞–π–Ω_–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è     : precision: 0.7148, recall: 0.5683, f1: 0.6332\n",
      "–æ–Ω–ª–∞–π–Ω_–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è      : precision: 0.9318, recall: 0.6089, f1: 0.7365\n",
      "–Ω–∞—Ä–∫–æ—Ç–∏–∫–∏                : precision: 0.9598, recall: 0.9191, f1: 0.9390\n",
      "–∞–∑–∞—Ä—Ç–Ω—ã–µ_–∏–≥—Ä—ã            : precision: 0.9333, recall: 0.8988, f1: 0.9157\n",
      "–ø–æ—Ä–Ω–æ–≥—Ä–∞—Ñ–∏—è              : precision: 0.8475, recall: 0.5952, f1: 0.6993\n",
      "–ø—Ä–æ—Å—Ç–∏—Ç—É—Ü–∏—è              : precision: 0.8785, recall: 0.8715, f1: 0.8750\n",
      "—Ä–∞–±—Å—Ç–≤–æ                  : precision: 0.8827, recall: 0.7980, f1: 0.8382\n",
      "—Å–∞–º–æ—É–±–∏–π—Å—Ç–≤–æ             : precision: 0.9654, recall: 0.9094, f1: 0.9366\n",
      "—Ç–µ—Ä—Ä–æ—Ä–∏–∑–º                : precision: 0.9427, recall: 0.7897, f1: 0.8594\n",
      "–æ—Ä—É–∂–∏–µ                   : precision: 0.9129, recall: 0.7420, f1: 0.8186\n",
      "–±–æ–¥–∏—à–µ–π–º–∏–Ω–≥              : precision: 0.8750, recall: 0.7712, f1: 0.8198\n",
      "—Ö–µ–π–ª—Ç—à–µ–π–º–∏–Ω–≥             : precision: 0.9130, recall: 0.6848, f1: 0.7826\n",
      "–ø–æ–ª–∏—Ç–∏–∫–∞                 : precision: 0.6728, recall: 0.4955, f1: 0.5707\n",
      "—Ä–∞—Å–∏–∑–º                   : precision: 0.9054, recall: 0.6147, f1: 0.7322\n",
      "—Ä–µ–ª–∏–≥–∏—è                  : precision: 0.9793, recall: 0.9487, f1: 0.9638\n",
      "—Å–µ–∫—Å—É–∞–ª—å–Ω—ã–µ_–º–µ–Ω—å—à–∏–Ω—Å—Ç–≤–∞  : precision: 0.9149, recall: 0.8431, f1: 0.8776\n",
      "—Å–µ–∫—Å–∏–∑–º                  : precision: 0.7643, recall: 0.6881, f1: 0.7242\n",
      "—Å–æ—Ü–∏–∞–ª—å–Ω–∞—è_–Ω–µ—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å: precision: 0.7480, recall: 0.4600, f1: 0.5697\n",
      "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π              : precision: 1.0000, recall: 0.9469, f1: 0.9728\n",
      "\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–ø–æ—Ö–∏:\n",
      "–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è:    0.0163\n",
      "–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:   0.0600\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 4/5\n",
      "==================================================\n",
      "\n",
      "–û–±—É—á–µ–Ω–∏–µ:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ–≥—Ä–µ—Å—Å: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1766/1766 [32:51<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–í–∞–ª–∏–¥–∞—Ü–∏—è:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ–≥—Ä–µ—Å—Å: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 221/221 [02:48<00:00,  1.31it/s]\n",
      "/home/username/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/username/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –º—É–ª—å—Ç–∏–ª–µ–π–±–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\n",
      "--------------------------------------------------\n",
      "hamming_loss        : 0.0176\n",
      "subset_accuracy     : 0.7558\n",
      "macro_precision     : 0.8904\n",
      "macro_recall        : 0.7357\n",
      "macro_f1            : 0.8007\n",
      "micro_f1            : 0.8217\n",
      "samples_f1          : 0.7199\n",
      "jaccard_score       : 0.7068\n",
      "\n",
      "–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º –º–µ—Ç–∫–∞–º:\n",
      "--------------------------------------------------\n",
      "–æ—Ñ—Ñ–ª–∞–π–Ω_–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è     : precision: 0.7283, recall: 0.5055, f1: 0.5968\n",
      "–æ–Ω–ª–∞–π–Ω_–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è      : precision: 0.8926, recall: 0.6584, f1: 0.7578\n",
      "–Ω–∞—Ä–∫–æ—Ç–∏–∫–∏                : precision: 0.9588, recall: 0.9257, f1: 0.9420\n",
      "–∞–∑–∞—Ä—Ç–Ω—ã–µ_–∏–≥—Ä—ã            : precision: 0.9486, recall: 0.8667, f1: 0.9058\n",
      "–ø–æ—Ä–Ω–æ–≥—Ä–∞—Ñ–∏—è              : precision: 0.8821, recall: 0.5881, f1: 0.7057\n",
      "–ø—Ä–æ—Å—Ç–∏—Ç—É—Ü–∏—è              : precision: 0.9127, recall: 0.8394, f1: 0.8745\n",
      "—Ä–∞–±—Å—Ç–≤–æ                  : precision: 0.8908, recall: 0.7828, f1: 0.8333\n",
      "—Å–∞–º–æ—É–±–∏–π—Å—Ç–≤–æ             : precision: 0.9648, recall: 0.8949, f1: 0.9286\n",
      "—Ç–µ—Ä—Ä–æ—Ä–∏–∑–º                : precision: 0.9363, recall: 0.8672, f1: 0.9004\n",
      "–æ—Ä—É–∂–∏–µ                   : precision: 0.9069, recall: 0.7785, f1: 0.8378\n",
      "–±–æ–¥–∏—à–µ–π–º–∏–Ω–≥              : precision: 0.9016, recall: 0.6992, f1: 0.7876\n",
      "—Ö–µ–π–ª—Ç—à–µ–π–º–∏–Ω–≥             : precision: 0.9438, recall: 0.6848, f1: 0.7937\n",
      "–ø–æ–ª–∏—Ç–∏–∫–∞                 : precision: 0.6710, recall: 0.4685, f1: 0.5517\n",
      "—Ä–∞—Å–∏–∑–º                   : precision: 0.9027, recall: 0.6239, f1: 0.7378\n",
      "—Ä–µ–ª–∏–≥–∏—è                  : precision: 0.9793, recall: 0.9487, f1: 0.9638\n",
      "—Å–µ–∫—Å—É–∞–ª—å–Ω—ã–µ_–º–µ–Ω—å—à–∏–Ω—Å—Ç–≤–∞  : precision: 0.9656, recall: 0.8260, f1: 0.8904\n",
      "—Å–µ–∫—Å–∏–∑–º                  : precision: 0.7587, recall: 0.6977, f1: 0.7270\n",
      "—Å–æ—Ü–∏–∞–ª—å–Ω–∞—è_–Ω–µ—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å: precision: 0.7732, recall: 0.3750, f1: 0.5051\n",
      "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π              : precision: 1.0000, recall: 0.9469, f1: 0.9728\n",
      "\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–ø–æ—Ö–∏:\n",
      "–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è:    0.0049\n",
      "–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:   0.0654\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 5/5\n",
      "==================================================\n",
      "\n",
      "–û–±—É—á–µ–Ω–∏–µ:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ–≥—Ä–µ—Å—Å: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1766/1766 [32:05<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–í–∞–ª–∏–¥–∞—Ü–∏—è:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ–≥—Ä–µ—Å—Å: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 221/221 [02:48<00:00,  1.31it/s]\n",
      "/home/username/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/username/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –º—É–ª—å—Ç–∏–ª–µ–π–±–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\n",
      "--------------------------------------------------\n",
      "hamming_loss        : 0.0172\n",
      "subset_accuracy     : 0.7612\n",
      "macro_precision     : 0.8995\n",
      "macro_recall        : 0.7347\n",
      "macro_f1            : 0.8031\n",
      "micro_f1            : 0.8249\n",
      "samples_f1          : 0.7206\n",
      "jaccard_score       : 0.7082\n",
      "\n",
      "–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º –º–µ—Ç–∫–∞–º:\n",
      "--------------------------------------------------\n",
      "–æ—Ñ—Ñ–ª–∞–π–Ω_–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è     : precision: 0.7682, recall: 0.4617, f1: 0.5768\n",
      "–æ–Ω–ª–∞–π–Ω_–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è      : precision: 0.8874, recall: 0.6634, f1: 0.7592\n",
      "–Ω–∞—Ä–∫–æ—Ç–∏–∫–∏                : precision: 0.9706, recall: 0.9204, f1: 0.9449\n",
      "–∞–∑–∞—Ä—Ç–Ω—ã–µ_–∏–≥—Ä—ã            : precision: 0.9194, recall: 0.9012, f1: 0.9102\n",
      "–ø–æ—Ä–Ω–æ–≥—Ä–∞—Ñ–∏—è              : precision: 0.8864, recall: 0.5762, f1: 0.6984\n",
      "–ø—Ä–æ—Å—Ç–∏—Ç—É—Ü–∏—è              : precision: 0.9355, recall: 0.8153, f1: 0.8712\n",
      "—Ä–∞–±—Å—Ç–≤–æ                  : precision: 0.8798, recall: 0.8131, f1: 0.8451\n",
      "—Å–∞–º–æ—É–±–∏–π—Å—Ç–≤–æ             : precision: 0.9653, recall: 0.9058, f1: 0.9346\n",
      "—Ç–µ—Ä—Ä–æ—Ä–∏–∑–º                : precision: 0.9393, recall: 0.8561, f1: 0.8958\n",
      "–æ—Ä—É–∂–∏–µ                   : precision: 0.9180, recall: 0.7671, f1: 0.8358\n",
      "–±–æ–¥–∏—à–µ–π–º–∏–Ω–≥              : precision: 0.8947, recall: 0.7203, f1: 0.7981\n",
      "—Ö–µ–π–ª—Ç—à–µ–π–º–∏–Ω–≥             : precision: 0.9355, recall: 0.7092, f1: 0.8068\n",
      "–ø–æ–ª–∏—Ç–∏–∫–∞                 : precision: 0.7540, recall: 0.4279, f1: 0.5460\n",
      "—Ä–∞—Å–∏–∑–º                   : precision: 0.9266, recall: 0.6177, f1: 0.7413\n",
      "—Ä–µ–ª–∏–≥–∏—è                  : precision: 0.9843, recall: 0.9399, f1: 0.9616\n",
      "—Å–µ–∫—Å—É–∞–ª—å–Ω—ã–µ_–º–µ–Ω—å—à–∏–Ω—Å—Ç–≤–∞  : precision: 0.9601, recall: 0.8260, f1: 0.8880\n",
      "—Å–µ–∫—Å–∏–∑–º                  : precision: 0.7786, recall: 0.6559, f1: 0.7120\n",
      "—Å–æ—Ü–∏–∞–ª—å–Ω–∞—è_–Ω–µ—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å: precision: 0.7873, recall: 0.4350, f1: 0.5604\n",
      "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π              : precision: 1.0000, recall: 0.9469, f1: 0.9728\n",
      "\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–ø–æ—Ö–∏:\n",
      "–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è:    0.0017\n",
      "–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:   0.0690\n",
      "\n",
      "–†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞!\n",
      "\n",
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è –≤ modernbert-russian-multilabel-final/training_history.json\n",
      "\n",
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –≤ modernbert-russian-multilabel-final/final_model\n",
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–µ—Ç–æ–∫ –≤ modernbert-russian-multilabel-final/label_columns.json\n",
      "\n",
      "–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaef31e",
   "metadata": {},
   "source": [
    "# üìä –û—Ç—á–µ—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\n",
    "\n",
    "## üìå –†–µ–∑—é–º–µ\n",
    "\n",
    "### –°—Ç–∞—Ç—É—Å –º–µ—Ç—Ä–∏–∫:\n",
    "- **Macro F1**: `0.803` ‚úÖ  \n",
    "- **Micro F1**: `0.825` ‚úÖ  \n",
    "- **Subset accuracy**: `0.761` ‚ö†Ô∏è  \n",
    "- **Hamming loss**: `0.017` ‚úÖ  \n",
    "\n",
    "---\n",
    "\n",
    "## üìà 1. –î–∏–Ω–∞–º–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "| –ú–µ—Ç—Ä–∏–∫–∞       | –ò–∑–º–µ–Ω–µ–Ω–∏–µ               | –°—Ç–∞—Ç—É—Å  |\n",
    "|---------------|-------------------------|---------|\n",
    "| **Train loss** | `0.085` ‚Üí `0.0017` (‚Üì 50x) | ‚úÖ      |\n",
    "| **Val loss**   | `0.065` ‚Üí `0.069` (‚Üë 6%)   | ‚ö†Ô∏è      |\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ 2. –ö–∞—á–µ—Å—Ç–≤–æ –ø–æ –∫–ª–∞—Å—Å–∞–º\n",
    "\n",
    "### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ F1-score\n",
    "\n",
    "#### –õ—É—á—à–∏–µ (>0.90):\n",
    "- **–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π**: `0.973`  \n",
    "- **—Ä–µ–ª–∏–≥–∏—è**: `0.962`  \n",
    "- **–Ω–∞—Ä–∫–æ—Ç–∏–∫–∏**: `0.945`  \n",
    "- **—Å–∞–º–æ—É–±–∏–π—Å—Ç–≤–æ**: `0.935`  \n",
    "\n",
    "#### –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ (<0.60):\n",
    "- **–ø–æ–ª–∏—Ç–∏–∫–∞**: `0.546`  \n",
    "- **–æ—Ñ—Ñ–ª–∞–π–Ω_–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è**: `0.577`  \n",
    "- **—Å–æ—Ü–∏–∞–ª—å–Ω–∞—è_–Ω–µ—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å**: `0.560`  \n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è 3. –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–æ–±–ª–µ–º—ã\n",
    "\n",
    "### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ issues:\n",
    "1. **–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ**: –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ `train/val loss`.  \n",
    "2. **–î–∏—Å–±–∞–ª–∞–Ω—Å**: —Ä–∞–∑–±—Ä–æ—Å F1-score (`0.546` - `0.973`).  \n",
    "3. **–°—Ç–∞–≥–Ω–∞—Ü–∏—è**: –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–µ —É–ª—É—á—à–∞—é—Ç—Å—è –ø–æ—Å–ª–µ —ç–ø–æ—Ö–∏ 2.  \n",
    "\n",
    "---\n",
    "\n",
    "## üìã 4. –ü–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π\n",
    "\n",
    "### –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è\n",
    "- **Early stopping** –Ω–∞ —ç–ø–æ—Ö–µ 3.  \n",
    "- –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ dropout –∏–ª–∏ L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏).  \n",
    "\n",
    "### –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤\n",
    "- –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤.  \n",
    "- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–∑–≤–µ—à–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –¥–ª—è —É—á–µ—Ç–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞.  \n",
    "\n",
    "---\n",
    "\n",
    "## üìù –ò—Ç–æ–≥–∏\n",
    "\n",
    "### –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
    "‚úÖ **–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã:**\n",
    "- –•–æ—Ä–æ—à–∏–µ –æ–±—â–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ (Macro F1, Micro F1).  \n",
    "- –°—Ç–∞–±–∏–ª—å–Ω—ã–π —Ä–æ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ.  \n",
    "\n",
    "‚ö†Ô∏è **–¢—Ä–µ–±—É—é—Ç –≤–Ω–∏–º–∞–Ω–∏—è:**\n",
    "- –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ (—Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ –º–µ–∂–¥—É train –∏ val loss).  \n",
    "- –î–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ (—Ä–∞–∑–±—Ä–æ—Å F1-score).  \n",
    "- –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—É—á–µ–Ω–∏—è –∏–∑-–∑–∞ —Å—Ç–∞–≥–Ω–∞—Ü–∏–∏ –º–µ—Ç—Ä–∏–∫.  \n",
    "\n",
    "---\n",
    "\n",
    "<p align=\"center\">üöÄ –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —É–ª—É—á—à–∞—Ç—å –º–æ–¥–µ–ª—å!</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
