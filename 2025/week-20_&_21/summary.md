# Машины непрерывного мышления (Continuous Thought Machines): внедрение нейронной синхронизации в качестве основы для искусственного интеллекта

## Оглавление  
1. [Введение](#введение)  
2. [Обзор архитектуры](#обзор-архитектуры)  
3. [Нейронная динамика и синхронизация](#нейронная-динамика-и-синхронизация)  
4. [Производительность по всем задачам](#производительность-по-всем-задачам)  
   - [Классификация изображений](#классификация-изображений)  
   - [Навигация по лабиринту](#навигация-по-лабиринту)  
   - [Адаптивные вычисления](#адаптивные-вычисления)  
   - [Обучение с подкреплением](#обучение-с-подкреплением)  
   - [Математические задачи](#математические-задачи)  
5. [Внутренние представления](#внутренние-представления)  
6. [Биологическая правдоподобность](#биологическая-правдоподобность)  
7. [Заключение](#заключение)

## **1. Введение**
Искусственный интеллект добился значительного прогресса благодаря архитектурам глубокого обучения, однако эти системы все еще сталкиваются со значительными ограничениями в рассуждениях здравого смысла, обобщении и прозрачности. Статья «Машины непрерывного мышления» (CTM) представляет новую архитектуру нейронной сети, которая устраняет эти ограничения, явно включая нейронную синхронизацию в качестве фундаментального компонента, черпая вдохновение из того, как биологический мозг обрабатывает информацию.

![Рисунок 1](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-20_&_21/assets/Image_01.jpeg)

**Рисунок 1:** Архитектура CTM с выделением ключевых компонентов: модель синапса, модели на уровне нейронов с обработкой истории и нейронная синхронизация как скрытое представление.

Разработанный исследователями из Sakana AI в сотрудничестве с Университетом Цукубы и Университетом информационных технологий Копенгагена, CTM представляет собой отход от стандартных подходов глубокого обучения, которые обычно абстрагируются от временной динамики нейронной обработки. Вместо этого CTM принимает время как существенное измерение, в котором могут разворачиваться мыслительные процессы, обеспечивая более сложные рассуждения посредством нейронной синхронизации и непрерывных паттернов нейронной активности.

## **2. Обзор архитектуры**

CTM (Continuous Thought Machines) представляет три ключевых архитектурных новшества, которые отличают ее от традиционных нейронных сетей:

1. **Временная обработка на уровне нейронов:** каждый нейрон в CTM использует уникальные весовые параметры для обработки истории входящих сигналов, а не только текущего состояния входа.

2. **Нейронная синхронизация как скрытое представление:** модель использует нейронную синхронизацию как фундаментальный механизм представления, обеспечивая формирование и обработку сложных паттернов.

3. **Разделенное внутреннее измерение времени:** CTM вводит внутреннее измерение, в котором мысль может разворачиваться независимо от входной последовательности, что обеспечивает итеративную обработку.

Как показано на рисунке 1, архитектура состоит из нескольких взаимосвязанных компонентов. Модель синапса (компонент 1) обрабатывает входные данные, в то время как модели нейронного уровня (компоненты 2-3) поддерживают историю предварительных активаций, которые развиваются во внутреннем измерении времени/мысли. Система использует механизмы синхронизации (компоненты 5-7) для установления скрытых представлений и создания выходных данных посредством специализированных механизмов внимания (компоненты 8-10).

## **3. Нейронная динамика и синхронизация**

Центральным элементом возможностей CTM является использование нейронной синхронизации в качестве механизма представления. В отличие от традиционных нейронных сетей, которые представляют информацию посредством паттернов активации в один момент времени, CTM кодирует информацию в паттернах синхронизации нейронной активности во времени.

Эти динамические паттерны создают богатое пространство представлений, которое позволяет модели поддерживать и манипулировать сложной информацией. Механизм синхронизации позволяет нейронам устанавливать отношения во времени, формируя то, что можно считать формой рабочей памяти или когнитивной карты.

В статье демонстрируется, что эта нейронная динамика — не просто деталь реализации, а фундаментальный аспект того, как CTM обрабатывает информацию и решает задачи. Например, при решении сложных задач модель демонстрирует характерные паттерны нейронной активности, которые развиваются во времени, при этом каждый нейрон имеет свою уникальную сигнатуру активности.

![Рисунок 2](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-20_&_21/assets/Image_02.jpeg)

**Рисунок 2:** Визуализация нейронной активности CTM, показывающая богатые паттерны, формируемые в процессе обработки. Каждая строка представляет активность отдельного нейрона во времени.

## **4. Производительность в различных задачах**

CTM демонстрирует впечатляющую универсальность в широком спектре задач, что указывает на ее потенциал в качестве архитектуры общего назначения:

- Классификация изображений (ImageNet-1K, CIFAR-10/100);
- Навигация по двухмерному лабиринту;
- Сортировка;
- Вычисление четности;
- Вопросно-ответная система (MNIST Q&A);
- Обучение с подкреплением (CartPole, Acrobot, MiniGrid Four Rooms).

Примечательно то, что основная архитектура CTM оставалась в основном неизменной во всех этих задачах, требуя лишь корректировки входных/выходных модулей. Это говорит о том, что подход нейронной динамики предлагает прочную основу для решения разнообразных когнитивных задач.

### **Классификация изображений**

В задачах классификации изображений CTM показывает конкурентоспособную производительность, предлагая при этом дополнительные преимущества с точки зрения интерпретируемости и адаптивных вычислений.

![Рисунок 3](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-20_&_21/assets/Image_03.jpeg)

**Рисунок 3:** (a) Кривые обучения, показывающие производительность CTM (на рисунке обозначена как ATM) по сравнению с прямоточными (FF) и LSTM-базовыми линиями. (b) График калибровки, сравнивающий CTM с производительностью человека.

В CIFAR-10 CTM достигла точности тестирования 86,03%, превзойдя как прямые сети (84,44%), так и LSTM (85,54%). Что еще более интересно, калибровка уверенности CTM (ее способность точно оценивать свою неопределенность) была поразительно похожа на производительность человека, что позволяет предположить, что ее процесс рассуждений может иметь некоторые общие черты с человеческим познанием.

### **Навигация по лабиринту**

Задача навигации по лабиринту представляет собой одну из наиболее убедительных демонстраций возможностей CTM. Модели было поручено найти кратчайший путь между двумя точками в лабиринте, что требует сложных последовательных рассуждений.

![Рисунок 4](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-20_&_21/assets/Image_04.jpeg)

**Рисунок 4:** Примеры решения CTM задач навигации по лабиринту. Цветные пути показывают последовательность фокусировки внимания по мере того, как модель решает лабиринт шаг за шагом.

Примечательно, что CTM смогла решить эту задачу без позиционных вложений, что позволяет предположить, что она строит внутреннее представление пространственной среды посредством своей нейронной динамики. Еще более впечатляющей была способность модели обобщать гораздо более крупные лабиринты, чем те, которые были замечены во время обучения, — успешно решать лабиринты 99×99 после обучения только на лабиринтах 39×39.

Визуализация траекторий внимания (рисунок 4) показывает, что CTM подходит к решению лабиринта методично, шаг за шагом, подобно тому, как люди могли бы решать такие задачи. Это открывает окно в ее внутренний процесс рассуждений и демонстрирует ее способность выполнять сложные последовательные рассуждения.

### **Адаптивные вычисления**

Одним из наиболее интересных свойств CTM является ее способность динамически корректировать свой вычислительный бюджет в зависимости от сложности задачи — возможность, называемая адаптивными вычислениями.

![Рисунок 5](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-20_&_21/assets/Image_05.jpeg)

**Рисунок 5:** Возможности адаптивных вычислений CTM. (a) При пороге достоверности 0,5 многие образцы классифицируются на ранней стадии. (b) При более высоком пороге 0,8 более сложные примеры получают расширенную обработку.

Как показано на рисунке 5, CTM можно настроить на продолжение обработки до достижения желаемого порога уверенности. Для более простых примеров он принимает решения раньше, а для более сложных случаев продолжает обработку в течение дополнительных внутренних временных шагов. Такое поведение возникает естественным образом из архитектуры модели и процедуры обучения.

В статье демонстрируется эта возможность на CIFAR-10, показывая, что уверенность модели сильно коррелирует с точностью и что разные образцы достигают уверенности с разной скоростью. Эта адаптивная вычислительная способность предлагает более эффективное использование вычислительных ресурсов и предоставляет интерпретируемый механизм для контроля компромисса между скоростью и точностью.

### **Обучение с подкреплением**

Чтобы оценить возможности CTM в последовательном принятии решений, исследователи оценили его на классических эталонных тестах обучения с подкреплением, включая CartPole, Acrobot и MiniGrid Four Rooms.

![Рисунок 6](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-20_&_21/assets/Image_06.jpeg)

**Рисунок 6:** Производительность моделей CTM и LSTM в задачах обучения с подкреплением с разными настройками итераций.

CTM достиг конкурентоспособной производительности с соответствующими по параметрам LSTM в этих задачах, демонстрируя, что он может эффективно использовать свою синхронизацию непрерывной истории активаций для изучения стратегий выбора действий. Это говорит о том, что возможности CTM по временной обработке хорошо подходят для последовательной природы задач обучения с подкреплением.

### **Математические задачи**

CTM также оценивался на математических задачах, требующих точных логических рассуждений, включая вычисление четности и сортировку.

В задаче на четность модель должна была определить, было ли число единиц в битовой строке нечетным или четным. CTM подошел к этому систематически, научившись считать и поддерживать текущую четность в своем нейронном состоянии. Для сортировки модель научилась реализовывать алгоритм, аналогичный сортировке выбором, демонстрируя свою способность разрабатывать алгоритмические решения для четко определенных проблем.

Эти задачи подчеркивают способность CTM разрабатывать структурированные внутренние процессы для решения абстрактных задач — ключевое требование для рассуждений более высокого уровня.

### **5. Внутренние представления**

В статье представлены увлекательные визуализации внутренних представлений CTM, предлагающие понимание того, как он обрабатывает информацию.

![Рисунок 7](https://raw.githubusercontent.com/Verbasik/Weekly-arXiv-ML-AI-Research-Review/refs/heads/develop/2025/week-20_&_21/assets/Image_07.jpeg)

**Рисунок 7:** Визуализация паттернов нейронной активности во время классификации изображений, показывающая разнообразные временные сигнатуры по нейронам.

Рисунок 7 показывает богатые и разнообразные временные паттерны, которые возникают в нейронах CTM во время классификации изображений. Каждый нейрон развивает уникальную временную сигнатуру, и эти паттерны коллективно кодируют понимание моделью входных данных.

Исследователи также проанализировали, как эти паттерны соотносятся между нейронами и между точками данных, обнаружив, что модель развивает специализированные нейронные реакции, сохраняя при этом распределенное представление. Этот баланс между специализацией и распределением напоминает то, как функционируют биологические нейронные сети.

### **6. Биологическая правдоподобность**

Хотя CTM не предназначен для буквальной модели функционирования мозга, принципы его проектирования вдохновлены биологической нейронной обработкой. Включение временной динамики, синхронизации и непрерывной обработки соответствует нескольким аспектам нейронных вычислений в биологических системах:

1. **Временная интеграция:** как и биологические нейроны, нейроны CTM интегрируют информацию во времени, что позволяет выполнять более сложные процессы, чем поточечные операции.

2. **Синхронизация:** нейронная синхронизация — хорошо задокументированное явление в биологическом мозге, которое, как считается, играет роль во внимании, рабочей памяти и связывании информации из разных областей мозга.

3. **Непрерывный процессинг:** биологический мозг работает непрерывно, а не дискретными шагами, что позволяет ему постоянно представлять информацию и манипулировать ею.

В статье утверждается, что эти вдохновленные биологией особенности способствуют возможностям CTM, предполагая, что дальнейшее изучение биологических принципов может привести к дополнительным достижениям в области искусственного интеллекта.

### **7. Заключение**

Машина непрерывного мышления представляет собой значительный отход от стандартных подходов глубокого обучения, явно включая нейронное время в качестве основополагающего элемента. Черпая вдохновение в том, как биологический мозг обрабатывает информацию, CTM демонстрирует возможности, которые решают некоторые ограничения современных систем ИИ.

Ключевые преимущества CTM включают в себя:

1. **Универсальность:** модель хорошо работает в различных задачах с минимальными архитектурными изменениями, что предполагает универсальный вычислительный подход.

2. **Интерпретируемость:** внутренняя обработка CTM поддается большей интерпретируемости, о чем свидетельствуют визуализации ее нейронной динамики и моделей внимания.

3. **Адаптивные вычисления:** модель естественным образом реализует адаптивные вычисления, выделяя больше времени обработки для более сложных входных данных.

4. **Сложное рассуждение:** CTM демонстрирует способность выполнять сложные последовательные рассуждения, как показано в задаче навигации по лабиринту.

5. **Надежная генерализация:** модель хорошо обобщает за пределы своего обучающего распределения, о чем свидетельствует ее производительность на больших лабиринтах.

CTM открывает новые направления исследований, демонстрируя, что включение временной динамики в качестве центрального компонента нейронной обработки может привести к созданию более способных и интерпретируемых систем ИИ. Хотя она не решает все задачи искусственного интеллекта, она предлагает многообещающий подход, который сокращает разрыв между текущими возможностями ИИ и гибкой, общей природой человеческого познания.