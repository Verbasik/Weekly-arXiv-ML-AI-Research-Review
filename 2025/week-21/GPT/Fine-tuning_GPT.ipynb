{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-2 Fine-tuning на датасете Wikibooks: Пошаговое руководство\n",
    "\n",
    "В этом туториале мы погрузимся в процесс **классического дообучения (full fine-tuning)** предобученной языковой модели GPT-2 на специфическом корпусе текстов — датасете Wikibooks на русском языке. Full fine-tuning — это мощный метод в области машинного обучения, который позволяет адаптировать уже обученную модель к новой задаче или набору данных, обновляя при этом **все её параметры**.\n",
    "\n",
    "### Что такое Full Fine-tuning?\n",
    "\n",
    "Full fine-tuning — это процесс взятия предварительно обученной нейронной сети (в нашем случае, GPT-2) и дальнейшего обучения её на новом, часто меньшем и более специализированном наборе данных. Идея заключается в том, что большая языковая модель, такая как GPT-2, уже изучила обширные общие закономерности языка (грамматику, синтаксис, базовые факты) на огромных объемах текстовых данных. Однако для выполнения более конкретных задач или работы с уникальными стилями текста ей требуется дополнительная адаптация.\n",
    "\n",
    "В отличие от методов PEFT (Parameter-Efficient Fine-Tuning), которые обновляют лишь малую часть параметров модели или добавляют небольшие, обучаемые модули, **full fine-tuning обновляет абсолютно все веса и смещения в нейронной сети**.\n",
    "\n",
    "### Как это работает?\n",
    "\n",
    "Процесс full fine-tuning можно упрощенно описать так:\n",
    "\n",
    "1.  **Выбор предобученной модели:** мы начинаем с модели, которая уже прошла обучение на очень большом и разнообразном корпусе данных. В нашем случае это `ai-forever/rugpt3small_based_on_gpt2` — русскоязычная версия GPT-2.\n",
    "2.  **Подготовка нового датасета:** собирается меньший, целевой набор данных, который специфичен для нашей задачи. В этом туториале мы используем часть датасета Wikibooks, чтобы модель научилась генерировать тексты в стиле энциклопедических статей.\n",
    "3.  **\"Разморозка\" и продолжение обучения:** веса предобученной модели используются как отправная точка. Все слои модели \"размораживаются\" (становятся обучаемыми), и процесс обучения продолжается на новом датасете. Модель продолжает учиться, адаптируя все свои внутренние представления к особенностям нового набора данных.\n",
    "4.  **Тонкая настройка параметров:** скорость обучения, размер батча и другие гиперпараметры могут быть скорректированы для достижения наилучших результатов на новом датасете. Обычно для fine-tuning используются меньшие скорости обучения по сравнению с начальным обучением, чтобы не \"забыть\" то, что модель уже выучила.\n",
    "5.  **Оценка и использование:** после дообучения модель оценивается на тестовых данных, и, если результаты удовлетворительны, она готова к использованию для генерации текста, суммаризации или других задач, на которые она была настроена.\n",
    "\n",
    "**Преимущества Full Fine-tuning:**\n",
    "\n",
    "* **Потенциально лучшая производительность:** поскольку все параметры модели адаптируются, full fine-tuning часто может достичь наивысшей производительности на целевой задаче, особенно если новый датасет достаточно велик и существенно отличается от исходных данных.\n",
    "* **Гибкость:** модель полностью перестраивается под новый домен.\n",
    "\n",
    "**Недостатки Full Fine-tuning:**\n",
    "\n",
    "* **Высокие вычислительные затраты:** требует значительных вычислительных ресурсов (GPU/TPU) и времени, поскольку обновляются миллионы или миллиарды параметров.\n",
    "* **Большие требования к памяти:** модель в памяти остается того же размера, что и исходная, так как все веса сохраняются.\n",
    "* **Риск \"катастрофического забывания\" (catastrophic forgetting):** если новый датасет слишком мал или слишком сильно отличается, модель может \"забыть\" общие языковые знания, полученные на этапе предварительного обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Данный программный код представляет собой демонстрационный туториал по дообучению (fine-tuning) модели GPT-2\n",
    "на русскоязычном наборе данных Wikibooks. Он охватывает все этапы: от подготовки данных до тренировки\n",
    "модели и генерации текста. Основная цель — показать процесс адаптации предобученной языковой модели\n",
    "к специфическому корпусу текстов для улучшения её способности генерировать связный и релевантный текст\n",
    "на русском языке.\n",
    "\"\"\"\n",
    "\n",
    "# --- Импорты стандартных библиотек ---\n",
    "import sqlite3\n",
    "from typing import List, Any\n",
    "\n",
    "# --- Импорты сторонних библиотек ---\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2Tokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    TextDataset,\n",
    "    AutoConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Константы ---\n",
    "# Путь к базе данных Wikibooks\n",
    "WIKIBOOKS_DB_PATH: str = '/kaggle/input/wikibooks-dataset/wikibooks.sqlite'\n",
    "# Количество строк для загрузки из базы данных\n",
    "DB_LOAD_LIMIT: int = 3300\n",
    "# Размер тестовой выборки (20%)\n",
    "TEST_SIZE: float = 0.2\n",
    "# Состояние для воспроизводимости разделения данных\n",
    "RANDOM_STATE: int = 0\n",
    "# Имя файла для тренировочных данных\n",
    "TRAIN_FILE_NAME: str = \"train.txt\"\n",
    "# Имя файла для валидационных данных\n",
    "VALID_FILE_NAME: str = \"valid.txt\"\n",
    "# Устройство для обучения модели (GPU, если доступно, иначе CPU)\n",
    "DEVICE: str = \"cuda\"\n",
    "# Имя или путь к предобученной модели GPT-2 на русском языке\n",
    "MODEL_NAME_OR_PATH: str = 'ai-forever/rugpt3small_based_on_gpt2'\n",
    "# Размер блока для обработки текста токенизатором\n",
    "BLOCK_SIZE: int = 64\n",
    "# Директория для сохранения дообученной модели\n",
    "OUTPUT_DIR: str = \"./finetuned_model\"\n",
    "# Количество эпох для обучения\n",
    "NUM_TRAIN_EPOCHS: int = 10\n",
    "# Количество шагов накопления градиента\n",
    "GRADIENT_ACCUMULATION_STEPS: int = 2\n",
    "# Использование 16-битной точности для ускорения обучения\n",
    "FP16: bool = True\n",
    "# Размер батча для обучения на одном устройстве\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE: int = 64\n",
    "# Начальная скорость обучения\n",
    "LEARNING_RATE: float = 0.0002\n",
    "# Оптимизатор\n",
    "OPTIMIZER: str = 'adafactor'\n",
    "# Тип планировщика скорости обучения\n",
    "LR_SCHEDULER_TYPE: str = 'cosine'\n",
    "# Шаги сохранения модели\n",
    "SAVE_STEPS: int = 1000\n",
    "# Зерно для воспроизводимости результатов\n",
    "SEED: int = 42\n",
    "# Путь к чекпоинту для загрузки модели после дообучения\n",
    "CHECKPOINT_PATH: str = \"./finetuned_model/checkpoint-5000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загружаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T22:18:16.235861Z",
     "iopub.status.busy": "2024-05-28T22:18:16.235499Z",
     "iopub.status.idle": "2024-05-28T22:18:18.283613Z",
     "shell.execute_reply": "2024-05-28T22:18:18.282882Z",
     "shell.execute_reply.started": "2024-05-28T22:18:16.235813Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Загрузка и подготовка данных ---\n",
    "conn: sqlite3.Connection = sqlite3.connect(WIKIBOOKS_DB_PATH)\n",
    "\n",
    "# Загрузка данных из таблицы 'ru' с ограничением по количеству строк\n",
    "df: pd.DataFrame = pd.read_sql_query(f\"SELECT * FROM ru LIMIT {DB_LOAD_LIMIT}\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T22:18:19.360098Z",
     "iopub.status.busy": "2024-05-28T22:18:19.359721Z",
     "iopub.status.idle": "2024-05-28T22:18:19.381675Z",
     "shell.execute_reply": "2024-05-28T22:18:19.380770Z",
     "shell.execute_reply.started": "2024-05-28T22:18:19.360069Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Викиучебник: Техника и технология средств масс...</td>\n",
       "      <td>https://ru.wikibooks.org/wiki/%D0%A2%D0%B5%D1%...</td>\n",
       "      <td>* [станция|Рабочая станция];</td>\n",
       "      <td>Рабочая станция;\\nСервер;\\nПерсональный компью...</td>\n",
       "      <td>&lt;div class=\"mw-parser-output\"&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Викиучебник: АОН/Пилотское свидетельство</td>\n",
       "      <td>https://ru.wikibooks.org/wiki/%D0%90%D0%9E%D0%...</td>\n",
       "      <td>Гражданское пилотское свидетельство - разрешен...</td>\n",
       "      <td>В Википедии имеется статья по теме «Свидетельс...</td>\n",
       "      <td>&lt;div class=\"mw-parser-output\"&gt;&lt;div class=\"info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Викиучебник: Книга программиста/Структуры данн...</td>\n",
       "      <td>https://ru.wikibooks.org/wiki/%D0%9A%D0%BD%D0%...</td>\n",
       "      <td>К оглавлению</td>\n",
       "      <td>К оглавлению\\nВсе программы, код которых вылож...</td>\n",
       "      <td>&lt;div class=\"mw-parser-output\"&gt;&lt;p&gt;&lt;a href=\"/wik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Викиучебник: Тесты НМО/Гигиенические основы и ...</td>\n",
       "      <td>https://ru.wikibooks.org/wiki/%D0%A2%D0%B5%D1%...</td>\n",
       "      <td>Гигиенические основы и медицинский контроль за...</td>\n",
       "      <td>Гигиенические основы и медицинский контроль за...</td>\n",
       "      <td>&lt;div class=\"mw-parser-output\"&gt;&lt;p&gt;&lt;b&gt;Гигиеничес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Викиучебник: Коктейли/Пенная фея</td>\n",
       "      <td>https://ru.wikibooks.org/wiki/%D0%9A%D0%BE%D0%...</td>\n",
       "      <td>Пенная фея</td>\n",
       "      <td>Пенная фея\\n\\nДжин Old Tom — 60 г\\nАбсент — 15...</td>\n",
       "      <td>&lt;div class=\"mw-parser-output\"&gt;&lt;p&gt;&lt;b&gt;Пенная фея...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Викиучебник: Техника и технология средств масс...   \n",
       "1           Викиучебник: АОН/Пилотское свидетельство   \n",
       "2  Викиучебник: Книга программиста/Структуры данн...   \n",
       "3  Викиучебник: Тесты НМО/Гигиенические основы и ...   \n",
       "4                   Викиучебник: Коктейли/Пенная фея   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://ru.wikibooks.org/wiki/%D0%A2%D0%B5%D1%...   \n",
       "1  https://ru.wikibooks.org/wiki/%D0%90%D0%9E%D0%...   \n",
       "2  https://ru.wikibooks.org/wiki/%D0%9A%D0%BD%D0%...   \n",
       "3  https://ru.wikibooks.org/wiki/%D0%A2%D0%B5%D1%...   \n",
       "4  https://ru.wikibooks.org/wiki/%D0%9A%D0%BE%D0%...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0                       * [станция|Рабочая станция];   \n",
       "1  Гражданское пилотское свидетельство - разрешен...   \n",
       "2                                       К оглавлению   \n",
       "3  Гигиенические основы и медицинский контроль за...   \n",
       "4                                         Пенная фея   \n",
       "\n",
       "                                           body_text  \\\n",
       "0  Рабочая станция;\\nСервер;\\nПерсональный компью...   \n",
       "1  В Википедии имеется статья по теме «Свидетельс...   \n",
       "2  К оглавлению\\nВсе программы, код которых вылож...   \n",
       "3  Гигиенические основы и медицинский контроль за...   \n",
       "4  Пенная фея\\n\\nДжин Old Tom — 60 г\\nАбсент — 15...   \n",
       "\n",
       "                                           body_html  \n",
       "0  <div class=\"mw-parser-output\"><ul><li><a href=...  \n",
       "1  <div class=\"mw-parser-output\"><div class=\"info...  \n",
       "2  <div class=\"mw-parser-output\"><p><a href=\"/wik...  \n",
       "3  <div class=\"mw-parser-output\"><p><b>Гигиеничес...  \n",
       "4  <div class=\"mw-parser-output\"><p><b>Пенная фея...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T22:18:19.566104Z",
     "iopub.status.busy": "2024-05-28T22:18:19.565782Z",
     "iopub.status.idle": "2024-05-28T22:18:19.574264Z",
     "shell.execute_reply": "2024-05-28T22:18:19.573366Z",
     "shell.execute_reply.started": "2024-05-28T22:18:19.566079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Фильтрация пустых текстовых полей\n",
    "df = df[df['body_text'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T22:18:19.923756Z",
     "iopub.status.busy": "2024-05-28T22:18:19.923429Z",
     "iopub.status.idle": "2024-05-28T22:18:20.522648Z",
     "shell.execute_reply": "2024-05-28T22:18:20.521743Z",
     "shell.execute_reply.started": "2024-05-28T22:18:19.923729Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Разделение данных на тренировочную и тестовую выборки\n",
    "train_texts: pd.Series\n",
    "test_texts:  pd.Series\n",
    "\n",
    "train_texts, test_texts = train_test_split(df['body_text'],\n",
    "                                           test_size=TEST_SIZE,\n",
    "                                           random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T22:18:20.524770Z",
     "iopub.status.busy": "2024-05-28T22:18:20.524460Z",
     "iopub.status.idle": "2024-05-28T22:18:20.530938Z",
     "shell.execute_reply": "2024-05-28T22:18:20.529872Z",
     "shell.execute_reply.started": "2024-05-28T22:18:20.524744Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2635,), (659,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts.shape, test_texts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохраняем тексты в файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T22:18:20.532748Z",
     "iopub.status.busy": "2024-05-28T22:18:20.532410Z",
     "iopub.status.idle": "2024-05-28T22:18:20.753040Z",
     "shell.execute_reply": "2024-05-28T22:18:20.751868Z",
     "shell.execute_reply.started": "2024-05-28T22:18:20.532721Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"train.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(train_texts.tolist()))\n",
    "\n",
    "with open(\"valid.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(test_texts.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Запускаем дообучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T22:18:37.873950Z",
     "iopub.status.busy": "2024-05-28T22:18:37.873398Z",
     "iopub.status.idle": "2024-05-28T22:18:43.649244Z",
     "shell.execute_reply": "2024-05-28T22:18:43.648230Z",
     "shell.execute_reply.started": "2024-05-28T22:18:37.873923Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27615eb197594464bdd930ffccda5dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6972f0283787472a9eac09f7c75b315a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46c3665d51f48ff8f06be9bd08708aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eaf0b452fa8464f9de7b6f965dce003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/574 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf30243bacc140b6a725e5eb5efce7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/720 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf03230322c48cfac638860ddf83d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/551M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# --- Инициализация модели и токенизатора ---\n",
    "# Инициализация токенизатора GPT-2\n",
    "tokenizer: GPT2Tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n",
    "\n",
    "# Загрузка предобученной модели GPT-2\n",
    "model: GPT2LMHeadModel = GPT2LMHeadModel.from_pretrained(MODEL_NAME_OR_PATH).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T22:18:43.650882Z",
     "iopub.status.busy": "2024-05-28T22:18:43.650568Z",
     "iopub.status.idle": "2024-05-28T22:18:44.254488Z",
     "shell.execute_reply": "2024-05-28T22:18:44.253527Z",
     "shell.execute_reply.started": "2024-05-28T22:18:43.650851Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта TextDataset для тренировочных данных\n",
    "# Этот объект подготавливает данные для обучения, используя токенизатор\n",
    "# и заданный размер блока.\n",
    "train_dataset: TextDataset = TextDataset(tokenizer=tokenizer,\n",
    "                                         file_path=f'/kaggle/working/{TRAIN_FILE_NAME}',\n",
    "                                         block_size=BLOCK_SIZE)\n",
    "\n",
    "# Создание DataCollator для языкового моделирования\n",
    "# DataCollator отвечает за динамическое создание батчей данных,\n",
    "# включая маскирование и другие операции, необходимые для обучения.\n",
    "data_collator: DataCollatorForLanguageModeling = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T22:18:44.256740Z",
     "iopub.status.busy": "2024-05-28T22:18:44.256442Z",
     "iopub.status.idle": "2024-05-28T22:18:44.284361Z",
     "shell.execute_reply": "2024-05-28T22:18:44.283472Z",
     "shell.execute_reply.started": "2024-05-28T22:18:44.256714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Настройка аргументов для обучения\n",
    "# Здесь определяются различные параметры обучения, такие как выходная директория,\n",
    "# количество эпох, размер батча и скорость обучения.\n",
    "training_args: TrainingArguments = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    fp16=FP16,\n",
    "    per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    optim=OPTIMIZER,\n",
    "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T22:18:44.285899Z",
     "iopub.status.busy": "2024-05-28T22:18:44.285542Z",
     "iopub.status.idle": "2024-05-28T22:18:44.933286Z",
     "shell.execute_reply": "2024-05-28T22:18:44.932335Z",
     "shell.execute_reply.started": "2024-05-28T22:18:44.285864Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Инициализация объекта Trainer\n",
    "# Trainer инкапсулирует процесс обучения, позволяя легко управлять\n",
    "# моделью, аргументами обучения, датасетом и коллатором данных.\n",
    "trainer: Trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T22:18:45.930384Z",
     "iopub.status.busy": "2024-05-28T22:18:45.930053Z",
     "iopub.status.idle": "2024-05-29T00:10:29.098619Z",
     "shell.execute_reply": "2024-05-29T00:10:29.097770Z",
     "shell.execute_reply.started": "2024-05-28T22:18:45.930354Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240528_221900-9uf502zt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/l-rekhlov-inno/huggingface/runs/9uf502zt' target=\"_blank\">apricot-star-6</a></strong> to <a href='https://wandb.ai/l-rekhlov-inno/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/l-rekhlov-inno/huggingface' target=\"_blank\">https://wandb.ai/l-rekhlov-inno/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/l-rekhlov-inno/huggingface/runs/9uf502zt' target=\"_blank\">https://wandb.ai/l-rekhlov-inno/huggingface/runs/9uf502zt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5860' max='5860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5860/5860 1:51:08, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.520200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.274900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.087500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.918200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.768100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.632600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.506500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.431100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.380700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.347800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5860, training_loss=1.8585257103825592, metrics={'train_runtime': 6702.7479, 'train_samples_per_second': 111.953, 'train_steps_per_second': 0.874, 'total_flos': 2.4489040453632e+16, 'train_loss': 1.8585257103825592, 'epoch': 9.99})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Запуск процесса обучения\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Генерируем примеры текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T18:43:42.447034Z",
     "iopub.status.busy": "2024-05-29T18:43:42.446188Z",
     "iopub.status.idle": "2024-05-29T18:43:42.453348Z",
     "shell.execute_reply": "2024-05-29T18:43:42.452337Z",
     "shell.execute_reply.started": "2024-05-29T18:43:42.447002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Функция для генерации текста ---\n",
    "# Краткое описания назначения функции\n",
    "def generate(\n",
    "    prompt: str,\n",
    "    do_sample: bool = True,\n",
    "    num_beams: int = 2,\n",
    "    temperature: float = 1.5,\n",
    "    top_p: float = 0.9,\n",
    "    max_length: int = 75\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    ---------------\n",
    "        Генерирует текст, используя дообученную модель GPT-2, на основе заданного\n",
    "        начального промпта. Поддерживает различные параметры генерации для контроля\n",
    "        качества и разнообразия вывода.\n",
    "\n",
    "    Args:\n",
    "    ---------------\n",
    "        prompt: Начальный текст (затравка) для генерации.\n",
    "\n",
    "        do_sample: Если True, будет использоваться сэмплирование для генерации,\n",
    "                   иначе - жадный поиск или beam search.\n",
    "\n",
    "        num_beams: Количество лучей для beam search. Если do_sample=False,\n",
    "                   увеличение num_beams может улучшить качество, но увеличит время.\n",
    "\n",
    "        temperature: Параметр, влияющий на \"креативность\" генерации. Более высокие\n",
    "                     значения делают текст более случайным, низкие - более предсказуемым.\n",
    "\n",
    "        top_p: Параметр фильтрации вероятностей, при котором выбираются токены,\n",
    "               сумма вероятностей которых достигает top_p. Помогает избежать\n",
    "               генерации редких и некорректных токенов.\n",
    "\n",
    "        max_length: Максимальная длина генерируемого текста, включая промпт.\n",
    "\n",
    "    Returns:\n",
    "    ---------------\n",
    "        None: Выводит сгенерированный текст в консоль.\n",
    "\n",
    "    Raises:\n",
    "    ---------------\n",
    "        Exception: Возникает, если модель или токенизатор не загружены или не\n",
    "                   доступны для устройства.\n",
    "\n",
    "    Examples:\n",
    "    ---------------\n",
    "        >>> generate(\"Привет, как дела?\", max_length=50)\n",
    "        'Привет, как дела? Я думаю, что все хорошо.'\n",
    "    \"\"\"\n",
    "    # Кодирование входного промпта в идентификаторы токенов и перемещение на устройство\n",
    "    input_ids: torch.Tensor = tokenizer.encode(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "    # Переключение модели в режим оценки\n",
    "    # Это отключает дропаут и нормализацию батчей, что важно для инференса.\n",
    "    model.eval()\n",
    "\n",
    "    # Отключение вычисления градиентов для ускорения инференса и уменьшения потребления памяти\n",
    "    with torch.no_grad():\n",
    "        # Генерация текста с использованием заданных параметров\n",
    "        out: torch.Tensor = model.generate(input_ids,\n",
    "                                           do_sample=do_sample,\n",
    "                                           num_beams=num_beams,\n",
    "                                           temperature=temperature,\n",
    "                                           top_p=top_p,\n",
    "                                           max_length=max_length,\n",
    "                                           )\n",
    "\n",
    "    # Декодирование сгенерированных идентификаторов токенов обратно в текст и вывод результата.\n",
    "    print(list(map(tokenizer.decode, out))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T18:42:26.591100Z",
     "iopub.status.busy": "2024-05-29T18:42:26.590336Z",
     "iopub.status.idle": "2024-05-29T18:42:26.597539Z",
     "shell.execute_reply": "2024-05-29T18:42:26.596509Z",
     "shell.execute_reply.started": "2024-05-29T18:42:26.591069Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Загрузка дообученной модели и генерация текста ---\n",
    "# Загрузка конфигурации модели из сохраненного чекпоинта\n",
    "# Это необходимо для правильной инициализации модели с архитектурой,\n",
    "# соответствующей дообученной версии.\n",
    "config: AutoConfig = AutoConfig.from_pretrained(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T18:42:48.277843Z",
     "iopub.status.busy": "2024-05-29T18:42:48.277420Z",
     "iopub.status.idle": "2024-05-29T18:42:53.382914Z",
     "shell.execute_reply": "2024-05-29T18:42:53.382062Z",
     "shell.execute_reply.started": "2024-05-29T18:42:48.277813Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f8328880814c0080da2a11895bef1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bc53d8c3c441ed9e5686dfcb59fa0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9283fbcbcf534a1fa807814c33a4a5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8114d59fe97a445f849ff96b47d379e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/574 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Инициализация токенизатора GPT-2\n",
    "# Токенизатор повторно загружается для гарантии корректной работы.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n",
    "\n",
    "# Загрузка предобученной модели GPT-2 с новой конфигурацией и перемещение на устройство\n",
    "# Модель инициализируется с конфигурацией из дообученного состояния,\n",
    "# что позволяет использовать ее для генерации текста.\n",
    "model = GPT2LMHeadModel(config=config).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T18:47:22.022741Z",
     "iopub.status.busy": "2024-05-29T18:47:22.022204Z",
     "iopub.status.idle": "2024-05-29T18:47:22.385998Z",
     "shell.execute_reply": "2024-05-29T18:47:22.384931Z",
     "shell.execute_reply.started": "2024-05-29T18:47:22.022710Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "женщина тык✂✂ потерять предательство назначения получимварда 123ike геопол геополгрегрегре отдельными 123 проведено путями полиэти контур 123 123 лезетшней Ставрополь Ставропольota\n"
     ]
    }
   ],
   "source": [
    "# Генерация текста с использованием дообученной модели\n",
    "generate(\"женщина\", max_length=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "Опять же, используем тот же датасет, что и раньше. Делим его на обучающую и текстовую выборки. Сохраняем преобразованные тексты в обучающий и валидационный файлы. Используем модель ai-forever/rugpt3small_based_on_gpt2, которая адаптирована под русский язык.\n",
    "\n",
    "Дообучение проводилось на обучающем наборе данных с использованием настроенных параметров. Потери модели уменьшались с каждым шагом обучения.\n",
    "\n",
    "После завершения обучения была проверена способность модели к генерации текста. Опять же, из-за малости модели текст по промту выдавался невсегда связанный.\n",
    "\n",
    "**Основные результаты**\n",
    "\n",
    "- Эффективность дообучения: снижение потерь в процессе обучения указывает на то, что модель успешно адаптировалась к новым данным.\n",
    "- Качество генерации текста: генерированные моделью тексты были семантически связны и соответствовали заданным промптам.\n",
    "\n",
    "**Заключение**\n",
    "\n",
    "Дообучение модели GPT было успешно реализовано, что позволило улучшить качество генерации текстов на русском языке. Предположительно, при увеличении размера модели могли бы получиться более осмысленные выражения."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1167113,
     "sourceId": 2730445,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
